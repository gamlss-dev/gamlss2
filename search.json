[
  {
    "objectID": "NEWS.html",
    "href": "NEWS.html",
    "title": "gamlss2 0.1-0",
    "section": "",
    "text": "gamlss2 0.1-0\n\nFirst version of ‘gamlss2’ providing a fresh reimplementaton of the classic ‘gamlss’ package while being more modular and facilitating the creation of advanced terms and models.",
    "crumbs": [
      "News"
    ]
  },
  {
    "objectID": "vignettes/specials.html",
    "href": "vignettes/specials.html",
    "title": "Special Model Terms",
    "section": "",
    "text": "In order to add any new machine learning type algorithm in gamlss2 you need to define three special functions:\nHere we demonstrate how this can be done using the local polynomial smoothing function loess() in R, Cleveland, Grosse, and Shyu (1993).\nNote that any regression type machine learning function is R can be easily incorporated in gamlss2 especially if there is a prior weights argument in the function. loess() has the argument weights for prior weights so it can be incorporated easily.",
    "crumbs": [
      "Articles",
      "Special Model Terms"
    ]
  },
  {
    "objectID": "vignettes/specials.html#the-special-model-term-constructor",
    "href": "vignettes/specials.html#the-special-model-term-constructor",
    "title": "Special Model Terms",
    "section": "1 The special model term constructor",
    "text": "1 The special model term constructor\nAny special model term constructor must be registered in the fake_formula() function. If not yet registered, the user can provide a new special name in the specials argument of fake_formula(). Another option is to use the special model term constructor name ‘“user”’, which is already part of the special names list in fake_formula().\nThe definition function can take all relevant loess and loess.control arguments so it can pass them into the fitting function.\n\nlo &lt;- function(formula, ...) \n{\n  ## ensure it's a formula\n  if(!inherits(formula, \"formula\")) {\n    formula &lt;- as.character(substitute(formula))\n    formula &lt;- as.formula(paste(\"~\", formula))\n    environment(formula) &lt;- sys.frame(-1)\n  }\n\n  ## list for setting up the special model term \n  st &lt;- list()\n\n  ## control arguments\n  st$control &lt;- list(...)\n\n  ## variables, label and data\n  st$term &lt;- all.vars(formula) \n  st$label &lt;- paste0(\"lo(\", paste0(gsub(\" \", \"\",\n    as.character(formula)), collapse = \"\"), \")\") \n  st$data &lt;- model.frame(formula)\n\n  ## New model formula used for fitting.\n  st$formula &lt;- update(formula, response_z ~ .)\n\n  ## Assign the \"special\" class and the new class \"n\".\n  class(st) &lt;- c(\"special\", \"lo\")\n\n  return(st) \n}",
    "crumbs": [
      "Articles",
      "Special Model Terms"
    ]
  },
  {
    "objectID": "vignettes/specials.html#the-fitting-function",
    "href": "vignettes/specials.html#the-fitting-function",
    "title": "Special Model Terms",
    "section": "2 The fitting function",
    "text": "2 The fitting function\nThe fitting function takes the current working response, the iterative weights and the corresponding relevant term and creates a call to the loess function to fit the relevant model. It then saves the fitted values and the fitted objects for later use.\n\nspecial_fit.lo &lt;- function(x, z, w, control, ...)\n{\n  ## assign current working response and weights\n  x$data$response_z &lt;- z\n  x$data$weights_w &lt;- w\n\n  ## set up loess call\n  call &lt;- \"loess(formula = x$formula, data = x$data, weights = weights_w\"\n\n  ## add optional control parameters\n  if(!is.null(x$control)) {\n    for(j in names(x$control))\n      call &lt;- paste0(call, \", \", j, \"= x$control$\", j)\n  }\n  call &lt;- paste0(call, \")\")\n\n  ## estimate model\n  rval &lt;- list(\"model\" = eval(parse(text = call)))\n\n  ## get the fitted.values\n  rval$fitted.values &lt;- fitted(rval$model) \n\n  ## center fitted values\n  rval$shift &lt;- mean(rval$fitted.values)\n  rval$fitted.values &lt;- rval$fitted.values - rval$shift \n\n  ## degrees of freedom\n  rval$edf &lt;-  rval$model$trace.hat\n\n  ## assign class for predict method \n  class(rval) &lt;- \"lo.fitted\" \n\n  return(rval) \n}",
    "crumbs": [
      "Articles",
      "Special Model Terms"
    ]
  },
  {
    "objectID": "vignettes/specials.html#the-predict-function",
    "href": "vignettes/specials.html#the-predict-function",
    "title": "Special Model Terms",
    "section": "3 The predict function",
    "text": "3 The predict function\nThe prediction function shows how the predicted values of the model can be extracted.\n\nspecial_predict.lo.fitted &lt;- function(x, data, se.fit = FALSE, ...) \n{\n  p &lt;- as.numeric(predict(x$model, newdata = data))\n  p &lt;- p - x$shift\n  if(se.fit)\n    p &lt;- data.frame(\"fit\" = p)\n  return(p)\n}",
    "crumbs": [
      "Articles",
      "Special Model Terms"
    ]
  },
  {
    "objectID": "vignettes/specials.html#example-rent99-data",
    "href": "vignettes/specials.html#example-rent99-data",
    "title": "Special Model Terms",
    "section": "4 Example: rent99 data",
    "text": "4 Example: rent99 data\nWe use the rent99 data to demonstrate the use of the functions\n\n## load the Munich rent data\ndata(\"rent99\", package = \"gamlss.data\") \n\n## scale covariates\nrent99$area &lt;- scale(rent99$area)\nrent99$yearc &lt;- scale(rent99$yearc)\n\nNote that the continuous variables in the data area and yearc have been standardised. We defined four formulae for modelling the rent data. The first two use loess and the third and fourth uses the additive smoothing function s() for comparison. Formula f uses main effect smoothing terms for area and yearc for parameters \\(\\mu\\) and \\(\\sigma\\), respectively, while the second, f1, uses two dimensional smoothing functions for modelling one way interaction. The third formula uses one dimensional smoother for main effects and the fourth two dimensional cubic splines smoothers for interactions. Note that in this example we only use explanatory terms for the first two parameters \\(\\mu\\) and \\(\\sigma\\) and constants for the rest, \\(\\nu\\) and \\(\\tau\\).\n\nf &lt;- rent ~ lo(~area)+lo(~yearc)+location+bath+kitchen| \n            lo(~area)+lo(~yearc)+location+bath+kitchen|\n            1|1 \n\nf1 &lt;- rent ~ lo(~area*yearc)+location+bath+kitchen| \n             lo(~area*yearc)+location+bath+kitchen|\n             1|1\n\nsf &lt;- rent ~ s(~area)+s(~yearc)+location+bath+kitchen| \n             s(~area)+s(~yearc)+location+bath+kitchen|\n            1|1 \n\nsf1 &lt;- rent ~ te(area,yearc) + location + bath + kitchen | \n              te(area,yearc) + location + bath + kitchen |\n            1|1",
    "crumbs": [
      "Articles",
      "Special Model Terms"
    ]
  },
  {
    "objectID": "vignettes/specials.html#estimation",
    "href": "vignettes/specials.html#estimation",
    "title": "Special Model Terms",
    "section": "5 Estimation",
    "text": "5 Estimation\nBelow we use the package tictoc to measure the time is taken to fit each model. The main effect fit for loess is;\n\nlibrary(\"tictoc\")\ntic()\nb1 &lt;- gamlss2(f, data = rent99, family = BCTo) \n\nGAMLSS-RS iteration  1: Global Deviance = 38409.6672 eps = 0.286141     \nGAMLSS-RS iteration  2: Global Deviance = 38363.6237 eps = 0.001198     \nGAMLSS-RS iteration  3: Global Deviance = 38360.7687 eps = 0.000074     \nGAMLSS-RS iteration  4: Global Deviance = 38359.9016 eps = 0.000022     \nGAMLSS-RS iteration  5: Global Deviance = 38359.6113 eps = 0.000007     \n\ntoc()\n\n4.838 sec elapsed\n\n\nThe first order interaction fit for loess is;\n\ntic()\nb2 &lt;- gamlss2(f1, data = rent99, family = BCTo) \n\nGAMLSS-RS iteration  1: Global Deviance = 38410.5652 eps = 0.286125     \nGAMLSS-RS iteration  2: Global Deviance = 38359.84 eps = 0.001320     \nGAMLSS-RS iteration  3: Global Deviance = 38356.7695 eps = 0.000080     \nGAMLSS-RS iteration  4: Global Deviance = 38355.8814 eps = 0.000023     \nGAMLSS-RS iteration  5: Global Deviance = 38355.6119 eps = 0.000007     \n\ntoc()\n\n8.373 sec elapsed\n\n\nNow the main effect model using s()\n\nlibrary(tictoc)\ntic()\na1&lt;- gamlss2(sf, data = rent99, family = BCT) \n\nGAMLSS-RS iteration  1: Global Deviance = 38462.5283 eps = 0.285214     \nGAMLSS-RS iteration  2: Global Deviance = 38416.2184 eps = 0.001204     \nGAMLSS-RS iteration  3: Global Deviance = 38412.248 eps = 0.000103     \nGAMLSS-RS iteration  4: Global Deviance = 38410.7531 eps = 0.000038     \nGAMLSS-RS iteration  5: Global Deviance = 38410.2172 eps = 0.000013     \nGAMLSS-RS iteration  6: Global Deviance = 38410.034 eps = 0.000004     \n\ntoc()\n\n1.063 sec elapsed\n\n\nThe interaction model using te()\n\nlibrary(tictoc)\ntic()\na2&lt;- gamlss2(sf1, data = rent99, family = BCT) \n\nGAMLSS-RS iteration  1: Global Deviance = 38409.1594 eps = 0.286206     \nGAMLSS-RS iteration  2: Global Deviance = 38364.6191 eps = 0.001159     \nGAMLSS-RS iteration  3: Global Deviance = 38361.2928 eps = 0.000086     \nGAMLSS-RS iteration  4: Global Deviance = 38360.2823 eps = 0.000026     \nGAMLSS-RS iteration  5: Global Deviance = 38359.898 eps = 0.000010     \nGAMLSS-RS iteration  6: Global Deviance = 38359.7641 eps = 0.000003     \n\ntoc()\n\n1.259 sec elapsed\n\n\nThe cubic spline function is lot faster than the loess() implementation lo() in gamlss2, but let us now compare the models using AIC.\n\n## deviance\nAIC(b1, b2, a1, a2, k = 0)\n\n        AIC       df\nb2 38355.61 36.77363\nb1 38359.61 33.15714\na2 38359.76 38.38334\na1 38410.03 31.24265\n\n## BIC\nAIC(b1, b2, a1, a2, k = log(nrow(rent99)))\n\n        AIC       df\nb1 38625.97 33.15714\nb2 38651.03 36.77363\na1 38661.02 31.24265\na2 38668.11 38.38334\n\n\nIt seems that the two lo() models do better that the s() as far as the AIC criteria are concern.",
    "crumbs": [
      "Articles",
      "Special Model Terms"
    ]
  },
  {
    "objectID": "vignettes/specials.html#visualise-the-fits",
    "href": "vignettes/specials.html#visualise-the-fits",
    "title": "Special Model Terms",
    "section": "6 Visualise the fits",
    "text": "6 Visualise the fits\nThe standard plot() function of gamlss2 can be used to visualises the smooth curves fits (under certain circumstances). For example for the main effect model using lo() we have;\n\nplot(b1)\n\n\n\n\n\n\n\n\nNote that no standard errors are shown here compare to the s() function model shown below;\n\nplot(a1)\n\n\n\n\n\n\n\n\nFor the first order interaction model b2 and because the effects are not defined within gamlss2 calling plot() produces the standard residual plots;\n\nplot(b2)\n\n\n\n\n\n\n\n\nFor the first order interaction model a2 using tensor products the plot are more informative;\n\nplot(a2)\n\n\n\n\n\n\n\n\nOne can use the function vis.lo() of the package gamlss to visualised the fitted terms fitted with lo(). Here we show the area fitted values for parameter \\(\\mu\\) and model b including the partial residuals from the model.\n\ngamlss:::vis.lo(specials(b1, model=\"mu\")[[1]]$model, partial = TRUE)\n\n\n\n\n\n\n\n\nNext we show the year of construction yearc fit for parameters \\(\\mu\\) from model b without partial residuals.\n\ngamlss:::vis.lo(specials(b1, model = \"mu\")[[2]]$model, partial = FALSE)\n\n\n\n\n\n\n\n\nHere we plot the fitted surface fit from model b2 and parameters \\(\\mu\\);\n\ngamlss:::vis.lo(specials(b2, model = \"mu\")$model, partial = FALSE)\n\n\n\n\n\n\n\n\nHere we plot the same fitted surface as above adding a 95% confidence intervals;\n\ngamlss:::vis.lo(specials(b2, model = \"mu\")$model, se = 1.97)\n\n\n\n\n\n\n\n\nFinally we plot the fitted surface fit from the \\(\\mu\\) model of b2 adding the partial residuals.\n\ngamlss:::vis.lo(specials(b2, model = \"mu\")$model, partial = TRUE)\n\n\n\n\n\n\n\n\nNote that similar plots are given in section 9.6.3 of Stasinopoulos et al. (2017), where the lo() function within package gamlss, is described.",
    "crumbs": [
      "Articles",
      "Special Model Terms"
    ]
  },
  {
    "objectID": "vignettes/spatial.html",
    "href": "vignettes/spatial.html",
    "title": "Spatial Effects",
    "section": "",
    "text": "pkg &lt;- c(\"spdep\", \"ggplot2\", \"raster\", \"exactextractr\")\nfor(p in pkg) {\n  if(!(p %in% installed.packages())) install.packages(p)\n}\nlibrary(\"gamlss2\")\nlibrary(\"sf\")\nlibrary(\"spdep\")\nlibrary(\"ggplot2\")\nlibrary(\"raster\")\nlibrary(\"colorspace\")\nSpatial data analysis is important in many fields such as environmental science, epidemiology, and climatology, where observations are collected across different geographical locations. A key challenge in spatial modeling is accounting for the dependence structure among nearby regions, which often display correlated patterns in outcomes.\nIn generalized additive models for location, scale, and shape (GAMLSS), spatial effects can be incorporated in various ways, such as through Markov random fields (MRFs). MRFs handle spatial correlation by applying penalties that reflect the neighborhood structure of the spatial data. This vignette is divided into two parts: the first part demonstrates how to estimate discrete spatial effects using MRFs with the gamlss2 package, while the second part provides examples of modeling spatial effects with smooth functions like thin-plate splines or tensor product splines.",
    "crumbs": [
      "Articles",
      "Spatial Effects"
    ]
  },
  {
    "objectID": "vignettes/spatial.html#example-modeling-severe-storm-counts-in-germany",
    "href": "vignettes/spatial.html#example-modeling-severe-storm-counts-in-germany",
    "title": "Spatial Effects",
    "section": "1 Example: Modeling Severe Storm Counts in Germany",
    "text": "1 Example: Modeling Severe Storm Counts in Germany\nIn this example, we analyze severe storm counts recorded at various weather stations across Germany over multiple years. Our goal is to model these storm counts while accounting for the spatial dependence between stations. To achieve this, we associate each weather station with its respective county in Germany, enabling us to incorporate the geographical structure into the model.\n\n## load the Germany severe storm data\ndata(\"storms\", package = \"gamlss2\")\n\n## plot storm counts per station and year\npar(mar = c(4, 4, 1, 1))\nplot(range(storms$year), range(storms$counts), type = \"n\",\n  xlab = \"Year\", ylab = \"Counts\")\nfor(j in levels(storms$id)) {\n  dj &lt;- subset(storms, id == j)\n  dj &lt;- dj[order(dj$year), ]\n  with(dj, lines(counts ~ year, type = \"b\", pch = 16,\n    col = rgb(0.1, 0.1, 0.1, alpha = 0.4)))\n}\n\n\n\n\n\n\n\n\nThe data contains storm counts per year for each station. A preliminary visualization of these counts allows us to inspect patterns of storm frequency over time and across stations.",
    "crumbs": [
      "Articles",
      "Spatial Effects"
    ]
  },
  {
    "objectID": "vignettes/spatial.html#visualizing-the-spatial-structure",
    "href": "vignettes/spatial.html#visualizing-the-spatial-structure",
    "title": "Spatial Effects",
    "section": "2 Visualizing the Spatial Structure",
    "text": "2 Visualizing the Spatial Structure\nWe begin by plotting the locations of weather stations on a map of Germany. The sf package is used to manage and plot spatial data.\n\n## load map of Germany\n## needs sf package for plotting\nlibrary(\"sf\")\ndata(\"Germany\", package = \"gamlss2\")\n\n## plot station locations\npar(mar = rep(0.5, 4))\nplot(st_geometry(Germany))\nco &lt;- unique(storms[, c(\"lat\", \"lon\")])\npoints(co, col = 2, pch = 4, lwd = 2)\n\n\n\n\n\n\n\n\nThis map shows the geographical distribution of weather stations. The spatial structure will be incorporated into our model to account for the proximity of stations when estimating storm counts.",
    "crumbs": [
      "Articles",
      "Spatial Effects"
    ]
  },
  {
    "objectID": "vignettes/spatial.html#defining-the-neighborhood-structure",
    "href": "vignettes/spatial.html#defining-the-neighborhood-structure",
    "title": "Spatial Effects",
    "section": "3 Defining the Neighborhood Structure",
    "text": "3 Defining the Neighborhood Structure\nNext, we define the neighborhood structure among the weather stations using a distance-based criterion. This is crucial for the Markov random field, as it specifies how spatial correlation should be penalized.\n\n## estimate spatial count model using\n## a Markov random field, first a neighbor matrix\n## needs to be computed, here we use distance based\n## neighbors\nlibrary(\"spdep\")\nnb &lt;- dnearneigh(st_centroid(st_geometry(Germany)), d1 = 0, d2 = 80)\npar(mar = rep(0.5, 4))\nplot(st_geometry(Germany), border = \"lightgray\")\nplot.nb(nb, st_geometry(Germany), add = TRUE)\n\nWarning in st_point_on_surface.sfc(coords): st_point_on_surface may not give\ncorrect results for longitude/latitude data\n\n\n\n\n\n\n\n\n\nThe neighbor matrix is constructed using the dneirneigh() function from the spdep package, which calculates the adjacency structure of the geographical regions. We then visualize the spatial network of neighbors on the map.",
    "crumbs": [
      "Articles",
      "Spatial Effects"
    ]
  },
  {
    "objectID": "vignettes/spatial.html#constructing-the-penalty-matrix",
    "href": "vignettes/spatial.html#constructing-the-penalty-matrix",
    "title": "Spatial Effects",
    "section": "4 Constructing the Penalty Matrix",
    "text": "4 Constructing the Penalty Matrix\nThe penalty matrix defines the spatial penalties imposed by the Markov random field. The matrix is constructed based on the neighbor relationships defined earlier.\n\n## compute final neighbor penalty matrix\nK &lt;- nb2mat(nb, style = \"B\", zero.policy = TRUE)\n\n## assign region names\nrownames(K) &lt;- colnames(K) &lt;- levels(Germany$id)\n\n## set up final penalty matrix\nK &lt;- -1 * K\ndiag(K) &lt;- -1 * rowSums(K)\n\n## remove regions not in data\ni &lt;- which(rownames(K) %in% levels(storms$id))\nK &lt;- K[i, i]\n\nThe penalty matrix K is set up such that it reflects the neighborhood relationships between the regions. Each element of the matrix represents how strongly each region is connected to its neighbors. The diagonal entries represent the total number of neighbors for each region.",
    "crumbs": [
      "Articles",
      "Spatial Effects"
    ]
  },
  {
    "objectID": "vignettes/spatial.html#estimating-the-model",
    "href": "vignettes/spatial.html#estimating-the-model",
    "title": "Spatial Effects",
    "section": "5 Estimating the Model",
    "text": "5 Estimating the Model\nWe now estimate the spatial count model using the Negative Binomial distribution (NBI). The model includes smooth functions of altitude, year, and an interaction between altitude and year, as well as a (functional) random effect over regions for the time trend. Spatial effects are incorporated using the bs = \"mrf\" option.\n\n## estimate count model using the NBI family,\n## model formula is\nf &lt;- ~ s(log(alt + 10)) + s(year) + s(id, bs = \"mrf\", xt = list(\"penalty\" = K), k = 100)\nf &lt;- list(update(f, counts ~ .), f)\n\n## estimate model using BIC for shrinkage parameter selection\nb &lt;- gamlss2(f, data = storms, family = NBI, criterion = \"BIC\")\n\nNote that estimation of this model takes some time, because of the quite high number of coefficients for the (functional) random effect ti(id, year, bs = c(\"re\", \"cr\"), k = c(157, 5)).\n\n## model summary\nsummary(b)\n\nCall:\ngamlss2(formula = counts ~ s(log(alt + 10)) + s(year) + s(id, \n    bs = \"mrf\", xt = list(penalty = K), k = 100) | s(log(alt + \n    10)) + s(year) + s(id, bs = \"mrf\", xt = list(penalty = K), \n    k = 100), data = storms, family = NBI, ... = pairlist(x = FALSE, criterion = \"BIC\"))\n---\nFamily: NBI \nLink function: mu = log, sigma = log\n*--------\nParameter: mu \n---\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   1.2999     0.0167   77.86   &lt;2e-16 ***\n---\nSmooth terms:\n    s(log(alt + 10)) s(year) s(id)\nedf           7.5077  2.2994 52.88\n*--------\nParameter: sigma \n---\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.20330    0.02505  -8.117  6.6e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n---\nSmooth terms:\n    s(log(alt + 10)) s(year)  s(id)\nedf           7.4533  2.1207 24.712\n*--------\nn = 3494 df =  98.97 res.df =  3395.03\nDeviance = 16484.181 Null Dev. Red. = 14.46%\nAIC = 16682.1271 elapsed =  4.48sec\n\n\nModel calibration is checked using histogram, Q-Q plot, wormplot etc.\n\nplot(b, which = \"resid\")\n\n\n\n\n\n\n\n\nHere, the spatial effect is modeled as an MRF smooth (s(id, bs = \"mrf\")), where the penalty matrix K enforces spatial structure based on neighboring stations. We use the Bayesian Information Criterion (BIC) to select the optimal smoothing parameters.",
    "crumbs": [
      "Articles",
      "Spatial Effects"
    ]
  },
  {
    "objectID": "vignettes/spatial.html#visualizing-the-estimated-effects",
    "href": "vignettes/spatial.html#visualizing-the-estimated-effects",
    "title": "Spatial Effects",
    "section": "6 Visualizing the Estimated Effects",
    "text": "6 Visualizing the Estimated Effects\nFinally, we visualize the estimated effects from the fitted model.\n\npar(mar = c(4, 4, 1, 1))\nplot(b)\n\n\n\n\n\n\n\n\nThe plot shows the estimated smooth functions for altitude, year, and the spatial effect. These visualizations help us interpret how storm counts vary across space and time.",
    "crumbs": [
      "Articles",
      "Spatial Effects"
    ]
  },
  {
    "objectID": "vignettes/spatial.html#prediction",
    "href": "vignettes/spatial.html#prediction",
    "title": "Spatial Effects",
    "section": "7 Prediction",
    "text": "7 Prediction\nWe predict the spatial risk of more than 2 severe storms in 2022. Therefore, we set up a new data frame containing only the unique locations.\n\nnd &lt;- unique(storms[, \"id\", drop = FALSE])\n\n## add the year\nnd$year &lt;- 2025\n\n## add altitude information, this is stored\n## in a raster file in\nrf &lt;- file.path(system.file(package = \"gamlss2\"), \"extra\", \"GermanyElevation.grd\")\n\n## needs the raster package\nlibrary(\"raster\")\n\n## read altitude raster file\nalt &lt;- raster(rf)\n\n## aggregate altitude to regions\nlibrary(\"exactextractr\")\nGermany$alt &lt;- exact_extract(alt, Germany, fun = \"median\")\nnd &lt;- merge(nd, Germany[, c(\"id\", \"alt\")], by = \"id\")\n\n## predict parameters of the NBI distribution\npar &lt;- predict(b, newdata = nd)\n\n## estimated probability of more than 2 severe storms\nnd$prob2 &lt;- 1 - family(b)$p(2, par)\n\n## add fitted probabilities to map of Germany\nm &lt;- merge(Germany, nd[, c(\"id\", \"prob2\")], by = \"id\", all.x = TRUE)\n\n## plot spatial risk\nlibrary(\"ggplot2\")\nlibrary(\"colorspace\")\nggplot(m) + geom_sf(aes(fill = prob2)) +\nscale_fill_continuous_diverging(\"Blue-Red 3\") + theme_bw()\n\n\n\n\n\n\n\n## note that because of the discrete spatial effect,\n## there are a lot of NAs, therefore, we need to compute\n## predictions in such regions by averaging using the neighbors\n## of a region. we use the neighbour list object nb to compute\n## the predictions, this is iterated.\nfill_missing_mrf &lt;- function(m, nb, j = \"fmu\") {\n  ## while there are still NAs in the specified column (e.g., 'fmu')\n  while(any(is.na(m[[j]]))) {\n    \n    ## recalculate the number of non-NA neighbors for each region\n    na_counts &lt;- sapply(seq_along(nb), function(i) {\n      if(is.na(m[[j]][i])) {\n        sum(!is.na(m[[j]][nb[[i]]])) ## count non-NA neighbors\n      } else {\n        -1 ## region already filled, deprioritize\n      }\n    })\n    \n    ## find the region with the most non-NA neighbors\n    max_index &lt;- which.max(na_counts)\n    \n    ## update that region using the mean of its neighbors' values\n    if(length(nb[[max_index]]) &gt; 0) {\n      m[[j]][max_index] &lt;- mean(m[[j]][nb[[max_index]]], na.rm = TRUE)\n    }\n  }\n  \n  ## return the updated predictions\n  return(m)\n}\n\nm &lt;- fill_missing_mrf(m, nb, j = \"prob2\")\n\n## plot final spatial risk\nggplot(m) + geom_sf(aes(fill = prob2)) +\nscale_fill_continuous_diverging(\"Blue-Red 3\") + theme_bw()",
    "crumbs": [
      "Articles",
      "Spatial Effects"
    ]
  },
  {
    "objectID": "vignettes/random.html",
    "href": "vignettes/random.html",
    "title": "Random Effects",
    "section": "",
    "text": "Random effects can be included as an additive term for any distribution parameter in a gamlss2 model by using the re() function in package gamlss2. Within the GAMLSS model fitting, the random effects additive term is then fitted locally by an interface with lme function of the nlme package.",
    "crumbs": [
      "Articles",
      "Random Effects"
    ]
  },
  {
    "objectID": "vignettes/random.html#random-effects-only-in-the-mu-model",
    "href": "vignettes/random.html#random-effects-only-in-the-mu-model",
    "title": "Random Effects",
    "section": "1 Random effects only in the \\(\\mu\\) model",
    "text": "1 Random effects only in the \\(\\mu\\) model\nFirst we will consider the case of random effects only in the \\(\\mu\\) model. In this case the estimates of the fixed effects for the \\(\\sigma\\) distribution parameter (and also \\(\\nu\\) and \\(\\tau\\)) in the gamlss2 fit do not use REML estimation.\nThis is not a problem if the total (effective) degrees of freedom (df) for estimating the fixed and random effects for \\(\\mu\\) are small relative to the total df (i.e. the sample size). Example 1 below illustrates this.\nHowever, if the total (effective) df for estimating the fixed and random effects for \\(\\mu\\) are a significant proportion of the total df, then the estimates of the fixed effects for \\(\\sigma\\) will be seriously negatively biased. Example 2 below illustrates this. [The estimated fixed effects for \\(\\mu\\) are OK (but not their estimated standard errors), and the random effects parameters are REML type estimates and are also OK. So, if these estimates are of primary interest, and the estimate of the \\(\\sigma\\) parameter is not of interest, then there is no problem.]\nThe total (effective) df for a random effect is ALWAYS less than the df for the corresponding fixed effects. So a quick check [of whether there might be a problem with serious negative bias in the estimates of the fixed effects for \\(\\sigma\\) in the gamlss() fit] is to compare the corresponding fixed effects df with the total df. For example, in a simple random intercepts model for \\(\\mu\\), if m is the number of individuals (or levels of the random effects factor), and n is the total sample size, then compare m with n, and if the proportion m/n is, say, greater than 0.05, there may be problem. Similarly for a random intercepts and slopes model for \\(\\mu\\), then compare 2m with n, and look and the proportion 2m/n.\nIn the first example below using re() in gamlss for random effects works [i.e. where the total number of individuals (or factor levels) is very small relative to the total number of observations and so REML estimation is not needed, for example, a relatively low number of individuals, each with a lot of repeated measurements, OR a random factor with a low number of levels, each with a lot of observations]. We show that using LME locally in gamlss() by the re() argument gives very similar results, to using LME directly.",
    "crumbs": [
      "Articles",
      "Random Effects"
    ]
  },
  {
    "objectID": "vignettes/random.html#example-2",
    "href": "vignettes/random.html#example-2",
    "title": "Random Effects",
    "section": "2 Example 2",
    "text": "2 Example 2\nIn the second example below using the Orthodont data, the number of individuals (or factor levels) is significant relative to the total number of observations, and there is a problem with a seriously negatively biased estimate of \\(\\sigma\\). We show that using lme locally in gamlss2 by the re() function gives a very different estimate of \\(\\sigma\\) than using LME directly. The Orthodont data set is analysed in detail on pages 147-155 of Pinheiro and Bates (2000) “Mixed-Effects Models in S and S-PLUS”.\n\nlibrary(\"gamlss\")\nlibrary(\"gamlss2\")\nlibrary(\"nlme\")\ndata(\"Orthodont\")\n\nFirst fit a random intercepts model using LME:\n\nl1 &lt;- lme(distance ~I(age-11),random =~ 1|Subject, data=Orthodont)\nl1\n\nLinear mixed-effects model fit by REML\n  Data: Orthodont \n  Log-restricted-likelihood: -223.5013\n  Fixed: distance ~ I(age - 11) \n(Intercept) I(age - 11) \n 24.0231481   0.6601852 \n\nRandom effects:\n Formula: ~1 | Subject\n        (Intercept) Residual\nStdDev:    2.114724 1.431592\n\nNumber of Observations: 108\nNumber of Groups: 27 \n\n\nThe model is\n\\[\n\\begin{split}\n\\texttt{distance}_{ij} \\sim& NO(0, \\sigma) \\\\\n    \\mu    =&  \\beta_{0}+ \\beta_1 (\\texttt{age}-11) +\\alpha_j \\\\\n\\end{split}\n\\] where \\(\\alpha_j \\sim NO(0, \\sigma_a)\\) The fitted model gives estimates \\(\\beta_0 = 24.02\\), \\(\\beta_1 = 0.660\\), \\(\\sigma_a = 2.1147\\) and \\(\\sigma = 1.432\\).\nNow fit the random intercepts model using function re() in gamlss2: Note that gamlss2 has problem in interpreting the I() function so we create the variable age_11\n\n\n\n\n\n\nNote\n\n\n\nthere is a problem with random intercepts in gamlss2 so we use gamlss\n\n\n\nb1 &lt;- gamlss2(distance ~ I(age-11) + re(random =~ 1 | Subject), data = Orthodont)\n\nGAMLSS-RS iteration  1: Global Deviance = 355.3077 eps = 0.339068     \nGAMLSS-RS iteration  2: Global Deviance = 355.3077 eps = 0.000000     \n\nm1 &lt;- gamlss(distance ~ I(age-11) + re(random =~ 1 | Subject), data = Orthodont)\n\nGAMLSS-RS iteration 1: Global Deviance = 355.3077 \nGAMLSS-RS iteration 2: Global Deviance = 355.3077 \n\n\n\n## extract fitted random intercept special mode term\nre &lt;- specials(b1, term = \"random\", elements = \"model\")\n\n## model summary\nsummary(re)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: x$data \n       AIC      BIC    logLik\n  449.3895 457.4359 -221.6948\n\nRandom effects:\n Formula: ~1 | Subject\n        (Intercept) Residual\nStdDev:    2.072142 1.783505\n\nVariance function:\n Structure: fixed weights\n Formula: ~weights_w \nFixed effects:  x$fixed \n                   Value Std.Error DF      t-value p-value\n(Intercept) 6.824005e-16 0.4235944 81 1.610976e-15       1\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-3.68695129 -0.53862941 -0.01232442  0.49100161  3.74701483 \n\nNumber of Observations: 108\nNumber of Groups: 27 \n\n## same with gamlss\ngetSmo(m1)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: Data \n  Log-likelihood: -221.6948\n  Fixed: fix.formula \n (Intercept) \n1.278595e-15 \n\nRandom effects:\n Formula: ~1 | Subject\n        (Intercept) Residual\nStdDev:    2.072142  1.13493\n\nVariance function:\n Structure: fixed weights\n Formula: ~W.var \nNumber of Observations: 108\nNumber of Groups: 27 \n\n\nCompare estimated coefficients\n\n## main model coefficients\ncoef(b1)\n\n   mu.p.(Intercept)    mu.p.I(age - 11) sigma.p.(Intercept) \n         24.0231481           0.6601852           0.2260047 \n\nsummary(l1)\n\nLinear mixed-effects model fit by REML\n  Data: Orthodont \n       AIC      BIC    logLik\n  455.0025 465.6563 -223.5013\n\nRandom effects:\n Formula: ~1 | Subject\n        (Intercept) Residual\nStdDev:    2.114724 1.431592\n\nFixed effects:  distance ~ I(age - 11) \n                Value Std.Error DF  t-value p-value\n(Intercept) 24.023148 0.4296605 80 55.91193       0\nI(age - 11)  0.660185 0.0616059 80 10.71626       0\n Correlation: \n            (Intr)\nI(age - 11) 0     \n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-3.66453932 -0.53507984 -0.01289591  0.48742859  3.72178465 \n\nNumber of Observations: 108\nNumber of Groups: 27 \n\n## random effect coefficients\nplot(coef(re)[, 1] + coef(b1)[\"mu.p.(Intercept)\"], coef(l1)[, 1],\n  xlab = \"gamlss2 random intercepts\", ylab = \"lme() random intercepts\",\n  main = \"Random Intercepts Comparison\")\nabline(0, 1, lty = 2, col = 4)\n\n\n\n\n\n\n\n\nThe fitted model gives estimates \\(\\beta_0 = 24.02\\), \\(\\beta_1 = 0.660\\), \\(\\sigma_a = 2.072\\) and \\(\\sigma = 1.254\\) The estimate of \\(\\sigma\\) is seriously negatively biased, because it is not a REML estimate.\nFor this simple random intercepts model, the estimate of \\(\\sigma\\) can be adjusted by multiplying by the local LME residual given by 1.135 giving: adjusted \\(\\sigma = 1.254*1.135 = 1.42\\), which is very close to the LME estimate of \\(\\sigma\\).\n\n\n\n\n\n\nWarning\n\n\n\nHowever this adjustment does NOT work for more complex random effects models.",
    "crumbs": [
      "Articles",
      "Random Effects"
    ]
  },
  {
    "objectID": "vignettes/s_pb.html",
    "href": "vignettes/s_pb.html",
    "title": "Smooth Terms using s() and pb()",
    "section": "",
    "text": "Smoothers are non-parametric techniques developed mostly in the 1980 and 90’s. The main advadance of a smoother is to suggest possible functional forms on how the explanatory variables effect the parameters of the response. That is, to let the data to detect non-linearities in the model. There are basically two types of smoothers;\nThere are several ways to use smoothers within the original GAMLSS framework and they are described in Chapter 9 of Stasinopoulos et al. (2017). Local polynomials smoothers can be used with gamlss2 by connection the R function loess() with gamlss2 using specials. This connection is described in a different vignette (Mikis reference here). Here we give an explanation of to how use the smooth terms s() and pb() within gamlss2.",
    "crumbs": [
      "Articles",
      "Smooth Terms using s() and pb()"
    ]
  },
  {
    "objectID": "vignettes/s_pb.html#the-s-function",
    "href": "vignettes/s_pb.html#the-s-function",
    "title": "Smooth Terms using s() and pb()",
    "section": "1 The s() function",
    "text": "1 The s() function\nThe function s() is using penalized regression smoothers and it is identical to the function s() used in the R package mgcv. The first argument of the function specifies the explanatory term(s). For one dimensional smoother the function can be used as;\n\nlibrary(gamlss2)\nlibrary(gamlss)\ngm11 &lt;- gamlss2(rent~s(area)+s(yearc)+location+bath+kitchen|\n               s(area)+s(yearc)+location+bath+kitchen,\n               data=rent99, family=GA)\n\nGAMLSS-RS iteration  1: Global Deviance = 38484.5671 eps = 0.124369     \nGAMLSS-RS iteration  2: Global Deviance = 38437.5655 eps = 0.001221     \nGAMLSS-RS iteration  3: Global Deviance = 38437.2934 eps = 0.000007     \n\n\nWe use smooth terms for the two continuous explanatory variables of the data, the size of the flats, area, and the year of construction, yearc. To visualise the fitted smooth functions try;\n\nplot(gm11)\n\n\n\n\n\n\n\n\nThe first two plot are for the \\(\\mu\\) model while the last two for the \\(\\sigma\\) model. It seems that both area, and yearc, need smoothing functions for the \\(\\mu\\) while only yearc need a smoother for the \\(\\sigma\\).\nNote that the first argument for s() is the continuous variables needed smoothing. Here we used single terms. Single terms represent main effects. More that one terms can be use to represent iteractions. Note that all argument of the s() function of the mgcv package apply here. Here we mention the most important ones;\n\nk; the dimension of the basis;\nbs; indicating the (penalized) smoothing basis to use, e.g. “tp” for thin plate regression spline, “cr” for cubic regression spline etc;\nm; The order of the penalty e.g. 2 for cubic spline penalty;\nby; a term for varying coefficient model (a specific form of iteraction);\n\nto find information about all the argument please try;\n\n?mgcv:::s\n\nTo model interactions within a additive smooth model we need two or more dimensional smoothers. The problem of course with more that two dimensional smoothers is that can not be visualised. Here we stick to two dimensional smoothers that is, a two way interaction;\n\ngm21 &lt;- gamlss2(rent~s(area,yearc)+location+bath+kitchen|\n                  s(area,yearc)+location+bath+kitchen,\n               data=rent99, family=GA)\n\nGAMLSS-RS iteration  1: Global Deviance = 38552.6223 eps = 0.122820     \nGAMLSS-RS iteration  2: Global Deviance = 38467.4636 eps = 0.002208     \nGAMLSS-RS iteration  3: Global Deviance = 38466.8474 eps = 0.000016     \nGAMLSS-RS iteration  4: Global Deviance = 38466.8359 eps = 0.000000     \n\n\nThe interaction plots can be visualised using;\n\nplot(gm21)\n\n\n\n\n\n\n\n\nOne could check for the best model using AIC.\n\nAIC(gm11, gm21)\n\n          AIC       df\ngm11 38496.64 29.67116\ngm21 38523.11 28.13775\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that the default value for m in s(), that is, the dimension of the basis for one dimensional smoother, is 10 which could be very small if a lot of degrees of freedom are needed for the smoother. This is important in the constructing of centile curves, see vignette Centile (Quantile) Estimation.\n\n\nMikis I think for two dimensional smoothers it uses \\(m=5\\) but I am not sure.",
    "crumbs": [
      "Articles",
      "Smooth Terms using s() and pb()"
    ]
  },
  {
    "objectID": "vignettes/s_pb.html#the-pb-function",
    "href": "vignettes/s_pb.html#the-pb-function",
    "title": "Smooth Terms using s() and pb()",
    "section": "2 The pb() function",
    "text": "2 The pb() function\nThe pb() function uses P-splines, see Eilers and Marx (2021). It tries to imitate the equivalent function pb() in the older gamlss package but still uses the s() function with different options. The option are s(..., bs=\"ps\", k=20) that is the number of basis is increased from 10 to 20. The way to estimate the hyper-parameter (smoothing-parameter) is also change, It uses criterion=\"ml\", which amount to a REML estimation of the smoothing parameter see Rigby and Stasinopoulos (2013). The result should be similar but not necessarily identical to the pb() function of the gamlss package.\n\ngm1 &lt;- gamlss2(rent~pb(area)+pb(yearc)+location+bath+kitchen|pb(area)+pb(yearc)+\n                 location+bath+kitchen,data=rent99, family=GA)\n\nGAMLSS-RS iteration  1: Global Deviance = 38439.2661 eps = 0.125399     \nGAMLSS-RS iteration  2: Global Deviance = 38429.5701 eps = 0.000252     \nGAMLSS-RS iteration  3: Global Deviance = 38429.4305 eps = 0.000003     \n\nplot(gm1)\n\n\n\n\n\n\n\n\nThe smooth functions for \\(\\mu\\) using the pv() function are almost identical to the ones when s() was used. The smooth terms for the \\(\\sigma\\) model especially for area are different. This could be to the fact that more degrees of freedom are allowed with pb() and possible this lead to overfit.\n\n\n\n\n\n\nNote\n\n\n\nNote that there are not two dimensional smoothers with pb()\n\n\nMikis It looks that pb() in gamlss2 overfits \\(\\sigma\\). Here is what we get in gamnlss\n\ng1 &lt;- gamlss(rent~pb(area)+pb(yearc)+location+bath+kitchen,~pb(area)+pb(yearc)+\n                 location+bath+kitchen,data=rent99, family=GA)\n\nGAMLSS-RS iteration 1: Global Deviance = 38459.65 \nGAMLSS-RS iteration 2: Global Deviance = 38448.8 \nGAMLSS-RS iteration 3: Global Deviance = 38448.64 \nGAMLSS-RS iteration 4: Global Deviance = 38448.62 \nGAMLSS-RS iteration 5: Global Deviance = 38448.62 \n\nterm.plot(g1, \"sigma\", pages=1, term=c(1,2), ask=FALSE)",
    "crumbs": [
      "Articles",
      "Smooth Terms using s() and pb()"
    ]
  },
  {
    "objectID": "vignettes/survival.html",
    "href": "vignettes/survival.html",
    "title": "Survival Models",
    "section": "",
    "text": "In survival analysis, we aim to model the time until an event occurs, which is typically represented as a random variable \\(T\\). The survival function \\(S(t)\\) indicates the probability that the event has not occurred by time \\(t\\), mathematically defined as \\[\nS(t) = P(T &gt; t) = 1 - F(t),\n\\] where \\(F(t)\\) is the cumulative distribution function (CDF) of the random variable \\(T\\).\nThe hazard function \\(\\lambda(t)\\), which describes the instantaneous risk of the event occurring at time \\(t\\), is defined as \\[\n\\lambda(t) = \\frac{d(t)}{S(t)},\n\\] where \\(d(t)\\) is the probability density function (PDF) of \\(T\\).",
    "crumbs": [
      "Articles",
      "Survival Models"
    ]
  },
  {
    "objectID": "vignettes/survival.html#survival-models-in-the-gamlss-framework",
    "href": "vignettes/survival.html#survival-models-in-the-gamlss-framework",
    "title": "Survival Models",
    "section": "1 Survival models in the GAMLSS framework",
    "text": "1 Survival models in the GAMLSS framework\nWithin the GAMLSS framework, we can specify a parametric form for the hazard function by selecting an appropriate distribution that fits the survival data, denoted as \\[\nd(t \\mid \\boldsymbol{\\theta}),\n\\] where \\(d( \\cdot )\\) represents a parametric density suitable for modeling survival times and \\(\\boldsymbol{\\theta} = (\\theta_1, \\ldots, \\theta_K)^\\top\\) are the parameters that need to be estimated.\nTo incorporate covariates into this model, we can express the parameters as functions of explanatory variables \\(\\theta_k(\\mathbf{x})\\), \\(k = 1, \\ldots, K\\). We utilize GAM-type predictors represented by \\[\n\\eta_{k}(\\mathbf{x}) = f_{1k}(\\mathbf{x}) + \\dots + f_{J_{k}k}(\\mathbf{x})\n\\] which are linked to the parameters through suitable link functions \\[\nh_{k}(\\theta_{k}(\\mathbf{x})) = \\eta_{k}(\\mathbf{x}).\n\\] The functions \\(f_{jk}(\\cdot)\\) for \\(j = 1, \\ldots, J_{k}\\) and \\(k = 1, \\ldots, K\\), can be nonlinear smooth functions (typically estimated using regression splines), linear effects, or random effects, among others. This flexible modeling approach allows for a richer representation of the relationship between covariates and the distribution parameters compared to simple linear effects.\nIn GAMLSS, model estimation is generally performed using (penalized) maximum likelihood estimation (MLE). The likelihood function for a survival model with right-censored data for \\(i = 1, \\ldots, n\\) observations can be expressed as \\[\nL(\\boldsymbol{\\beta}, \\boldsymbol{\\theta}) = \\prod_{i=1}^{n} \\left[ d(t_i \\mid \\boldsymbol{\\theta}(\\mathbf{x}_i)) \\right]^{\\delta_i} \\left[ S(t_i \\mid \\boldsymbol{\\theta}(\\mathbf{x}_i)) \\right]^{1 - \\delta_i},\n\\] where \\(\\delta_i\\) is the censoring indicator for the \\(i\\)-th observation. It takes the value of 1 if the event is observed (i.e., not censored) and 0 if it is censored. This likelihood function effectively accounts for both observed and censored data, facilitating the estimation of model parameters.",
    "crumbs": [
      "Articles",
      "Survival Models"
    ]
  },
  {
    "objectID": "vignettes/survival.html#leuksurv-data-example",
    "href": "vignettes/survival.html#leuksurv-data-example",
    "title": "Survival Models",
    "section": "2 LeukSurv data example",
    "text": "2 LeukSurv data example\nIn this example, we analyze the LeukSurv data provided in the spBayesSurv package. This dataset contains survival information on patients diagnosed with leukemia, where the main variables include time (the survival time), cens (the censoring indicator, with 1 indicating the event has occurred and 0 indicating right-censoring), age, sex, wbc (white blood cell count), tpi (tumor proliferative index), and spatial coordinates xcoord and ycoord representing the location of the patients. These covariates provide both demographic and clinical information that can be used to model the survival times and the associated risks.\nThe dataset is particularly useful for illustrating spatial survival modeling, as it allows us to incorporate spatial covariates (coordinates) into the survival model, capturing potential geographical variations in survival probabilities. We will first demonstrate how to estimate simple survival curves using gamlss2, followed by a full spatial survival model where the geographical coordinates are explicitly modeled to investigate any spatial effects on survival.\nWe begin by loading the necessary packages and the LeukSurv dataset. These packages provide functions for survival analysis, censored data handling, and spatial data manipulation, which are essential for the analysis that follows. Specifically, gamlss2 will be used for flexible survival model estimation, while gamlss.cens manages the censored data structure. Additionally, sf and stars will facilitate spatial data processing and visualization.\n\n## install packages\npkg &lt;- c(\"spBayesSurv\", \"gamlss.cens\", \"sf\", \"stars\")\nfor(p in pkg) {\n  if(!(p %in% installed.packages())) install.packages(p)\n}\n\n## load required packages\nlibrary(\"gamlss2\")\nlibrary(\"gamlss.cens\")\nlibrary(\"sf\")\nlibrary(\"stars\")\n\n## load the LeukSurv data\ndata(\"LeukSurv\", package = \"spBayesSurv\")",
    "crumbs": [
      "Articles",
      "Survival Models"
    ]
  },
  {
    "objectID": "vignettes/survival.html#generating-a-censored-family",
    "href": "vignettes/survival.html#generating-a-censored-family",
    "title": "Survival Models",
    "section": "3 Generating a censored family",
    "text": "3 Generating a censored family\nTo handle censored data in the gamlss2 framework, we first need to generate a censored family based on a parametric distribution. In this case, we use the Weibull distribution (denoted as WEI in gamlss.dist). This involves transforming the standard Weibull family into one that can handle censored observations.\nWe accomplish this by using the gen.cens() function provided in the gamlss.cens package, which adapts the distribution to accommodate censoring. Then, we create a censored family using the cens() function.\n\ngen.cens(WEI)\n\nA censored family of distributions from WEI has been generated \n and saved under the names:  \n dWEIrc pWEIrc qWEIrc WEIrc \nThe type of censoring is right  \n\nfam &lt;- cens(WEI)",
    "crumbs": [
      "Articles",
      "Survival Models"
    ]
  },
  {
    "objectID": "vignettes/survival.html#estimating-time-only-models",
    "href": "vignettes/survival.html#estimating-time-only-models",
    "title": "Survival Models",
    "section": "4 Estimating time-only models",
    "text": "4 Estimating time-only models\nTo begin, we estimate a simple survival model where the only predictor is time. This is done both with gamlss2 for flexible distributional modeling, and with the more traditional survfit() function from the survival package for comparison.\nIn gamlss2, the model is specified using the Surv(time, cens) function, where time is the survival time, and cens is the censoring indicator. We fit the model assuming a Weibull distribution for survival times.\n\n## using gamlss2\nb1 &lt;- gamlss2(Surv(time, cens) ~ 1, family = fam, data = LeukSurv)\n\nGAMLSS-RS iteration  1: Global Deviance = 12269.5961 eps = 0.009779     \nGAMLSS-RS iteration  2: Global Deviance = 12267.698 eps = 0.000154     \nGAMLSS-RS iteration  3: Global Deviance = 12267.6904 eps = 0.000000     \n\n## and now with survfit\ns1 &lt;- survfit(Surv(time, cens) ~ 1, data = LeukSurv)",
    "crumbs": [
      "Articles",
      "Survival Models"
    ]
  },
  {
    "objectID": "vignettes/survival.html#predicting-survival-curves",
    "href": "vignettes/survival.html#predicting-survival-curves",
    "title": "Survival Models",
    "section": "5 Predicting survival curves",
    "text": "5 Predicting survival curves\nOnce the models are fitted, we can predict survival probabilities based on the estimated parameters. In gamlss2, the predicted parameters from the model are used to compute survival probabilities. We then compare these with the survival probabilities obtained from the Kaplan-Meier estimate using survfit().\nIn the case of gamlss2, we extract the predicted parameters and compute the survival probabilities with\n\n## predict parameters from the gamlss2 model\npar &lt;- predict(b1, newdata = LeukSurv)\n\n## compute survival probabilities\np1 &lt;- 1 - family(b1)$p(Surv(LeukSurv$time, rep(1, nrow(LeukSurv))), par)\n\nFor the survfit() model, we use the step function to extract the survival probabilities at each time point.\n\n## step function for Kaplan-Meier survival estimates\nf &lt;- stepfun(s1$time, c(1, s1$surv))\np2 &lt;- f(LeukSurv$time)",
    "crumbs": [
      "Articles",
      "Survival Models"
    ]
  },
  {
    "objectID": "vignettes/survival.html#plotting-the-estimated-survival-curves",
    "href": "vignettes/survival.html#plotting-the-estimated-survival-curves",
    "title": "Survival Models",
    "section": "6 Plotting the estimated survival curves",
    "text": "6 Plotting the estimated survival curves\nFinally, we plot the estimated survival curves from both models to visually compare the results. This will allow us to see how the flexible parametric model from gamlss2 compares with the non-parametric Kaplan-Meier estimate.\n\nmatplot(LeukSurv$time, cbind(p1, p2),\n  type = \"l\", lty = 1, lwd = 3, col = c(1, 4),\n  xlab = \"Time\", ylab = \"Survival Prob(t &gt; Time)\",\n  main = \"Estimated Survival Curves\")\nlegend(\"topright\", c(\"gamlss2\", \"survfit\"),\n  lwd = 3, col = c(1, 4), bty = \"n\")\n\n\n\n\n\n\n\n\nIn this plot, we observe that the estimated survival curves are generally similar. However, the Kaplan-Meier estimate shows a slightly steeper decline in survival probabilities early on and flattens out more towards the end. This difference likely reflects the nature of the Kaplan-Meier estimator, which is non-parametric and purely empirical, capturing the observed data trends without any underlying assumptions about the distribution of survival times. In contrast, the parametric model from gamlss2 provides a more structured approach, allowing for smoother, distribution-driven survival estimates that incorporate the shape of the underlying Weibull distribution.",
    "crumbs": [
      "Articles",
      "Survival Models"
    ]
  },
  {
    "objectID": "vignettes/survival.html#spatial-survival-model",
    "href": "vignettes/survival.html#spatial-survival-model",
    "title": "Survival Models",
    "section": "7 Spatial survival model",
    "text": "7 Spatial survival model\nNext, we extend our analysis by estimating a full spatial survival model. This model incorporates both clinical covariates (such as age, sex, wbc, and tpi) and spatial information represented by the coordinates (xcoord and ycoord). The inclusion of spatial covariates allows us to assess potential geographic variation in survival probabilities, which could reveal spatial clustering or regional effects on survival outcomes.\nThe model is specified using the formula below, where the response is the censored survival time (Surv(time, cens)), and smooth terms (s()) are used to model nonlinear effects of continuous covariates like age, wbc, tpi, and the spatial coordinates. The pipe symbol (|) separates the formulas for the parameters of the distribution, allowing for flexible covariate effects on survival times.\n\n## model formula\nf &lt;- Surv(time, cens) ~ sex + s(age) + s(wbc) + s(tpi) + s(xcoord, ycoord) |\n  sex + s(age) + s(wbc) + s(tpi) + s(xcoord, ycoord)\n\n## estimate the spatial survival model\nb2 &lt;- gamlss2(f, family = fam, data = LeukSurv)\n\nGAMLSS-RS iteration  1: Global Deviance = 11869.8787 eps = 0.042038     \nGAMLSS-RS iteration  2: Global Deviance = 11866.6901 eps = 0.000268     \nGAMLSS-RS iteration  3: Global Deviance = 11866.619 eps = 0.000005",
    "crumbs": [
      "Articles",
      "Survival Models"
    ]
  },
  {
    "objectID": "vignettes/survival.html#visualizing-effects-residuals",
    "href": "vignettes/survival.html#visualizing-effects-residuals",
    "title": "Survival Models",
    "section": "8 Visualizing effects & residuals",
    "text": "8 Visualizing effects & residuals\nTo explore the impact of the covariates and spatial coordinates, we can plot the estimated effects from the model. This visualization helps us understand how each covariate, including the spatial effect, influences survival outcomes.\n\npar(mar = c(4, 4, 3, 1))\nplot(b2)\n\n\n\n\n\n\n\n\nTo assess the model fit, we generate diagnostic plots of the quantile residuals. These plots allow us to evaluate the adequacy of the model and check for any potential issues.\n\nplot(b2, which = \"resid\")\n\n\n\n\n\n\n\n\nThe plot suggests that the Weibull distribution is a reasonable choice for modeling the survival data. However, it is always advisable to explore alternative distributions to ensure the best possible model fit. In the GAMLSS framework, various other parametric distributions-such as the log-normal, gamma, or generalized gamma-can be easily tested to assess whether they provide a better fit to the data, especially if there are signs of deviations in the residuals or misspecification of the hazard function.",
    "crumbs": [
      "Articles",
      "Survival Models"
    ]
  },
  {
    "objectID": "vignettes/survival.html#visualize-the-spatial-effect.",
    "href": "vignettes/survival.html#visualize-the-spatial-effect.",
    "title": "Survival Models",
    "section": "9 Visualize the spatial effect.",
    "text": "9 Visualize the spatial effect.\n\n## read the map of new west england.\nfile &lt;- system.file(\"otherdata/nwengland.bnd\", package = \"spBayesSurv\")\nd &lt;- readLines(file)\n\n## transform the polygons to a list().\nid &lt;- grep('\\\"', d, fixed = TRUE)\npolys &lt;- list()\nfor(i in 1:length(id)) {\n  j &lt;- strsplit(d[id[i]], \",\")[[1]][2]\n  if(i &lt; length(id))\n    polys[[j]] &lt;- d[(id[i] + 1):(id[i + 1] - 1)]\n  else\n    polys[[j]] &lt;- d[(id[i] + 1):length(d)]\n}\n\npolys &lt;- lapply(polys, function(x) {\n  tf &lt;- tempfile()\n  writeLines(x, tf)\n  pol &lt;- as.matrix(read.csv(tf, header = FALSE))\n  unlink(tf)\n  return(st_polygon(list(pol)))\n})\n\n## transform to sf object\npolys_sfc &lt;- st_sfc(polys)\nmap &lt;- st_sf(geometry = polys_sfc)\nmap$id &lt;- names(polys)\nmap$district &lt;- 1:nrow(map)\n\n## plot the map\npar(mar = rep(0, 4))\nplot(st_geometry(map))\n\n\n\n\n\n\n\n\n\n## sample coordinates for plotting\nco &lt;- st_sample(map, size = 10000, type = \"regular\")\n\n## create new data for prediction\nnd &lt;- as.data.frame(st_coordinates(co))\nnames(nd) &lt;- c(\"xcoord\", \"ycoord\")\nnd$sex &lt;- 1\nnd$wbc &lt;- mean(LeukSurv$wbc)\nnd$tpi &lt;- mean(LeukSurv$tpi)\nnd$age &lt;- mean(LeukSurv$age)\n\n## predict parameters\npar &lt;- predict(b2, newdata = nd)\n\n## compute survival probabilities\np2 &lt;- 1 - family(b2)$p(Surv(rep(365, nrow(nd)), rep(1, nrow(nd))), par)\n\n## plot on map\nsp &lt;- st_sf(geometry = co)\nsp$survprob &lt;- p2\n\n## reference system, only used for plotting\nsp &lt;- st_set_crs(sp, 4326)\nmap &lt;- st_set_crs(map, 4326)\n\n## plot as raster map\nspr &lt;- st_as_stars(sp)\n\npar(mar = c(0, 0, 5, 0))\nplot(spr, main = \"Survival Probabilities Prob(t &gt; 365)\",\n  reset = FALSE, nbreaks = 100)\nplot(st_geometry(map), add = TRUE)\nbox()",
    "crumbs": [
      "Articles",
      "Survival Models"
    ]
  },
  {
    "objectID": "vignettes/topmodels.html#probabilistic-model-infrastructure",
    "href": "vignettes/topmodels.html#probabilistic-model-infrastructure",
    "title": "Forecasting and Assessment with topmodels",
    "section": "1 Probabilistic model infrastructure",
    "text": "1 Probabilistic model infrastructure\nIntroduction on how to use the topmodels package (topmodels?) with gamlss2.\nCurrently not on CRAN, yet, so install from R-universe (if not done already). The development version of gamlss.dist is also needed.\n\nif(!(\"topmodels\" %in% installed.packages())) {\n  install.packages(\"topmodels\", repos = \"https://zeileis.R-universe.dev\")\n}\nif(packageVersion(\"gamlss.dist\") &lt; \"6.1-3\") {\n  install.packages(\"gamlss.dist\", repos = \"https://gamlss-dev.R-universe.dev\")\n}\n\nOn GitHub, unfortunately, in the GitHub Action the gamlss.dist package is always taken from CRAN (via r-cran-gamlss.dist apparently).\n\npackageVersion(\"gamlss.dist\")\n\n[1] '6.1.1'\n\ngamlss_dist_devel &lt;- packageVersion(\"gamlss.dist\") &gt;= \"6.1-3\"",
    "crumbs": [
      "Articles",
      "Forecasting and Assessment with topmodels"
    ]
  },
  {
    "objectID": "vignettes/topmodels.html#data-and-models",
    "href": "vignettes/topmodels.html#data-and-models",
    "title": "Forecasting and Assessment with topmodels",
    "section": "2 Data and models",
    "text": "2 Data and models\n\nlibrary(\"gamlss2\")\ndata(\"HarzTraffic\", package = \"gamlss2\")\nm1 &lt;- lm(log(cars) ~ poly(yday, 3), data = HarzTraffic)\nm2 &lt;- gamlss2(log(cars) ~ s(yday, bs = \"cc\") | s(yday, bs = \"cc\"), data = HarzTraffic, family = SN2)",
    "crumbs": [
      "Articles",
      "Forecasting and Assessment with topmodels"
    ]
  },
  {
    "objectID": "vignettes/topmodels.html#probabilistic-forecasting",
    "href": "vignettes/topmodels.html#probabilistic-forecasting",
    "title": "Forecasting and Assessment with topmodels",
    "section": "3 Probabilistic forecasting",
    "text": "3 Probabilistic forecasting\n\nlibrary(\"topmodels\")\nnd &lt;- data.frame(yday = 1:365)\nnd &lt;- cbind(nd,\n  procast(m1, newdata = nd, type = \"quantile\", at = c(0.025, 0.5, 0.975)),\n  procast(m2, newdata = nd, type = \"quantile\", at = c(0.025, 0.5, 0.975)))\nplot(log(cars) ~ yday, data = HarzTraffic, type = \"n\")\npolygon(c(nd[[1]], rev(nd[[1]])), c(nd[[2]], rev(nd[[4]])),\n  col = adjustcolor(2, alpha.f = 0.4), border = \"transparent\")\npolygon(c(nd[[1]], rev(nd[[1]])), c(nd[[5]], rev(nd[[7]])),\n  col = adjustcolor(4, alpha.f = 0.4), border = \"transparent\")\npoints(log(cars) ~ yday, data = HarzTraffic)\nlines(nd[[1]], nd[[3]], col = 2, lwd = 2)\nlines(nd[[1]], nd[[6]], col = 4, lwd = 2)",
    "crumbs": [
      "Articles",
      "Forecasting and Assessment with topmodels"
    ]
  },
  {
    "objectID": "vignettes/topmodels.html#graphical-model-assessment",
    "href": "vignettes/topmodels.html#graphical-model-assessment",
    "title": "Forecasting and Assessment with topmodels",
    "section": "4 Graphical model assessment",
    "text": "4 Graphical model assessment\n\n4.1 Within model diagnostics\n\npar(mfrow = c(2, 2))\nrootogram(m1)\npithist(m1)\nqqrplot(m1)\nwormplot(m1)\n\n\npar(mfrow = c(2, 2))\nrootogram(m2)\npithist(m2)\nqqrplot(m2)\nwormplot(m2)\n\n\n\n4.2 Between Models diagnostics\n\npar(mfrow = c(1, 2))\np1 &lt;- pithist(m1, plot = FALSE)\np2 &lt;- pithist(m2, plot = FALSE)\nplot(c(p1, p2), col = c(2, 4), single_graph = TRUE, style = \"line\")\nw1 &lt;- wormplot(m1, plot = FALSE)\nw2 &lt;- wormplot(m2, plot = FALSE)\nplot(c(w1, w2), col = c(2, 4), single_graph = TRUE)",
    "crumbs": [
      "Articles",
      "Forecasting and Assessment with topmodels"
    ]
  },
  {
    "objectID": "vignettes/topmodels.html#scoring-rules",
    "href": "vignettes/topmodels.html#scoring-rules",
    "title": "Forecasting and Assessment with topmodels",
    "section": "5 Scoring rules",
    "text": "5 Scoring rules\n\nm &lt;- list(lm = m1, gamlss2 = m2)\nsapply(m, proscore, type = c(\"logs\", \"crps\", \"mae\", \"mse\", \"dss\"))\n\nMikis : can we do the same with newdata ?",
    "crumbs": [
      "Articles",
      "Forecasting and Assessment with topmodels"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "gamlss2: Infrastructure for Flexible Distributional Regression",
    "section": "",
    "text": "The development version of gamlss2 can be installed via\ninstall.packages(\"gamlss2\",\n  repos = c(\"https://gamlss-dev.R-universe.dev\", \"https://cloud.R-project.org\"))\n\n\n\nThe primary purpose of this package is to facilitate the creation of advanced infrastructures designed to enhance the GAMLSS modeling framework. Notably, the gamlss2 package represents a significant overhaul of its predecessor, gamlss, with a key emphasis on improving estimation speed and incorporating more flexible infrastructures. These enhancements enable the seamless integration of various algorithms into GAMLSS, including gradient boosting, Bayesian estimation, regression trees, and forests, fostering a more versatile and powerful modeling environment.\nMoreover, the package expands its compatibility by supporting all model terms from the base R mgcv package. Additionally, the gamlss2 package introduces the capability to accommodate more than four parameter families. Essentially, this means that users can now specify any type of model using these new infrastructures, making the package highly flexible and accommodating to a wide range of modeling requirements.\n\nThe main model function is gamlss2().\nThe default optimizer functions is RS(). Optimizer functions can be exchanged.\nMost important methods: summary(), plot(), predict().\nEasy development of new family objects, see ?family.gamlss2.\nUser-specific “special” terms are possible, see ?special_terms.\n\nFor examples, please visit the manual pages.\nhelp(package = \"gamlss2\")"
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "gamlss2: Infrastructure for Flexible Distributional Regression",
    "section": "",
    "text": "The development version of gamlss2 can be installed via\ninstall.packages(\"gamlss2\",\n  repos = c(\"https://gamlss-dev.R-universe.dev\", \"https://cloud.R-project.org\"))"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "gamlss2: Infrastructure for Flexible Distributional Regression",
    "section": "",
    "text": "The primary purpose of this package is to facilitate the creation of advanced infrastructures designed to enhance the GAMLSS modeling framework. Notably, the gamlss2 package represents a significant overhaul of its predecessor, gamlss, with a key emphasis on improving estimation speed and incorporating more flexible infrastructures. These enhancements enable the seamless integration of various algorithms into GAMLSS, including gradient boosting, Bayesian estimation, regression trees, and forests, fostering a more versatile and powerful modeling environment.\nMoreover, the package expands its compatibility by supporting all model terms from the base R mgcv package. Additionally, the gamlss2 package introduces the capability to accommodate more than four parameter families. Essentially, this means that users can now specify any type of model using these new infrastructures, making the package highly flexible and accommodating to a wide range of modeling requirements.\n\nThe main model function is gamlss2().\nThe default optimizer functions is RS(). Optimizer functions can be exchanged.\nMost important methods: summary(), plot(), predict().\nEasy development of new family objects, see ?family.gamlss2.\nUser-specific “special” terms are possible, see ?special_terms.\n\nFor examples, please visit the manual pages.\nhelp(package = \"gamlss2\")"
  },
  {
    "objectID": "man/predict.gamlss2.html",
    "href": "man/predict.gamlss2.html",
    "title": "gamlss2",
    "section": "",
    "text": "Methods for gamlss2 model objects for extracting fitted (in-sample) or predicted (out-of-sample) parameters, terms, etc.\n\n\n\n## S3 method for class 'gamlss2'\npredict(object, model = NULL, newdata = NULL,\n  type = c(\"parameter\", \"link\", \"response\", \"terms\"), terms = NULL,\n  se.fit = FALSE, drop = TRUE, ...)\n\n\n\n\n\n\n\nobject\n\n\nmodel object of class gamlss2.\n\n\n\n\nmodel\n\n\ncharacter. Which model part(s) should be predicted? Can be one or more of “mu”, “sigma”, etc. By default all model parts are included.\n\n\n\n\nnewdata\n\n\ndata.frame. Optionally, a new data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\ntype\n\n\ncharacter. Which type of prediction should be computed? Can be the full additive predictor(s) (“link”, before applying the link function(s)), the corresponding parameter (“parameter”, after applying the link function(s)), the individual terms of the additive predictor(s) (“terms”), or the corresponding mean of the response distribution (“response”).\n\n\n\n\nterms\n\n\ncharacter. Which of the terms in the additive predictor(s) should be included? By default all terms are included.\n\n\n\n\nse.fit\n\n\nlogical. Should standard errors for the predictions be included? (not implemented yet).\n\n\n\n\ndrop\n\n\nlogical. Should the predictions be simplified to a vector if possible (TRUE) or always returned as a data.frame (FALSE)?\n\n\n\n\n…\n\n\ncurrently only used for catching what as an alias for model.\n\n\n\n\n\n\nPredictions for gamlss2 model objects are obtained in the following steps: First, the original data is extracted or some newdata is set up. Second, all of the terms in the additive predictors of all model parameters (“mu”, “sigma”, …) are computed. Third, the full additive predictor(s) are obtained by adding up all individual terms. Fourth, the parameter(s) are obtained from the additive predictor(s) by applying the inverse link function(s). In a final step, the mean of the associated probability distribution can be computed.\nSee also prodist.gamlss2 for setting up a full distributions3 object from which moments, probabilities, quantiles, or random numbers can be obtained.\n\n\n\nIf drop = FALSE a data.frame. If drop = TRUE (the default), the data.frame might be simplified to a numeric vector, if possible.\n\n\n\npredict, prodist.gamlss2\n\n\n\n\nlibrary(\"gamlss2\")\n\n## fit heteroscedastic normal GAMLSS model\n## stopping distance (ft) explained by speed (mph)\ndata(\"cars\", package = \"datasets\")\nm &lt;- gamlss2(dist ~ s(speed) | s(speed), data = cars, family = NO)\n\nGAMLSS-RS iteration  1: Global Deviance = 407.3541 eps = 0.125497     \nGAMLSS-RS iteration  2: Global Deviance = 405.7146 eps = 0.004024     \nGAMLSS-RS iteration  3: Global Deviance = 405.6978 eps = 0.000041     \nGAMLSS-RS iteration  4: Global Deviance = 405.6976 eps = 0.000000     \n\n## new data for predictions\nnd &lt;- data.frame(speed = c(10, 20, 30))\n\n## default: additive predictors (on link scale) for all model parameters\npredict(m, newdata = nd)\n\n        mu    sigma\n1 23.03912 10.06300\n2 59.03607 18.51012\n3 96.34896 33.95078\n\n## mean of the response distribution\npredict(m, newdata = nd, type = \"response\")\n\n       1        2        3 \n23.03912 59.03607 96.34896 \n\n## model parameter(s)\npredict(m, newdata = nd)\n\n        mu    sigma\n1 23.03912 10.06300\n2 59.03607 18.51012\n3 96.34896 33.95078\n\npredict(m, newdata = nd, model = \"sigma\")\n\n       1        2        3 \n10.06300 18.51012 33.95078 \n\npredict(m, newdata = nd, model = \"sigma\", drop = FALSE)\n\n     sigma\n1 10.06300\n2 18.51012\n3 33.95078\n\n## individual terms in additive predictor(s)\npredict(m, newdata = nd, type = \"terms\", model = \"sigma\")\n\n  (Intercept)   s(speed)\n1    2.638039 -0.3291741\n2    2.638039  0.2802782\n3    2.638039  0.8868728\n\npredict(m, newdata = nd, type = \"terms\", model = \"sigma\", terms = \"s(speed)\")\n\n    s(speed)\n1 -0.3291741\n2  0.2802782\n3  0.8868728",
    "crumbs": [
      "Reference",
      "predict.gamlss2"
    ]
  },
  {
    "objectID": "man/predict.gamlss2.html#extracting-fitted-or-predicted-parameters-or-terms-from-gamlss2-models",
    "href": "man/predict.gamlss2.html#extracting-fitted-or-predicted-parameters-or-terms-from-gamlss2-models",
    "title": "gamlss2",
    "section": "",
    "text": "Methods for gamlss2 model objects for extracting fitted (in-sample) or predicted (out-of-sample) parameters, terms, etc.\n\n\n\n## S3 method for class 'gamlss2'\npredict(object, model = NULL, newdata = NULL,\n  type = c(\"parameter\", \"link\", \"response\", \"terms\"), terms = NULL,\n  se.fit = FALSE, drop = TRUE, ...)\n\n\n\n\n\n\n\nobject\n\n\nmodel object of class gamlss2.\n\n\n\n\nmodel\n\n\ncharacter. Which model part(s) should be predicted? Can be one or more of “mu”, “sigma”, etc. By default all model parts are included.\n\n\n\n\nnewdata\n\n\ndata.frame. Optionally, a new data frame in which to look for variables with which to predict. If omitted, the original observations are used.\n\n\n\n\ntype\n\n\ncharacter. Which type of prediction should be computed? Can be the full additive predictor(s) (“link”, before applying the link function(s)), the corresponding parameter (“parameter”, after applying the link function(s)), the individual terms of the additive predictor(s) (“terms”), or the corresponding mean of the response distribution (“response”).\n\n\n\n\nterms\n\n\ncharacter. Which of the terms in the additive predictor(s) should be included? By default all terms are included.\n\n\n\n\nse.fit\n\n\nlogical. Should standard errors for the predictions be included? (not implemented yet).\n\n\n\n\ndrop\n\n\nlogical. Should the predictions be simplified to a vector if possible (TRUE) or always returned as a data.frame (FALSE)?\n\n\n\n\n…\n\n\ncurrently only used for catching what as an alias for model.\n\n\n\n\n\n\nPredictions for gamlss2 model objects are obtained in the following steps: First, the original data is extracted or some newdata is set up. Second, all of the terms in the additive predictors of all model parameters (“mu”, “sigma”, …) are computed. Third, the full additive predictor(s) are obtained by adding up all individual terms. Fourth, the parameter(s) are obtained from the additive predictor(s) by applying the inverse link function(s). In a final step, the mean of the associated probability distribution can be computed.\nSee also prodist.gamlss2 for setting up a full distributions3 object from which moments, probabilities, quantiles, or random numbers can be obtained.\n\n\n\nIf drop = FALSE a data.frame. If drop = TRUE (the default), the data.frame might be simplified to a numeric vector, if possible.\n\n\n\npredict, prodist.gamlss2\n\n\n\n\nlibrary(\"gamlss2\")\n\n## fit heteroscedastic normal GAMLSS model\n## stopping distance (ft) explained by speed (mph)\ndata(\"cars\", package = \"datasets\")\nm &lt;- gamlss2(dist ~ s(speed) | s(speed), data = cars, family = NO)\n\nGAMLSS-RS iteration  1: Global Deviance = 407.3541 eps = 0.125497     \nGAMLSS-RS iteration  2: Global Deviance = 405.7146 eps = 0.004024     \nGAMLSS-RS iteration  3: Global Deviance = 405.6978 eps = 0.000041     \nGAMLSS-RS iteration  4: Global Deviance = 405.6976 eps = 0.000000     \n\n## new data for predictions\nnd &lt;- data.frame(speed = c(10, 20, 30))\n\n## default: additive predictors (on link scale) for all model parameters\npredict(m, newdata = nd)\n\n        mu    sigma\n1 23.03912 10.06300\n2 59.03607 18.51012\n3 96.34896 33.95078\n\n## mean of the response distribution\npredict(m, newdata = nd, type = \"response\")\n\n       1        2        3 \n23.03912 59.03607 96.34896 \n\n## model parameter(s)\npredict(m, newdata = nd)\n\n        mu    sigma\n1 23.03912 10.06300\n2 59.03607 18.51012\n3 96.34896 33.95078\n\npredict(m, newdata = nd, model = \"sigma\")\n\n       1        2        3 \n10.06300 18.51012 33.95078 \n\npredict(m, newdata = nd, model = \"sigma\", drop = FALSE)\n\n     sigma\n1 10.06300\n2 18.51012\n3 33.95078\n\n## individual terms in additive predictor(s)\npredict(m, newdata = nd, type = \"terms\", model = \"sigma\")\n\n  (Intercept)   s(speed)\n1    2.638039 -0.3291741\n2    2.638039  0.2802782\n3    2.638039  0.8868728\n\npredict(m, newdata = nd, type = \"terms\", model = \"sigma\", terms = \"s(speed)\")\n\n    s(speed)\n1 -0.3291741\n2  0.2802782\n3  0.8868728",
    "crumbs": [
      "Reference",
      "predict.gamlss2"
    ]
  },
  {
    "objectID": "man/special_terms.html",
    "href": "man/special_terms.html",
    "title": "gamlss2",
    "section": "",
    "text": "The gamlss2 package provides infrastructure to include special model terms for the optimizer functions RS and CG, e.g., such as neural networks, trees and forests. The infrastructure assumes that such special model terms provide their own fitting and predict method.\n\n\n\n## Generic fitting method.\nspecial_fit(x, ...)\n\n## Generic predict method.\nspecial_predict(x, ...)\n\n## Extractor function for fitted special terms.\nspecials(object, model = NULL, terms = NULL, elements = NULL, ...)\n\n\n\n\n\n\n\nx\n\n\nA model term object as supplied in the formula in the gamlss2 call.\n\n\n\n\nobject\n\n\nA fitted gamlss2 object.\n\n\n\n\nmodel\n\n\nCharacter or integer, specifies the model for which fitted special terms should be extracted.\n\n\n\n\nterms\n\n\nCharacter or integer, specifies the special model terms that should be extracted.\n\n\n\n\nelements\n\n\nCharacter, specifies which elements of a fitted special term should be extracted. If elements = “names”, the corresponding element names are extracted.\n\n\n\n\n…\n\n\nArguments needed for the special_fit() function to facilitate the fitting of the model term, see the details. Similarly, for the special_predict() function, the … argument encompasses the objects for computing predictions for the model term.\n\n\n\n\n\n\nTo implement a new special term, the first step is to write a formula constructor function for the new model term. For example, consider the implementation below, which demonstrates how to create a neural network model term. Additionally, the name of the new model term constructor must be passed to the specials argument of the function fake_formula. Please note that in the provided example, no new special name is passed because “n” is already registered in fake_formula.\nAfterwards, a fitting and a predict method for the new special model term needs to be implemented. Please also refer to the example below, implementing these functions for a neural network model term.\nThe following describes the detailed arguments and return values.\nA method for special_fit() has the following arguments:\n\n\nx: The special model term object, containing all the data for fitting.\n\n\nz: The current working response/residual from the backfitting step.\n\n\nw: The current working weights from the backfitting step.\n\n\ny: The response vector/matrix, e.g., used to evaluate the log-likelihood.\n\n\neta: The current named list of predictors.\n\n\nj: Character, the parameter name for which the model term needs to be updated.\n\n\nfamily: The family object of the model, see gamlss2.family.\n\n\ncontrol: A named list of control arguments, see gamlss2_control.\n\n\nNote that for setting up a special model term only the first three arguments a mandatory, all other arguments are optional. The function must at least return a named list containing the “fitted.values” to work with RS and CG.\nA method for special_predict() has the following arguments:\n\n\nx: Depending on the return value of function special_fit(), the fitted model term object, see the examples.\n\n\ndata: The data for which predictions should be computed.\n\n\nse.fit: Logical, should standard errors of the predictions be computed.\n\n\nNote that function special_predict() should return a data frame with named colums “fit”, “lower” and “upper”, “lower” and “upper” are optional.\n\n\n\ngamlss2, RS, gamlss2_control, gamlss2.family\n\n\n\n\nlibrary(\"gamlss2\")\n\n\n## example special term for neural networks,\n## the constructor function is used in the formula\n## when calling gamlss2()\nn &lt;- function(formula, ...)\n{\n  stopifnot(requireNamespace(\"nnet\"))\n\n  ## list for setting up the special model term\n  st &lt;- list()\n\n  ## list of control arguments\n  ctr &lt;- list(...)\n  if(is.null(ctr$size))\n    ctr$size &lt;- 50\n  if(is.null(ctr$maxit))\n    ctr$maxit &lt;- 1000\n  if(is.null(ctr$decay))\n    ctr$decay &lt;- 0.1\n  if(is.null(ctr$trace))\n    ctr$trace &lt;- FALSE\n  if(is.null(ctr$MaxNWts))\n    ctr$MaxNWts &lt;- 10000\n  if(is.null(ctr$scale))\n    ctr$scale &lt;- TRUE\n\n  ## put all information together\n  st$control &lt;- ctr\n  st$formula &lt;- formula\n  st$term &lt;- all.vars(formula)\n  st$label &lt;- paste0(\"n(\", paste0(gsub(\" \", \"\", as.character(formula)), collapse = \"\"), \")\")\n  st$data &lt;- model.frame(formula)\n\n  ## scale per default!\n  if(ctr$scale) {\n    sx &lt;- list()\n    for(j in colnames(st$data)) {\n      if(!is.factor(st$data[[j]])) {\n        sx[[j]] &lt;- range(st$data[[j]])\n        st$data[[j]] &lt;- (st$data[[j]] - sx[[j]][1]) / diff(sx[[j]])\n      }\n    }\n    st$scalex &lt;- sx\n  }\n\n  ## assign the \"special\" class and the new class \"n\"\n  class(st) &lt;- c(\"special\", \"n\")\n\n  return(st)\n}\n\n## set up the special \"n\" model term fitting function\nspecial_fit.n &lt;- function(x, z, w, control, ...)\n{\n  ## model formula needs to be updated\n  .fnns &lt;- update(x$formula, response_z ~ .)\n\n  ## assign current working response\n  x$data$response_z &lt;- z\n  x$data$weights_w &lt;- w\n\n  ## possible weights from last iteration\n  Wts &lt;- list(...)$transfer$Wts\n\n  ## estimate model\n  nnc &lt;- parse(text = paste0('nnet::nnet(formula = .fnns, data = x$data, weights = weights_w,',\n      'size = x$control$size, maxit = x$control$maxit, decay = x$control$decay,',\n      'trace = x$control$trace, MaxNWts = x$control$MaxNWts, linout = TRUE',\n      if(!is.null(Wts)) ', Wts = Wts)' else ')'))\n\n  rval &lt;- list(\"model\" = eval(nnc))\n\n  ## get the fitted.values\n  rval$fitted.values &lt;- predict(rval$model)\n\n  ## transferring the weights for the next backfitting iteration\n  ## note, \"transfer\" can be used to transfer anything from one\n  ## iteration to the next\n  rval$transfer &lt;- list(\"Wts\" = rval$model$wts)\n\n  ## center fitted values\n  rval$shift &lt;- mean(rval$fitted.values)\n  rval$fitted.values &lt;- rval$fitted.values - rval$shift\n\n  ## degrees of freedom\n  rval$edf &lt;- length(coef(rval$model))\n\n  ## possible scaling\n  rval$scalex &lt;- x$scalex\n\n  ## assign class for predict method\n  class(rval) &lt;- \"n.fitted\"\n\n  return(rval)\n}\n\n## finally, the predict method\nspecial_predict.n.fitted &lt;- function(x, data, se.fit = FALSE, ...)\n{\n  if(!is.null(x$scalex)) {\n    for(j in names(x$scalex)) {\n      data[[j]] &lt;- (data[[j]] - x$scalex[[j]][1]) / diff(x$scalex[[j]])\n    }\n  }\n  p &lt;- predict(x$model, newdata = data, type = \"raw\")\n  p &lt;- p - x$shift\n  if(se.fit)\n    p &lt;- data.frame(\"fit\" = p)\n  return(p)\n}\n\ndata(\"abdom\", package = \"gamlss.data\")\n\n## specify the model Formula\nf &lt;- y ~ n(~x) | n(~x) | n(~x) | n(~x)\n\n## estimate model,\n## set the seed for reproducibility\n## note, data should be scaled!\nset.seed(123)\nb &lt;- gamlss2(f, data = abdom, family = BCT)\n\n## visualize estimated effects\nplot(b, which = \"effects\")\n\n## plot diagnostics\nplot(b, which = \"resid\")\n\n## predict parameters\npar &lt;- predict(b)\n\n## predict quantiles\npq &lt;- sapply(c(0.05, 0.5, 0.95), function(q) family(b)$q(q, par))\n\n## plot\nplot(y ~ x, data = abdom, pch = 19,\n  col = rgb(0.1, 0.1, 0.1, alpha = 0.3))\nmatplot(abdom$x, pq, type = \"l\", lwd = 2,\n  lty = 1, col = 4, add = TRUE)\n\n## another example using the Munich rent data\ndata(\"rent\", package = \"gamlss.data\")\n\n## model Formula\nf &lt;- R ~ n(~Fl+A,size=10,decay=0.7) | n(~Fl+A,size=10,decay=0.7)\n\n## estimate model\nset.seed(456)\nb &lt;- gamlss2(f, data = rent, family = GA)\n\n## plot estimated effects\nplot(b, which = \"effects\", persp = FALSE)\n\n## diagnostics\nplot(b, which = \"resid\")\n\n## predict using new data\nn &lt;- 50\nnd &lt;- with(rent, expand.grid(\n  \"Fl\" = seq(min(Fl), max(Fl), length = n),\n  \"A\" = seq(min(A), max(A), length = n)\n))\n\n## predict parameters of the GA distribution\npar &lt;- predict(b, newdata = nd)\n\n## compute median rent R estimate\nnd$fit &lt;- family(b)$q(0.5, par)\n\n## visualize\nlibrary(\"lattice\")\n\np1 &lt;- wireframe(fit ~ Fl + A, data = nd,\n  screen = list(z = 50, x = -70, y = -10),\n  aspect = c(1, 0.9), drape = TRUE,\n  main = \"n(~Fl+A)\",\n  xlab = \"Floor\", ylab = \"YoC\",\n  zlab = \"Rent\")\n\np2 &lt;- levelplot(fit ~ Fl + A, data = nd,\n  contour = TRUE,\n  main = \"n(~Fl+A)\", xlab = \"Floor\", ylab = \"YoC\")\n\nprint(p1, split = c(1, 1, 2, 1), more = TRUE)\nprint(p2, split = c(2, 1, 2, 1), more = FALSE)\n\n## extract fitted special terms,\n## fitted NN for parameter mu\nspecials(b, model = \"mu\", elements = \"model\")\n\n## same for sigma\nspecials(b, model = \"sigma\", elements = \"model\")\n\n## return element names of fitted special term list\nspecials(b, model = \"sigma\", elements = \"names\")",
    "crumbs": [
      "Reference",
      "special_terms"
    ]
  },
  {
    "objectID": "man/special_terms.html#special-model-terms-for-gamlss",
    "href": "man/special_terms.html#special-model-terms-for-gamlss",
    "title": "gamlss2",
    "section": "",
    "text": "The gamlss2 package provides infrastructure to include special model terms for the optimizer functions RS and CG, e.g., such as neural networks, trees and forests. The infrastructure assumes that such special model terms provide their own fitting and predict method.\n\n\n\n## Generic fitting method.\nspecial_fit(x, ...)\n\n## Generic predict method.\nspecial_predict(x, ...)\n\n## Extractor function for fitted special terms.\nspecials(object, model = NULL, terms = NULL, elements = NULL, ...)\n\n\n\n\n\n\n\nx\n\n\nA model term object as supplied in the formula in the gamlss2 call.\n\n\n\n\nobject\n\n\nA fitted gamlss2 object.\n\n\n\n\nmodel\n\n\nCharacter or integer, specifies the model for which fitted special terms should be extracted.\n\n\n\n\nterms\n\n\nCharacter or integer, specifies the special model terms that should be extracted.\n\n\n\n\nelements\n\n\nCharacter, specifies which elements of a fitted special term should be extracted. If elements = “names”, the corresponding element names are extracted.\n\n\n\n\n…\n\n\nArguments needed for the special_fit() function to facilitate the fitting of the model term, see the details. Similarly, for the special_predict() function, the … argument encompasses the objects for computing predictions for the model term.\n\n\n\n\n\n\nTo implement a new special term, the first step is to write a formula constructor function for the new model term. For example, consider the implementation below, which demonstrates how to create a neural network model term. Additionally, the name of the new model term constructor must be passed to the specials argument of the function fake_formula. Please note that in the provided example, no new special name is passed because “n” is already registered in fake_formula.\nAfterwards, a fitting and a predict method for the new special model term needs to be implemented. Please also refer to the example below, implementing these functions for a neural network model term.\nThe following describes the detailed arguments and return values.\nA method for special_fit() has the following arguments:\n\n\nx: The special model term object, containing all the data for fitting.\n\n\nz: The current working response/residual from the backfitting step.\n\n\nw: The current working weights from the backfitting step.\n\n\ny: The response vector/matrix, e.g., used to evaluate the log-likelihood.\n\n\neta: The current named list of predictors.\n\n\nj: Character, the parameter name for which the model term needs to be updated.\n\n\nfamily: The family object of the model, see gamlss2.family.\n\n\ncontrol: A named list of control arguments, see gamlss2_control.\n\n\nNote that for setting up a special model term only the first three arguments a mandatory, all other arguments are optional. The function must at least return a named list containing the “fitted.values” to work with RS and CG.\nA method for special_predict() has the following arguments:\n\n\nx: Depending on the return value of function special_fit(), the fitted model term object, see the examples.\n\n\ndata: The data for which predictions should be computed.\n\n\nse.fit: Logical, should standard errors of the predictions be computed.\n\n\nNote that function special_predict() should return a data frame with named colums “fit”, “lower” and “upper”, “lower” and “upper” are optional.\n\n\n\ngamlss2, RS, gamlss2_control, gamlss2.family\n\n\n\n\nlibrary(\"gamlss2\")\n\n\n## example special term for neural networks,\n## the constructor function is used in the formula\n## when calling gamlss2()\nn &lt;- function(formula, ...)\n{\n  stopifnot(requireNamespace(\"nnet\"))\n\n  ## list for setting up the special model term\n  st &lt;- list()\n\n  ## list of control arguments\n  ctr &lt;- list(...)\n  if(is.null(ctr$size))\n    ctr$size &lt;- 50\n  if(is.null(ctr$maxit))\n    ctr$maxit &lt;- 1000\n  if(is.null(ctr$decay))\n    ctr$decay &lt;- 0.1\n  if(is.null(ctr$trace))\n    ctr$trace &lt;- FALSE\n  if(is.null(ctr$MaxNWts))\n    ctr$MaxNWts &lt;- 10000\n  if(is.null(ctr$scale))\n    ctr$scale &lt;- TRUE\n\n  ## put all information together\n  st$control &lt;- ctr\n  st$formula &lt;- formula\n  st$term &lt;- all.vars(formula)\n  st$label &lt;- paste0(\"n(\", paste0(gsub(\" \", \"\", as.character(formula)), collapse = \"\"), \")\")\n  st$data &lt;- model.frame(formula)\n\n  ## scale per default!\n  if(ctr$scale) {\n    sx &lt;- list()\n    for(j in colnames(st$data)) {\n      if(!is.factor(st$data[[j]])) {\n        sx[[j]] &lt;- range(st$data[[j]])\n        st$data[[j]] &lt;- (st$data[[j]] - sx[[j]][1]) / diff(sx[[j]])\n      }\n    }\n    st$scalex &lt;- sx\n  }\n\n  ## assign the \"special\" class and the new class \"n\"\n  class(st) &lt;- c(\"special\", \"n\")\n\n  return(st)\n}\n\n## set up the special \"n\" model term fitting function\nspecial_fit.n &lt;- function(x, z, w, control, ...)\n{\n  ## model formula needs to be updated\n  .fnns &lt;- update(x$formula, response_z ~ .)\n\n  ## assign current working response\n  x$data$response_z &lt;- z\n  x$data$weights_w &lt;- w\n\n  ## possible weights from last iteration\n  Wts &lt;- list(...)$transfer$Wts\n\n  ## estimate model\n  nnc &lt;- parse(text = paste0('nnet::nnet(formula = .fnns, data = x$data, weights = weights_w,',\n      'size = x$control$size, maxit = x$control$maxit, decay = x$control$decay,',\n      'trace = x$control$trace, MaxNWts = x$control$MaxNWts, linout = TRUE',\n      if(!is.null(Wts)) ', Wts = Wts)' else ')'))\n\n  rval &lt;- list(\"model\" = eval(nnc))\n\n  ## get the fitted.values\n  rval$fitted.values &lt;- predict(rval$model)\n\n  ## transferring the weights for the next backfitting iteration\n  ## note, \"transfer\" can be used to transfer anything from one\n  ## iteration to the next\n  rval$transfer &lt;- list(\"Wts\" = rval$model$wts)\n\n  ## center fitted values\n  rval$shift &lt;- mean(rval$fitted.values)\n  rval$fitted.values &lt;- rval$fitted.values - rval$shift\n\n  ## degrees of freedom\n  rval$edf &lt;- length(coef(rval$model))\n\n  ## possible scaling\n  rval$scalex &lt;- x$scalex\n\n  ## assign class for predict method\n  class(rval) &lt;- \"n.fitted\"\n\n  return(rval)\n}\n\n## finally, the predict method\nspecial_predict.n.fitted &lt;- function(x, data, se.fit = FALSE, ...)\n{\n  if(!is.null(x$scalex)) {\n    for(j in names(x$scalex)) {\n      data[[j]] &lt;- (data[[j]] - x$scalex[[j]][1]) / diff(x$scalex[[j]])\n    }\n  }\n  p &lt;- predict(x$model, newdata = data, type = \"raw\")\n  p &lt;- p - x$shift\n  if(se.fit)\n    p &lt;- data.frame(\"fit\" = p)\n  return(p)\n}\n\ndata(\"abdom\", package = \"gamlss.data\")\n\n## specify the model Formula\nf &lt;- y ~ n(~x) | n(~x) | n(~x) | n(~x)\n\n## estimate model,\n## set the seed for reproducibility\n## note, data should be scaled!\nset.seed(123)\nb &lt;- gamlss2(f, data = abdom, family = BCT)\n\n## visualize estimated effects\nplot(b, which = \"effects\")\n\n## plot diagnostics\nplot(b, which = \"resid\")\n\n## predict parameters\npar &lt;- predict(b)\n\n## predict quantiles\npq &lt;- sapply(c(0.05, 0.5, 0.95), function(q) family(b)$q(q, par))\n\n## plot\nplot(y ~ x, data = abdom, pch = 19,\n  col = rgb(0.1, 0.1, 0.1, alpha = 0.3))\nmatplot(abdom$x, pq, type = \"l\", lwd = 2,\n  lty = 1, col = 4, add = TRUE)\n\n## another example using the Munich rent data\ndata(\"rent\", package = \"gamlss.data\")\n\n## model Formula\nf &lt;- R ~ n(~Fl+A,size=10,decay=0.7) | n(~Fl+A,size=10,decay=0.7)\n\n## estimate model\nset.seed(456)\nb &lt;- gamlss2(f, data = rent, family = GA)\n\n## plot estimated effects\nplot(b, which = \"effects\", persp = FALSE)\n\n## diagnostics\nplot(b, which = \"resid\")\n\n## predict using new data\nn &lt;- 50\nnd &lt;- with(rent, expand.grid(\n  \"Fl\" = seq(min(Fl), max(Fl), length = n),\n  \"A\" = seq(min(A), max(A), length = n)\n))\n\n## predict parameters of the GA distribution\npar &lt;- predict(b, newdata = nd)\n\n## compute median rent R estimate\nnd$fit &lt;- family(b)$q(0.5, par)\n\n## visualize\nlibrary(\"lattice\")\n\np1 &lt;- wireframe(fit ~ Fl + A, data = nd,\n  screen = list(z = 50, x = -70, y = -10),\n  aspect = c(1, 0.9), drape = TRUE,\n  main = \"n(~Fl+A)\",\n  xlab = \"Floor\", ylab = \"YoC\",\n  zlab = \"Rent\")\n\np2 &lt;- levelplot(fit ~ Fl + A, data = nd,\n  contour = TRUE,\n  main = \"n(~Fl+A)\", xlab = \"Floor\", ylab = \"YoC\")\n\nprint(p1, split = c(1, 1, 2, 1), more = TRUE)\nprint(p2, split = c(2, 1, 2, 1), more = FALSE)\n\n## extract fitted special terms,\n## fitted NN for parameter mu\nspecials(b, model = \"mu\", elements = \"model\")\n\n## same for sigma\nspecials(b, model = \"sigma\", elements = \"model\")\n\n## return element names of fitted special term list\nspecials(b, model = \"sigma\", elements = \"names\")",
    "crumbs": [
      "Reference",
      "special_terms"
    ]
  },
  {
    "objectID": "man/random.html",
    "href": "man/random.html",
    "title": "gamlss2",
    "section": "",
    "text": "There are two ways of fitting a random effect within gamlss2. The first, using s(), is for a simple random effect, that is, when only one factor is entered the model as a smoother. This method uses the function s() of the package mgcv with argument bs = “re”. For example, if area is factor with several levels, s(area, bs = “re”) will sringh the levels of area towards their mean level. The second, more general way, allows to fit more complicated random effect models using the function re(). The function re() is an interface connecting gamlss2 with the specialised package for random effects nlme.\nHere we document only the re() function only but we also give examples using s(…, bs = “re”).\n\n\n\nre(fixed =~ 1, random = NULL, ...)\n\n\n\n\n\n\n\nfixed\n\n\nA formula that specifies the fixed effects of the nlme{lme} model. In most cases, this can also be included in the gamlss2 parameter formula.\n\n\n\n\nrandom\n\n\nA formula specifying the random effect part of the model, as in the nlme{lme()} function.\n\n\n\n\n…\n\n\nFor the re() function, the dots argument is used to specify additional control arguments for the nlme{lme} function, such as the method and correlation arguments.\n\n\n\n\n\n\nBoth functions set up model terms that can be estimated using a backfitting algorithm, e.g., the default RS algorithm.\n\n\n\nFunction s with bs = “re” returns a smooth specification object of class “re.smooth.spec”, see also smooth.construct.re.smooth.spec.\nThe re() function returns a special model term specification object, see specials for details.\n\n\n\ngamlss2, smooth.construct.re.smooth.spec, s, lme\n\n\n\n\nlibrary(\"gamlss2\")\n\n\n\n\n## orthdontic measurement data\ndata(\"Orthodont\", package = \"nlme\")\n\n## model using lme()\nm &lt;- lme(distance ~ I(age-11), data = Orthodont,\n  random =~ I(age-11) | Subject, method = \"ML\")\n\n## using re(), function I() is not supported,\n## please transform all variables in advance\nOrthodont$age11  &lt;- Orthodont$age - 11\n\n## estimation using the re() constructor\nb &lt;- gamlss2(distance ~ s(age,k=3) + re(random =~ age11 | Subject),\n  data = Orthodont)\n\nGAMLSS-RS iteration  1: Global Deviance = 326.6569 eps = 0.392363     \nGAMLSS-RS iteration  2: Global Deviance = 326.0931 eps = 0.001726     \nGAMLSS-RS iteration  3: Global Deviance = 326.0758 eps = 0.000053     \nGAMLSS-RS iteration  4: Global Deviance = 326.0757 eps = 0.000000     \n\n## compare fitted values\nplot(fitted(b, model = \"mu\"), fitted(m))\nabline(0, 1, col = 4)\n\n\n\n\n\n\n\n## extract summary for re() model term\nst &lt;- specials(b, model = \"mu\", elements = \"model\")\nsummary(st)\n\n                             Length Class  Mode\nmu.s(age)                     9     -none- list\nmu.re(random=~age11|Subject) 19     lme    list\n\n## random intercepts and slopes with s() using AIC\na &lt;- gamlss2(distance ~ s(age,k=3) + s(Subject, bs = \"re\") + s(Subject, age11, bs = \"re\"),\n  data = Orthodont)\n\nGAMLSS-RS iteration  1: Global Deviance = 427.3879 eps = 0.204987     \nGAMLSS-RS iteration  2: Global Deviance = 370.2269 eps = 0.133744     \nGAMLSS-RS iteration  3: Global Deviance = 340.2986 eps = 0.080837     \nGAMLSS-RS iteration  4: Global Deviance = 325.4086 eps = 0.043755     \nGAMLSS-RS iteration  5: Global Deviance = 319.3603 eps = 0.018586     \nGAMLSS-RS iteration  6: Global Deviance = 316.706 eps = 0.008311     \nGAMLSS-RS iteration  7: Global Deviance = 315.7332 eps = 0.003071     \nGAMLSS-RS iteration  8: Global Deviance = 315.3835 eps = 0.001107     \nGAMLSS-RS iteration  9: Global Deviance = 315.2588 eps = 0.000395     \nGAMLSS-RS iteration 10: Global Deviance = 315.2156 eps = 0.000137     \nGAMLSS-RS iteration 11: Global Deviance = 315.2007 eps = 0.000047     \nGAMLSS-RS iteration 12: Global Deviance = 315.1956 eps = 0.000016     \nGAMLSS-RS iteration 13: Global Deviance = 315.1933 eps = 0.000007     \n\n## compare fitted values\nplot(fitted(b, model = \"mu\"), fitted(m))\npoints(fitted(a, model = \"mu\"), fitted(m), col = 2)\nabline(0, 1, col = 4)\n\n\n\n\n\n\n\n## more complicated correlation structures.\ndata(\"Ovary\", package = \"nlme\")\n\n## ARMA model\nm &lt;- lme(follicles ~ sin(2 * pi * Time) + cos(2 * pi * Time), data = Ovary, \n  random = pdDiag(~sin(2*pi*Time)), correlation = corARMA(q = 2))\n\n## now with gamlss2(), transform in advance\nOvary$sin1 &lt;- sin(2 * pi * Ovary$Time)\nOvary$cos1 &lt;- cos(2 * pi * Ovary$Time)\n\n## model formula\nf &lt;- follicles ~ s(Time) + re(random =~ sin1 | Mare,\n  correlation = corARMA(q = 2), control = lmeControl(maxIter = 100))\n\n## estimate model\nb &lt;- gamlss2(f, data = Ovary)\n\nGAMLSS-RS iteration  1: Global Deviance = 1553.7576 eps = 0.168812     \nGAMLSS-RS iteration  2: Global Deviance = 1550.0142 eps = 0.002409     \nGAMLSS-RS iteration  3: Global Deviance = 1549.9734 eps = 0.000026     \nGAMLSS-RS iteration  4: Global Deviance = 1549.9731 eps = 0.000000     \n\n## smooth random effects\nf &lt;- follicles ~ ti(Time) + ti(Mare, bs = \"re\") + \n  ti(Mare, Time, bs = c(\"re\", \"cr\"), k = c(11, 5))\n\ng &lt;- gamlss2(f, data = Ovary)\n\nGAMLSS-RS iteration  1: Global Deviance = 1522.1007 eps = 0.185747     \nGAMLSS-RS iteration  2: Global Deviance = 1436.4746 eps = 0.056255     \nGAMLSS-RS iteration  3: Global Deviance = 1426.662 eps = 0.006831     \nGAMLSS-RS iteration  4: Global Deviance = 1425.7706 eps = 0.000624     \nGAMLSS-RS iteration  5: Global Deviance = 1425.692 eps = 0.000055     \nGAMLSS-RS iteration  6: Global Deviance = 1425.6854 eps = 0.000004     \n\n## compare fitted values\npar(mfrow = n2mfrow(nlevels(Ovary$Mare)), mar = c(4, 4, 1, 1))\n\nfor(j in levels(Ovary$Mare)) {\n  ds &lt;- subset(Ovary, Mare == j)\n\n  plot(follicles ~ Time, data = ds)\n\n  f &lt;- fitted(b, model = \"mu\")[Ovary$Mare == j]\n  lines(f ~ ds$Time, col = 4, lwd = 2)\n\n  f &lt;- fitted(g, model = \"mu\")[Ovary$Mare == j]\n  lines(f ~ ds$Time, col = 3, lwd = 2)\n\n  f &lt;- fitted(m)[Ovary$Mare == j]\n  lines(f ~ ds$Time, col = 2, lwd = 2)\n }",
    "crumbs": [
      "Reference",
      "random"
    ]
  },
  {
    "objectID": "man/random.html#random-effects",
    "href": "man/random.html#random-effects",
    "title": "gamlss2",
    "section": "",
    "text": "There are two ways of fitting a random effect within gamlss2. The first, using s(), is for a simple random effect, that is, when only one factor is entered the model as a smoother. This method uses the function s() of the package mgcv with argument bs = “re”. For example, if area is factor with several levels, s(area, bs = “re”) will sringh the levels of area towards their mean level. The second, more general way, allows to fit more complicated random effect models using the function re(). The function re() is an interface connecting gamlss2 with the specialised package for random effects nlme.\nHere we document only the re() function only but we also give examples using s(…, bs = “re”).\n\n\n\nre(fixed =~ 1, random = NULL, ...)\n\n\n\n\n\n\n\nfixed\n\n\nA formula that specifies the fixed effects of the nlme{lme} model. In most cases, this can also be included in the gamlss2 parameter formula.\n\n\n\n\nrandom\n\n\nA formula specifying the random effect part of the model, as in the nlme{lme()} function.\n\n\n\n\n…\n\n\nFor the re() function, the dots argument is used to specify additional control arguments for the nlme{lme} function, such as the method and correlation arguments.\n\n\n\n\n\n\nBoth functions set up model terms that can be estimated using a backfitting algorithm, e.g., the default RS algorithm.\n\n\n\nFunction s with bs = “re” returns a smooth specification object of class “re.smooth.spec”, see also smooth.construct.re.smooth.spec.\nThe re() function returns a special model term specification object, see specials for details.\n\n\n\ngamlss2, smooth.construct.re.smooth.spec, s, lme\n\n\n\n\nlibrary(\"gamlss2\")\n\n\n\n\n## orthdontic measurement data\ndata(\"Orthodont\", package = \"nlme\")\n\n## model using lme()\nm &lt;- lme(distance ~ I(age-11), data = Orthodont,\n  random =~ I(age-11) | Subject, method = \"ML\")\n\n## using re(), function I() is not supported,\n## please transform all variables in advance\nOrthodont$age11  &lt;- Orthodont$age - 11\n\n## estimation using the re() constructor\nb &lt;- gamlss2(distance ~ s(age,k=3) + re(random =~ age11 | Subject),\n  data = Orthodont)\n\nGAMLSS-RS iteration  1: Global Deviance = 326.6569 eps = 0.392363     \nGAMLSS-RS iteration  2: Global Deviance = 326.0931 eps = 0.001726     \nGAMLSS-RS iteration  3: Global Deviance = 326.0758 eps = 0.000053     \nGAMLSS-RS iteration  4: Global Deviance = 326.0757 eps = 0.000000     \n\n## compare fitted values\nplot(fitted(b, model = \"mu\"), fitted(m))\nabline(0, 1, col = 4)\n\n\n\n\n\n\n\n## extract summary for re() model term\nst &lt;- specials(b, model = \"mu\", elements = \"model\")\nsummary(st)\n\n                             Length Class  Mode\nmu.s(age)                     9     -none- list\nmu.re(random=~age11|Subject) 19     lme    list\n\n## random intercepts and slopes with s() using AIC\na &lt;- gamlss2(distance ~ s(age,k=3) + s(Subject, bs = \"re\") + s(Subject, age11, bs = \"re\"),\n  data = Orthodont)\n\nGAMLSS-RS iteration  1: Global Deviance = 427.3879 eps = 0.204987     \nGAMLSS-RS iteration  2: Global Deviance = 370.2269 eps = 0.133744     \nGAMLSS-RS iteration  3: Global Deviance = 340.2986 eps = 0.080837     \nGAMLSS-RS iteration  4: Global Deviance = 325.4086 eps = 0.043755     \nGAMLSS-RS iteration  5: Global Deviance = 319.3603 eps = 0.018586     \nGAMLSS-RS iteration  6: Global Deviance = 316.706 eps = 0.008311     \nGAMLSS-RS iteration  7: Global Deviance = 315.7332 eps = 0.003071     \nGAMLSS-RS iteration  8: Global Deviance = 315.3835 eps = 0.001107     \nGAMLSS-RS iteration  9: Global Deviance = 315.2588 eps = 0.000395     \nGAMLSS-RS iteration 10: Global Deviance = 315.2156 eps = 0.000137     \nGAMLSS-RS iteration 11: Global Deviance = 315.2007 eps = 0.000047     \nGAMLSS-RS iteration 12: Global Deviance = 315.1956 eps = 0.000016     \nGAMLSS-RS iteration 13: Global Deviance = 315.1933 eps = 0.000007     \n\n## compare fitted values\nplot(fitted(b, model = \"mu\"), fitted(m))\npoints(fitted(a, model = \"mu\"), fitted(m), col = 2)\nabline(0, 1, col = 4)\n\n\n\n\n\n\n\n## more complicated correlation structures.\ndata(\"Ovary\", package = \"nlme\")\n\n## ARMA model\nm &lt;- lme(follicles ~ sin(2 * pi * Time) + cos(2 * pi * Time), data = Ovary, \n  random = pdDiag(~sin(2*pi*Time)), correlation = corARMA(q = 2))\n\n## now with gamlss2(), transform in advance\nOvary$sin1 &lt;- sin(2 * pi * Ovary$Time)\nOvary$cos1 &lt;- cos(2 * pi * Ovary$Time)\n\n## model formula\nf &lt;- follicles ~ s(Time) + re(random =~ sin1 | Mare,\n  correlation = corARMA(q = 2), control = lmeControl(maxIter = 100))\n\n## estimate model\nb &lt;- gamlss2(f, data = Ovary)\n\nGAMLSS-RS iteration  1: Global Deviance = 1553.7576 eps = 0.168812     \nGAMLSS-RS iteration  2: Global Deviance = 1550.0142 eps = 0.002409     \nGAMLSS-RS iteration  3: Global Deviance = 1549.9734 eps = 0.000026     \nGAMLSS-RS iteration  4: Global Deviance = 1549.9731 eps = 0.000000     \n\n## smooth random effects\nf &lt;- follicles ~ ti(Time) + ti(Mare, bs = \"re\") + \n  ti(Mare, Time, bs = c(\"re\", \"cr\"), k = c(11, 5))\n\ng &lt;- gamlss2(f, data = Ovary)\n\nGAMLSS-RS iteration  1: Global Deviance = 1522.1007 eps = 0.185747     \nGAMLSS-RS iteration  2: Global Deviance = 1436.4746 eps = 0.056255     \nGAMLSS-RS iteration  3: Global Deviance = 1426.662 eps = 0.006831     \nGAMLSS-RS iteration  4: Global Deviance = 1425.7706 eps = 0.000624     \nGAMLSS-RS iteration  5: Global Deviance = 1425.692 eps = 0.000055     \nGAMLSS-RS iteration  6: Global Deviance = 1425.6854 eps = 0.000004     \n\n## compare fitted values\npar(mfrow = n2mfrow(nlevels(Ovary$Mare)), mar = c(4, 4, 1, 1))\n\nfor(j in levels(Ovary$Mare)) {\n  ds &lt;- subset(Ovary, Mare == j)\n\n  plot(follicles ~ Time, data = ds)\n\n  f &lt;- fitted(b, model = \"mu\")[Ovary$Mare == j]\n  lines(f ~ ds$Time, col = 4, lwd = 2)\n\n  f &lt;- fitted(g, model = \"mu\")[Ovary$Mare == j]\n  lines(f ~ ds$Time, col = 3, lwd = 2)\n\n  f &lt;- fitted(m)[Ovary$Mare == j]\n  lines(f ~ ds$Time, col = 2, lwd = 2)\n }",
    "crumbs": [
      "Reference",
      "random"
    ]
  },
  {
    "objectID": "man/Germany.html",
    "href": "man/Germany.html",
    "title": "gamlss2",
    "section": "",
    "text": "The map contains the counties of Germany. The data was originally taken from GADM (https://gadm.org/) and slightly simplified to reduce disk space.\n\n\n\ndata(\"Germany\", package = \"gamlss2\")\n\n\n\nA class “sf” data frame containing 403 counties of Germany.\n\n\nid\n\n\nFactor, a county id.\n\n\ncounty\n\n\nCharacter, the county in Germany where the weather station is located.\n\n\nstate\n\n\nCharacter, the state in Germany where the weather station is located.\n\n\ngeometry\n\n\nThe polygon information.\n\n\n\n\n\nMap of Germany:\n\n\nData Source:\n\n\nGADM\n\n\nLicence:\n\n\nCC BY\n\n\nURL:\n\n\nhttps://gadm.org/\n\n\nCoordinate Reference System:\n\n\nLongitude/latitude and the WGS84 datum.\n\n\n\n\n\n\nlibrary(\"gamlss2\")\n\n\n## load sf package for plotting\nlibrary(\"sf\")\n\n## load the data\ndata(\"Germany\", package = \"gamlss2\")\n\n## plot the map\nplot(st_geometry(Germany))",
    "crumbs": [
      "Reference",
      "Germany"
    ]
  },
  {
    "objectID": "man/Germany.html#map-of-germany",
    "href": "man/Germany.html#map-of-germany",
    "title": "gamlss2",
    "section": "",
    "text": "The map contains the counties of Germany. The data was originally taken from GADM (https://gadm.org/) and slightly simplified to reduce disk space.\n\n\n\ndata(\"Germany\", package = \"gamlss2\")\n\n\n\nA class “sf” data frame containing 403 counties of Germany.\n\n\nid\n\n\nFactor, a county id.\n\n\ncounty\n\n\nCharacter, the county in Germany where the weather station is located.\n\n\nstate\n\n\nCharacter, the state in Germany where the weather station is located.\n\n\ngeometry\n\n\nThe polygon information.\n\n\n\n\n\nMap of Germany:\n\n\nData Source:\n\n\nGADM\n\n\nLicence:\n\n\nCC BY\n\n\nURL:\n\n\nhttps://gadm.org/\n\n\nCoordinate Reference System:\n\n\nLongitude/latitude and the WGS84 datum.\n\n\n\n\n\n\nlibrary(\"gamlss2\")\n\n\n## load sf package for plotting\nlibrary(\"sf\")\n\n## load the data\ndata(\"Germany\", package = \"gamlss2\")\n\n## plot the map\nplot(st_geometry(Germany))",
    "crumbs": [
      "Reference",
      "Germany"
    ]
  },
  {
    "objectID": "man/find_family.html",
    "href": "man/find_family.html",
    "title": "gamlss2",
    "section": "",
    "text": "These functions provide useful infrastructures for finding suitable GAMLSS families for a response variable.\n\n\n\n## List of available families from gamlss.dist package.\navailable_families(type = c(\"continuous\", \"discrete\"), families = NULL)\n\n## Find suitable response distribution.\nfind_family(y, families = NULL, k = 2, verbose = TRUE, ...)\n\n## Fit distribution parameters.\nfit_family(y, family = NO, plot = TRUE, ...)\n\n\n\n\n\n\n\ntype\n\n\nCharacter, is the reponse continuous or discrete?\n\n\n\n\nfamilies\n\n\nCharacter, the names of the family objects of the gamlss.dist package that should be returned.\n\n\n\n\ny\n\n\nThe response vector or matrix.\n\n\n\n\nk\n\n\nNumeric, the penalty factor that should be used for the GAIC.\n\n\n\n\nverbose\n\n\nLogical, should runtime information be printed?\n\n\n\n\nfamily\n\n\nA famnily object that should be used for estimation, see also gamlss2.family.\n\n\n\n\nplot\n\n\nLogical, should a plot of the fitted density be provided?\n\n\n\n\n…\n\n\nFurther arguments to be passed to gamlss2 when using find_family(), or arguments legend = TRUE/FALSE, pos = “topright” (see also function legend), main, xlab and ylab when argument plot = TRUE using function fit_family().\n\n\n\n\n\n\nThe function find_family() employs gamlss2 to estimate intercept-only models for each specified family object in the families argument. Note that model estimation occurs within a try block with warnings suppressed. Additionally, the function calculates the GAIC for each family whenever feasible and returns the sorted values in descending order.\nFunction fit_family() fits a single intercept-only model using the specified family and creates a plot of the fitted density.\n\n\n\nFunction find_family() returns a vector of GAIC values for the different fitted families. Function fit_family() returns the fitted intercept-only model.\n\n\n\ngamlss2.\n\n\n\n\nlibrary(\"gamlss2\")\n\n\ndata(\"rent\", package = \"gamlss.data\")\n\n## find a suitable response to the response\nic &lt;- find_family(rent$R)\nprint(ic)\n\n## fit parameters using the BCCG family\nfit_family(rent$R, family = BCCG)\n\n## count data\ndata(\"polio\", package = \"gamlss.data\")\n\n## search best count model\nic &lt;- find_family(polio, k = 0,\n  families = available_families(type = \"discrete\"))\nprint(ic)\n\n## fit parameters using the ZASICHEL family\nfit_family(polio, family = ZASICHEL)",
    "crumbs": [
      "Reference",
      "find_family"
    ]
  },
  {
    "objectID": "man/find_family.html#find-and-fit-gamlss-families",
    "href": "man/find_family.html#find-and-fit-gamlss-families",
    "title": "gamlss2",
    "section": "",
    "text": "These functions provide useful infrastructures for finding suitable GAMLSS families for a response variable.\n\n\n\n## List of available families from gamlss.dist package.\navailable_families(type = c(\"continuous\", \"discrete\"), families = NULL)\n\n## Find suitable response distribution.\nfind_family(y, families = NULL, k = 2, verbose = TRUE, ...)\n\n## Fit distribution parameters.\nfit_family(y, family = NO, plot = TRUE, ...)\n\n\n\n\n\n\n\ntype\n\n\nCharacter, is the reponse continuous or discrete?\n\n\n\n\nfamilies\n\n\nCharacter, the names of the family objects of the gamlss.dist package that should be returned.\n\n\n\n\ny\n\n\nThe response vector or matrix.\n\n\n\n\nk\n\n\nNumeric, the penalty factor that should be used for the GAIC.\n\n\n\n\nverbose\n\n\nLogical, should runtime information be printed?\n\n\n\n\nfamily\n\n\nA famnily object that should be used for estimation, see also gamlss2.family.\n\n\n\n\nplot\n\n\nLogical, should a plot of the fitted density be provided?\n\n\n\n\n…\n\n\nFurther arguments to be passed to gamlss2 when using find_family(), or arguments legend = TRUE/FALSE, pos = “topright” (see also function legend), main, xlab and ylab when argument plot = TRUE using function fit_family().\n\n\n\n\n\n\nThe function find_family() employs gamlss2 to estimate intercept-only models for each specified family object in the families argument. Note that model estimation occurs within a try block with warnings suppressed. Additionally, the function calculates the GAIC for each family whenever feasible and returns the sorted values in descending order.\nFunction fit_family() fits a single intercept-only model using the specified family and creates a plot of the fitted density.\n\n\n\nFunction find_family() returns a vector of GAIC values for the different fitted families. Function fit_family() returns the fitted intercept-only model.\n\n\n\ngamlss2.\n\n\n\n\nlibrary(\"gamlss2\")\n\n\ndata(\"rent\", package = \"gamlss.data\")\n\n## find a suitable response to the response\nic &lt;- find_family(rent$R)\nprint(ic)\n\n## fit parameters using the BCCG family\nfit_family(rent$R, family = BCCG)\n\n## count data\ndata(\"polio\", package = \"gamlss.data\")\n\n## search best count model\nic &lt;- find_family(polio, k = 0,\n  families = available_families(type = \"discrete\"))\nprint(ic)\n\n## fit parameters using the ZASICHEL family\nfit_family(polio, family = ZASICHEL)",
    "crumbs": [
      "Reference",
      "find_family"
    ]
  },
  {
    "objectID": "man/pb.html",
    "href": "man/pb.html",
    "title": "gamlss2",
    "section": "",
    "text": "Estimation of P-splines using an efficient local maximum likelihood approach to automatically select the smoothing parameter. According to the inventors of P-splines, pb stands for \"penalized beta\" splines or \"Paul and Brian\".\n\n\n\npb(x, k = 20, ...)\n\n\n\n\n\n\n\nx\n\n\nThe variable that should be used for estimation.\n\n\n\n\nk\n\n\nThe dimension of the B-spline basis to represent the smooth term.\n\n\n\n\n…\n\n\nFurther arguments passed to function s.\n\n\n\n\n\n\nFunction pb() is an internal wrapper function that calls s to set up a smooth specification object that can be used for model fitting with gamlss2. Using pb(), an efficient local maximum likelihood approach is used to estimate the smoothing parameter. See the reference for details.\n\n\n\nThe function returns a smooth specification object of class “ps.smooth.spec”, see also smooth.construct.ps.smooth.spec.\n\n\n\nEilers PHC, Marx BD (1996). “Flexible Smoothing with B-Splines and Penalties.” Statistical Science, 11(2), 89–121. doi:10.1214/ss/1038425655\nRigby RA, Stasinopoulos DM (2014). “Automatic Smoothing Parameter Selection in GAMLSS with an Application to Centile Estimation.” Statistical Methods in Medical Research, 23(4), 318–332. doi:10.1177/0962280212473302\n\n\n\ngamlss2, smooth.construct.ps.smooth.spec\n\n\n\n\nlibrary(\"gamlss2\")\n\n\n## load head circumference data\ndata(\"dbhh\", package = \"gamlss.data\")\n\n## specify the model Formula\nf &lt;- head ~ pb(age) | pb(age) | pb(age) | pb(age)\n\n## estimate model\nb &lt;- gamlss2(f, data = dbhh, family = BCT)\n\nGAMLSS-RS iteration  1: Global Deviance = 26377.8229 eps = 0.390162     \nGAMLSS-RS iteration  2: Global Deviance = 26205.3586 eps = 0.006538     \nGAMLSS-RS iteration  3: Global Deviance = 26202.541 eps = 0.000107     \nGAMLSS-RS iteration  4: Global Deviance = 26202.1755 eps = 0.000013     \nGAMLSS-RS iteration  5: Global Deviance = 26202.0501 eps = 0.000004     \n\n## visualize estimated effects\nplot(b, which = \"effects\")\n\n\n\n\n\n\n\n## plot diagnostics\nplot(b, which = \"resid\")\n\n\n\n\n\n\n\n## predict parameters\npar &lt;- predict(b)\n\n## predict quantiles\npq &lt;- sapply(c(0.05, 0.5, 0.95), function(q) family(b)$q(q, par))\n\n## plot\nplot(head ~ age, data = dbhh, pch = 19,\n  col = rgb(0.1, 0.1, 0.1, alpha = 0.3))\nmatplot(dbhh$age, pq, type = \"l\",\n  lty = 1, col = 4, add = TRUE)",
    "crumbs": [
      "Reference",
      "pb"
    ]
  },
  {
    "objectID": "man/pb.html#p-splines-for-gamlss",
    "href": "man/pb.html#p-splines-for-gamlss",
    "title": "gamlss2",
    "section": "",
    "text": "Estimation of P-splines using an efficient local maximum likelihood approach to automatically select the smoothing parameter. According to the inventors of P-splines, pb stands for \"penalized beta\" splines or \"Paul and Brian\".\n\n\n\npb(x, k = 20, ...)\n\n\n\n\n\n\n\nx\n\n\nThe variable that should be used for estimation.\n\n\n\n\nk\n\n\nThe dimension of the B-spline basis to represent the smooth term.\n\n\n\n\n…\n\n\nFurther arguments passed to function s.\n\n\n\n\n\n\nFunction pb() is an internal wrapper function that calls s to set up a smooth specification object that can be used for model fitting with gamlss2. Using pb(), an efficient local maximum likelihood approach is used to estimate the smoothing parameter. See the reference for details.\n\n\n\nThe function returns a smooth specification object of class “ps.smooth.spec”, see also smooth.construct.ps.smooth.spec.\n\n\n\nEilers PHC, Marx BD (1996). “Flexible Smoothing with B-Splines and Penalties.” Statistical Science, 11(2), 89–121. doi:10.1214/ss/1038425655\nRigby RA, Stasinopoulos DM (2014). “Automatic Smoothing Parameter Selection in GAMLSS with an Application to Centile Estimation.” Statistical Methods in Medical Research, 23(4), 318–332. doi:10.1177/0962280212473302\n\n\n\ngamlss2, smooth.construct.ps.smooth.spec\n\n\n\n\nlibrary(\"gamlss2\")\n\n\n## load head circumference data\ndata(\"dbhh\", package = \"gamlss.data\")\n\n## specify the model Formula\nf &lt;- head ~ pb(age) | pb(age) | pb(age) | pb(age)\n\n## estimate model\nb &lt;- gamlss2(f, data = dbhh, family = BCT)\n\nGAMLSS-RS iteration  1: Global Deviance = 26377.8229 eps = 0.390162     \nGAMLSS-RS iteration  2: Global Deviance = 26205.3586 eps = 0.006538     \nGAMLSS-RS iteration  3: Global Deviance = 26202.541 eps = 0.000107     \nGAMLSS-RS iteration  4: Global Deviance = 26202.1755 eps = 0.000013     \nGAMLSS-RS iteration  5: Global Deviance = 26202.0501 eps = 0.000004     \n\n## visualize estimated effects\nplot(b, which = \"effects\")\n\n\n\n\n\n\n\n## plot diagnostics\nplot(b, which = \"resid\")\n\n\n\n\n\n\n\n## predict parameters\npar &lt;- predict(b)\n\n## predict quantiles\npq &lt;- sapply(c(0.05, 0.5, 0.95), function(q) family(b)$q(q, par))\n\n## plot\nplot(head ~ age, data = dbhh, pch = 19,\n  col = rgb(0.1, 0.1, 0.1, alpha = 0.3))\nmatplot(dbhh$age, pq, type = \"l\",\n  lty = 1, col = 4, add = TRUE)",
    "crumbs": [
      "Reference",
      "pb"
    ]
  },
  {
    "objectID": "man/softplus.html",
    "href": "man/softplus.html",
    "title": "gamlss2",
    "section": "",
    "text": "Link object (with link function, inverse link function, etc.) that assures positivity of parameters based on the softplus function.\n\n\n\nsoftplus(a = 1)\n\n\n\n\n\n\n\na\n\n\nExtra parameter of the generalized softplus function\n\n\n\n\n\n\nThe softplus link function with parameter \\(a\\) is given by:\n\n\\(\\displaystyle \\frac{\\log(1 + \\exp(a \\cdot x))}{a}\\)\nThis is an approximation of the linear spline \\(\\max\\{0, x\\}\\) where the discrepancy between the two functions decreases with increasing \\(a\\).\nWiemann et al. (2023) propose to employ the softplus function as the inverse link function where positivity of a parameter needs to be assured, e.g., in count data regressions. This is in particular of interest as an alternative to the exponential inverse link function because the exponential implies multiplicative effects of the regressors while the softplus function does not.\n\n\n\nAn object of class “link-glm”.\n\n\n\nWiemann PFV, Kneib T, Hambuckers J (2023). “Using the Softplus Function to Construct Alternative Link Functions in Generalized Linear Models and Beyond.” Statistical Papers, forthcoming. doi:https://doi.org/10.1007/s00362-023-01509-x\n\n\n\nmake.link, gamlss2\n\n\n\n\nlibrary(\"gamlss2\")\n\n\n## visualization of softmax function from Wiemann et al. (2003, Figure 1)\nx &lt;- -200:200/50\nplot(x, softplus(1)$linkinv(x), ylab = expression(softplus[a](x)),\n  type = \"l\", col = 2, lwd = 2)\ngrid()\nlines(x, softplus(5)$linkinv(x), col = 3, lwd = 2)\nlines(x, softplus(10)$linkinv(x), col = 4, lwd = 2)\nlines(x, pmax(0, x), lty = 3, lwd = 2)\nlegend(\"topleft\", c(\"a = 1\", \"a = 5\", \"a = 10\", \"linear spline\"),\n  col = c(2, 3, 4, 1), lty = c(1, 1, 1, 3), lwd = 2, bty = \"n\")\n\n\n\n\n\n\n\n## Poisson regression example with different links\ndata(\"FIFA2018\", package = \"distributions3\")\nm_exp &lt;- glm(goals ~ difference, data = FIFA2018, family = poisson(link = \"log\"))\nm_splus &lt;- glm(goals ~ difference, data = FIFA2018, family = poisson(link = softplus(1)))\nAIC(m_exp, m_splus)\n\n        df      AIC\nm_exp    2 359.3942\nm_splus  2 359.3774\n\n## comparison of fitted effects\nnd &lt;- data.frame(difference = -15:15/10)\nnd$mu_exp &lt;- predict(m_exp, newdata = nd, type = \"response\")\nnd$mu_splus &lt;- predict(m_splus, newdata = nd, type = \"response\")\nplot(mu_exp ~ difference, data = nd, ylab = expression(mu),\n  type = \"l\", col = 4, lwd = 2, ylim = c(0, 2.5))\nlines(mu_splus ~ difference, data = nd, col = 2, lwd = 2)\nlegend(\"topleft\", c(\"exp\", \"softplus\"), col = c(4, 2), lwd = 2, lty = 1, bty = \"n\")",
    "crumbs": [
      "Reference",
      "softplus"
    ]
  },
  {
    "objectID": "man/softplus.html#softplus-link-object",
    "href": "man/softplus.html#softplus-link-object",
    "title": "gamlss2",
    "section": "",
    "text": "Link object (with link function, inverse link function, etc.) that assures positivity of parameters based on the softplus function.\n\n\n\nsoftplus(a = 1)\n\n\n\n\n\n\n\na\n\n\nExtra parameter of the generalized softplus function\n\n\n\n\n\n\nThe softplus link function with parameter \\(a\\) is given by:\n\n\\(\\displaystyle \\frac{\\log(1 + \\exp(a \\cdot x))}{a}\\)\nThis is an approximation of the linear spline \\(\\max\\{0, x\\}\\) where the discrepancy between the two functions decreases with increasing \\(a\\).\nWiemann et al. (2023) propose to employ the softplus function as the inverse link function where positivity of a parameter needs to be assured, e.g., in count data regressions. This is in particular of interest as an alternative to the exponential inverse link function because the exponential implies multiplicative effects of the regressors while the softplus function does not.\n\n\n\nAn object of class “link-glm”.\n\n\n\nWiemann PFV, Kneib T, Hambuckers J (2023). “Using the Softplus Function to Construct Alternative Link Functions in Generalized Linear Models and Beyond.” Statistical Papers, forthcoming. doi:https://doi.org/10.1007/s00362-023-01509-x\n\n\n\nmake.link, gamlss2\n\n\n\n\nlibrary(\"gamlss2\")\n\n\n## visualization of softmax function from Wiemann et al. (2003, Figure 1)\nx &lt;- -200:200/50\nplot(x, softplus(1)$linkinv(x), ylab = expression(softplus[a](x)),\n  type = \"l\", col = 2, lwd = 2)\ngrid()\nlines(x, softplus(5)$linkinv(x), col = 3, lwd = 2)\nlines(x, softplus(10)$linkinv(x), col = 4, lwd = 2)\nlines(x, pmax(0, x), lty = 3, lwd = 2)\nlegend(\"topleft\", c(\"a = 1\", \"a = 5\", \"a = 10\", \"linear spline\"),\n  col = c(2, 3, 4, 1), lty = c(1, 1, 1, 3), lwd = 2, bty = \"n\")\n\n\n\n\n\n\n\n## Poisson regression example with different links\ndata(\"FIFA2018\", package = \"distributions3\")\nm_exp &lt;- glm(goals ~ difference, data = FIFA2018, family = poisson(link = \"log\"))\nm_splus &lt;- glm(goals ~ difference, data = FIFA2018, family = poisson(link = softplus(1)))\nAIC(m_exp, m_splus)\n\n        df      AIC\nm_exp    2 359.3942\nm_splus  2 359.3774\n\n## comparison of fitted effects\nnd &lt;- data.frame(difference = -15:15/10)\nnd$mu_exp &lt;- predict(m_exp, newdata = nd, type = \"response\")\nnd$mu_splus &lt;- predict(m_splus, newdata = nd, type = \"response\")\nplot(mu_exp ~ difference, data = nd, ylab = expression(mu),\n  type = \"l\", col = 4, lwd = 2, ylim = c(0, 2.5))\nlines(mu_splus ~ difference, data = nd, col = 2, lwd = 2)\nlegend(\"topleft\", c(\"exp\", \"softplus\"), col = c(4, 2), lwd = 2, lty = 1, bty = \"n\")",
    "crumbs": [
      "Reference",
      "softplus"
    ]
  },
  {
    "objectID": "man/prodist.gamlss2.html",
    "href": "man/prodist.gamlss2.html",
    "title": "gamlss2",
    "section": "",
    "text": "Methods for gamlss2 model objects for extracting fitted (in-sample) or predicted (out-of-sample) probability distributions as distributions3 objects.\n\n\n\n## S3 method for class 'gamlss2'\nprodist(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA model object of class gamlss2.\n\n\n\n\n…\n\n\nArguments passed on to predict.gamlss2, e.g., newdata.\n\n\n\n\n\n\nTo facilitate making probabilistic forecasts based on gamlss2 model objects, the prodist method extracts fitted or predicted probability distribution objects. Internally, the predict.gamlss2 method is used first to obtain the distribution parameters (mu, sigma, tau, nu, or a subset thereof). Subsequently, the corresponding distribution object is set up using the GAMLSS class from the gamlss.dist package, enabling the workflow provided by the distributions3 package (see Zeileis et al. 2022).\nNote that these probability distributions only reflect the random variation in the dependent variable based on the model employed (and its associated distributional assumption for the dependent variable). This does not capture the uncertainty in the parameter estimates.\n\n\n\nAn object of class GAMLSS inheriting from distribution.\n\n\n\nZeileis A, Lang MN, Hayes A (2022). “distributions3: From Basic Probability to Probabilistic Regression.” Presented at useR! 2022 - The R User Conference. Slides, video, vignette, code at https://www.zeileis.org/news/user2022/.\n\n\n\nGAMLSS, predict.gamlss2\n\n\n\n\nlibrary(\"gamlss2\")\n\n\n## packages, code, and data\nlibrary(\"distributions3\")\ndata(\"cars\", package = \"datasets\")\n\n## fit heteroscedastic normal GAMLSS model\n## stopping distance (ft) explained by speed (mph)\nm &lt;- gamlss2(dist ~ s(speed) | s(speed), data = cars, family = NO)\n\nGAMLSS-RS iteration  1: Global Deviance = 407.3541 eps = 0.125497     \nGAMLSS-RS iteration  2: Global Deviance = 405.7146 eps = 0.004024     \nGAMLSS-RS iteration  3: Global Deviance = 405.6978 eps = 0.000041     \nGAMLSS-RS iteration  4: Global Deviance = 405.6976 eps = 0.000000     \n\n## obtain predicted distributions for three levels of speed\nd &lt;- prodist(m, newdata = data.frame(speed = c(10, 20, 30)))\nprint(d)\n\n                                     1                                      2 \n\"GAMLSS NO(mu = 23.04, sigma = 10.06)\" \"GAMLSS NO(mu = 59.04, sigma = 18.51)\" \n                                     3 \n\"GAMLSS NO(mu = 96.35, sigma = 33.95)\" \n\n## obtain quantiles (works the same for any distribution object 'd' !)\nquantile(d, 0.5)\n\n       1        2        3 \n23.03912 59.03607 96.34896 \n\nquantile(d, c(0.05, 0.5, 0.95), elementwise = FALSE)\n\n     q_0.05    q_0.5    q_0.95\n1  6.486962 23.03912  39.59128\n2 28.589641 59.03607  89.48250\n3 40.504887 96.34896 152.19303\n\nquantile(d, c(0.05, 0.5, 0.95), elementwise = TRUE)\n\n         1          2          3 \n  6.486962  59.036073 152.193030 \n\n## visualization\nplot(dist ~ speed, data = cars)\nnd &lt;- data.frame(speed = 0:240/4)\nnd$dist &lt;- prodist(m, newdata = nd)\nnd$fit &lt;- quantile(nd$dist, c(0.05, 0.5, 0.95))\nmatplot(nd$speed, nd$fit, type = \"l\", lty = 1, col = \"slategray\", add = TRUE)\n\n\n\n\n\n\n\n## moments\nmean(d)\n\n       1        2        3 \n23.03912 59.03607 96.34896 \n\nvariance(d)\n\n        1         2         3 \n 101.2639  342.6244 1152.6558 \n\n## simulate random numbers\nrandom(d, 5)\n\n       r_1      r_2      r_3      r_4       r_5\n1 24.72864 12.34393 40.14598 36.03732  12.85618\n2 66.24679 90.10050 81.85565 71.47874  71.28206\n3 94.43690 73.57451 67.46084 91.83861 160.58226\n\n## density and distribution\npdf(d, 50 * -2:2)\n\n        d_-100        d_-50          d_0        d_50        d_100\n1 1.365786e-34 1.440750e-13 0.0028836944 0.001095127 7.891037e-15\n2 2.012473e-18 6.289547e-10 0.0001332376 0.019131662 1.862073e-03\n3 6.414012e-10 1.084300e-06 0.0002095201 0.004627633 1.168286e-02\n\ncdf(d, 50 * -2:2)\n\n        p_-100        p_-50          p_0       p_50     p_100\n1 1.116699e-34 1.961566e-13 0.0110254856 0.99631019 1.0000000\n2 4.279141e-18 1.923739e-09 0.0007128545 0.31271491 0.9865531\n3 3.661574e-09 8.139843e-06 0.0022705648 0.08609812 0.5428194\n\n## Poisson example\ndata(\"FIFA2018\", package = \"distributions3\")\nm2 &lt;- gamlss2(goals ~ s(difference), data = FIFA2018, family = PO)\n\nGAMLSS-RS iteration  1: Global Deviance = 355.3922 eps = 0.045332     \nGAMLSS-RS iteration  2: Global Deviance = 355.3922 eps = 0.000000     \n\nd2 &lt;- prodist(m2, newdata = data.frame(difference = 0))\nprint(d2)\n\n                      1 \n\"GAMLSS PO(mu = 1.237)\" \n\nquantile(d2, c(0.05, 0.5, 0.95))\n\n[1] 0 1 3\n\n## note that log_pdf() can replicate logLik() value\nsum(log_pdf(prodist(m2), FIFA2018$goals))\n\n[1] -177.6961\n\nlogLik(m2)\n\n'log Lik.' -177.6961 (df=2.005144)",
    "crumbs": [
      "Reference",
      "prodist.gamlss2"
    ]
  },
  {
    "objectID": "man/prodist.gamlss2.html#extracting-fitted-or-predicted-probability-distributions-from-gamlss2-models",
    "href": "man/prodist.gamlss2.html#extracting-fitted-or-predicted-probability-distributions-from-gamlss2-models",
    "title": "gamlss2",
    "section": "",
    "text": "Methods for gamlss2 model objects for extracting fitted (in-sample) or predicted (out-of-sample) probability distributions as distributions3 objects.\n\n\n\n## S3 method for class 'gamlss2'\nprodist(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA model object of class gamlss2.\n\n\n\n\n…\n\n\nArguments passed on to predict.gamlss2, e.g., newdata.\n\n\n\n\n\n\nTo facilitate making probabilistic forecasts based on gamlss2 model objects, the prodist method extracts fitted or predicted probability distribution objects. Internally, the predict.gamlss2 method is used first to obtain the distribution parameters (mu, sigma, tau, nu, or a subset thereof). Subsequently, the corresponding distribution object is set up using the GAMLSS class from the gamlss.dist package, enabling the workflow provided by the distributions3 package (see Zeileis et al. 2022).\nNote that these probability distributions only reflect the random variation in the dependent variable based on the model employed (and its associated distributional assumption for the dependent variable). This does not capture the uncertainty in the parameter estimates.\n\n\n\nAn object of class GAMLSS inheriting from distribution.\n\n\n\nZeileis A, Lang MN, Hayes A (2022). “distributions3: From Basic Probability to Probabilistic Regression.” Presented at useR! 2022 - The R User Conference. Slides, video, vignette, code at https://www.zeileis.org/news/user2022/.\n\n\n\nGAMLSS, predict.gamlss2\n\n\n\n\nlibrary(\"gamlss2\")\n\n\n## packages, code, and data\nlibrary(\"distributions3\")\ndata(\"cars\", package = \"datasets\")\n\n## fit heteroscedastic normal GAMLSS model\n## stopping distance (ft) explained by speed (mph)\nm &lt;- gamlss2(dist ~ s(speed) | s(speed), data = cars, family = NO)\n\nGAMLSS-RS iteration  1: Global Deviance = 407.3541 eps = 0.125497     \nGAMLSS-RS iteration  2: Global Deviance = 405.7146 eps = 0.004024     \nGAMLSS-RS iteration  3: Global Deviance = 405.6978 eps = 0.000041     \nGAMLSS-RS iteration  4: Global Deviance = 405.6976 eps = 0.000000     \n\n## obtain predicted distributions for three levels of speed\nd &lt;- prodist(m, newdata = data.frame(speed = c(10, 20, 30)))\nprint(d)\n\n                                     1                                      2 \n\"GAMLSS NO(mu = 23.04, sigma = 10.06)\" \"GAMLSS NO(mu = 59.04, sigma = 18.51)\" \n                                     3 \n\"GAMLSS NO(mu = 96.35, sigma = 33.95)\" \n\n## obtain quantiles (works the same for any distribution object 'd' !)\nquantile(d, 0.5)\n\n       1        2        3 \n23.03912 59.03607 96.34896 \n\nquantile(d, c(0.05, 0.5, 0.95), elementwise = FALSE)\n\n     q_0.05    q_0.5    q_0.95\n1  6.486962 23.03912  39.59128\n2 28.589641 59.03607  89.48250\n3 40.504887 96.34896 152.19303\n\nquantile(d, c(0.05, 0.5, 0.95), elementwise = TRUE)\n\n         1          2          3 \n  6.486962  59.036073 152.193030 \n\n## visualization\nplot(dist ~ speed, data = cars)\nnd &lt;- data.frame(speed = 0:240/4)\nnd$dist &lt;- prodist(m, newdata = nd)\nnd$fit &lt;- quantile(nd$dist, c(0.05, 0.5, 0.95))\nmatplot(nd$speed, nd$fit, type = \"l\", lty = 1, col = \"slategray\", add = TRUE)\n\n\n\n\n\n\n\n## moments\nmean(d)\n\n       1        2        3 \n23.03912 59.03607 96.34896 \n\nvariance(d)\n\n        1         2         3 \n 101.2639  342.6244 1152.6558 \n\n## simulate random numbers\nrandom(d, 5)\n\n       r_1      r_2      r_3      r_4       r_5\n1 24.72864 12.34393 40.14598 36.03732  12.85618\n2 66.24679 90.10050 81.85565 71.47874  71.28206\n3 94.43690 73.57451 67.46084 91.83861 160.58226\n\n## density and distribution\npdf(d, 50 * -2:2)\n\n        d_-100        d_-50          d_0        d_50        d_100\n1 1.365786e-34 1.440750e-13 0.0028836944 0.001095127 7.891037e-15\n2 2.012473e-18 6.289547e-10 0.0001332376 0.019131662 1.862073e-03\n3 6.414012e-10 1.084300e-06 0.0002095201 0.004627633 1.168286e-02\n\ncdf(d, 50 * -2:2)\n\n        p_-100        p_-50          p_0       p_50     p_100\n1 1.116699e-34 1.961566e-13 0.0110254856 0.99631019 1.0000000\n2 4.279141e-18 1.923739e-09 0.0007128545 0.31271491 0.9865531\n3 3.661574e-09 8.139843e-06 0.0022705648 0.08609812 0.5428194\n\n## Poisson example\ndata(\"FIFA2018\", package = \"distributions3\")\nm2 &lt;- gamlss2(goals ~ s(difference), data = FIFA2018, family = PO)\n\nGAMLSS-RS iteration  1: Global Deviance = 355.3922 eps = 0.045332     \nGAMLSS-RS iteration  2: Global Deviance = 355.3922 eps = 0.000000     \n\nd2 &lt;- prodist(m2, newdata = data.frame(difference = 0))\nprint(d2)\n\n                      1 \n\"GAMLSS PO(mu = 1.237)\" \n\nquantile(d2, c(0.05, 0.5, 0.95))\n\n[1] 0 1 3\n\n## note that log_pdf() can replicate logLik() value\nsum(log_pdf(prodist(m2), FIFA2018$goals))\n\n[1] -177.6961\n\nlogLik(m2)\n\n'log Lik.' -177.6961 (df=2.005144)",
    "crumbs": [
      "Reference",
      "prodist.gamlss2"
    ]
  },
  {
    "objectID": "man/modelstats.html",
    "href": "man/modelstats.html",
    "title": "gamlss2",
    "section": "",
    "text": "Functions to compute the GAIC and the generalised R-squared of Nagelkerke (1991) for a GAMLSS models.\n\n\n\n## Information criteria.\nGAIC(object, ...,\n  k = 2, corrected = FALSE)\n\n## R-squared.\nRsq(object, ...,\n  type = c(\"Cox Snell\", \"Cragg Uhler\", \"both\", \"simple\"),\n  newdata = NULL)\n\n\n\n\n\n\n\nobject\n\n\nA fitted model object\n\n\n\n\n…\n\n\nOptionally more fitted model objects.\n\n\n\n\nk\n\n\nNumeric, the penalty to be used. The default k = 2 corresponds to the classical AIC.\n\n\n\n\ncorrected\n\n\nLogical, whether the corrected AIC should be used? Note that it applies only when k = 2.\n\n\n\n\ntype\n\n\nwhich definition of R squared. Can be the “Cox Snell” or the Nagelkerke, “Cragg Uhler” or “both”, and “simple”, which computes the R-squared based on the median. In this case also newdata may be supplied.\n\n\n\n\nnewdata\n\n\nOnly for type = “simple” the R-squared can be evaluated using newdata.\n\n\n\n\n\n\nThe Rsq() function uses the definition for R-squared:\n\n\\(R^2=1- \\left(\\frac{L(0)}{L(\\hat{\\theta})}\\right)^{2/n}\\)\nwhere \\(L(0)\\) is the null model (only a constant is fitted to all parameters) and \\(L(\\hat{\\theta})\\) is the current fitted model. This definition sometimes is referred to as the Cox & Snell R-squared. The Nagelkerke /Cragg & Uhler’s definition divides the above with\n\n\\(1 - L(0)^{2/n}\\)\n\n\n\nNumeric vector or data frame, depending on the number of fitted model objects.\n\n\n\nNagelkerke NJD (1991). “A Note on a General Definition of the Coefficient of Determination.” Biometrika, 78(3), 691–692. doi:10.1093/biomet/78.3.691\n\n\n\ngamlss2\n\n\n\n\nlibrary(\"gamlss2\")\n\n\n## load the aids data set\ndata(\"aids\", package = \"gamlss.data\")\n\n## estimate negative binomial count models\nb1 &lt;- gamlss2(y ~ x + qrt, data = aids, family = NBI)\n\nGAMLSS-RS iteration  1: Global Deviance = 492.7033 eps = 0.148555     \nGAMLSS-RS iteration  2: Global Deviance = 492.6374 eps = 0.000133     \nGAMLSS-RS iteration  3: Global Deviance = 492.6373 eps = 0.000000     \n\nb2 &lt;- gamlss2(y ~ s(x) + s(qrt, bs = \"re\"), data = aids, family = NBI)\n\nGAMLSS-RS iteration  1: Global Deviance = 406.0278 eps = 0.298340     \nGAMLSS-RS iteration  2: Global Deviance = 373.0395 eps = 0.081246     \nGAMLSS-RS iteration  3: Global Deviance = 363.9491 eps = 0.024368     \nGAMLSS-RS iteration  4: Global Deviance = 363.1967 eps = 0.002067     \nGAMLSS-RS iteration  5: Global Deviance = 363.1423 eps = 0.000149     \nGAMLSS-RS iteration  6: Global Deviance = 363.1339 eps = 0.000023     \nGAMLSS-RS iteration  7: Global Deviance = 363.1323 eps = 0.000004     \n\n## compare models\nRsq(b1)\n\n[1] 0.8095853\n\nRsq(b1, type = \"both\")\n\n$CoxSnell\n[1] 0.8095853\n\n$CraggUhler\n[1] 0.809588\n\nRsq(b1, b2)\n\n       b1        b2 \n0.8095853 0.9892885 \n\nGAIC(b1, b2)\n\n        AIC       df\nb2 388.9107 12.88923\nb1 504.6373  6.00000\n\nAIC(b1, b2)\n\n        AIC       df\nb2 388.9107 12.88923\nb1 504.6373  6.00000\n\nBIC(b1, b2)\n\n        AIC       df\nb2 412.1972 12.88923\nb1 515.4773  6.00000\n\n## plot estimated effects\nplot(b2)",
    "crumbs": [
      "Reference",
      "modelstats"
    ]
  },
  {
    "objectID": "man/modelstats.html#gaic-and-generalised-pseudo-r-squared-for-gamlss-models",
    "href": "man/modelstats.html#gaic-and-generalised-pseudo-r-squared-for-gamlss-models",
    "title": "gamlss2",
    "section": "",
    "text": "Functions to compute the GAIC and the generalised R-squared of Nagelkerke (1991) for a GAMLSS models.\n\n\n\n## Information criteria.\nGAIC(object, ...,\n  k = 2, corrected = FALSE)\n\n## R-squared.\nRsq(object, ...,\n  type = c(\"Cox Snell\", \"Cragg Uhler\", \"both\", \"simple\"),\n  newdata = NULL)\n\n\n\n\n\n\n\nobject\n\n\nA fitted model object\n\n\n\n\n…\n\n\nOptionally more fitted model objects.\n\n\n\n\nk\n\n\nNumeric, the penalty to be used. The default k = 2 corresponds to the classical AIC.\n\n\n\n\ncorrected\n\n\nLogical, whether the corrected AIC should be used? Note that it applies only when k = 2.\n\n\n\n\ntype\n\n\nwhich definition of R squared. Can be the “Cox Snell” or the Nagelkerke, “Cragg Uhler” or “both”, and “simple”, which computes the R-squared based on the median. In this case also newdata may be supplied.\n\n\n\n\nnewdata\n\n\nOnly for type = “simple” the R-squared can be evaluated using newdata.\n\n\n\n\n\n\nThe Rsq() function uses the definition for R-squared:\n\n\\(R^2=1- \\left(\\frac{L(0)}{L(\\hat{\\theta})}\\right)^{2/n}\\)\nwhere \\(L(0)\\) is the null model (only a constant is fitted to all parameters) and \\(L(\\hat{\\theta})\\) is the current fitted model. This definition sometimes is referred to as the Cox & Snell R-squared. The Nagelkerke /Cragg & Uhler’s definition divides the above with\n\n\\(1 - L(0)^{2/n}\\)\n\n\n\nNumeric vector or data frame, depending on the number of fitted model objects.\n\n\n\nNagelkerke NJD (1991). “A Note on a General Definition of the Coefficient of Determination.” Biometrika, 78(3), 691–692. doi:10.1093/biomet/78.3.691\n\n\n\ngamlss2\n\n\n\n\nlibrary(\"gamlss2\")\n\n\n## load the aids data set\ndata(\"aids\", package = \"gamlss.data\")\n\n## estimate negative binomial count models\nb1 &lt;- gamlss2(y ~ x + qrt, data = aids, family = NBI)\n\nGAMLSS-RS iteration  1: Global Deviance = 492.7033 eps = 0.148555     \nGAMLSS-RS iteration  2: Global Deviance = 492.6374 eps = 0.000133     \nGAMLSS-RS iteration  3: Global Deviance = 492.6373 eps = 0.000000     \n\nb2 &lt;- gamlss2(y ~ s(x) + s(qrt, bs = \"re\"), data = aids, family = NBI)\n\nGAMLSS-RS iteration  1: Global Deviance = 406.0278 eps = 0.298340     \nGAMLSS-RS iteration  2: Global Deviance = 373.0395 eps = 0.081246     \nGAMLSS-RS iteration  3: Global Deviance = 363.9491 eps = 0.024368     \nGAMLSS-RS iteration  4: Global Deviance = 363.1967 eps = 0.002067     \nGAMLSS-RS iteration  5: Global Deviance = 363.1423 eps = 0.000149     \nGAMLSS-RS iteration  6: Global Deviance = 363.1339 eps = 0.000023     \nGAMLSS-RS iteration  7: Global Deviance = 363.1323 eps = 0.000004     \n\n## compare models\nRsq(b1)\n\n[1] 0.8095853\n\nRsq(b1, type = \"both\")\n\n$CoxSnell\n[1] 0.8095853\n\n$CraggUhler\n[1] 0.809588\n\nRsq(b1, b2)\n\n       b1        b2 \n0.8095853 0.9892885 \n\nGAIC(b1, b2)\n\n        AIC       df\nb2 388.9107 12.88923\nb1 504.6373  6.00000\n\nAIC(b1, b2)\n\n        AIC       df\nb2 388.9107 12.88923\nb1 504.6373  6.00000\n\nBIC(b1, b2)\n\n        AIC       df\nb2 412.1972 12.88923\nb1 515.4773  6.00000\n\n## plot estimated effects\nplot(b2)",
    "crumbs": [
      "Reference",
      "modelstats"
    ]
  },
  {
    "objectID": "man/gamlss2_control.html",
    "href": "man/gamlss2_control.html",
    "title": "gamlss2",
    "section": "",
    "text": "Various parameters that control fitting of GAMLSS using gamlss2.\n\n\n\ngamlss2_control(optimizer = RS, trace = TRUE,\n  flush = TRUE, light = FALSE, expand = TRUE,\n  model = TRUE, x = TRUE, y = TRUE,\n  fixed = FALSE, ...)\n\n\n\n\n\n\n\noptimizer\n\n\nFunction, the optimizer function that should be used for fitting.\n\n\n\n\ntrace\n\n\nLogical, should information be printed while the algorithm is running?\n\n\n\n\nflush\n\n\nLogical, use flush.console for displaying the current output in the console.\n\n\n\n\nlight\n\n\nLogical, if set to light = TRUE, no model frame, response, model matrix and other design matrices will be part of the return value.\n\n\n\n\nexpand\n\n\nLogical, if fewer formulas are supplied than there are parameters of the distribution, should formulas with intercept only formulas be added?\n\n\n\n\nmodel\n\n\nLogical, should the model frame be included as component of the returned object.\n\n\n\n\nx\n\n\nLogical, indicating whether the model matrix should be included as component of the returned object.\n\n\n\n\ny\n\n\nLogical, should the response be included as component of the returned object.\n\n\n\n\nfixed\n\n\nLogical, a named vector of parameters that should be fixed during estimation. See the examples for gamlss2.\n\n\n\n\n…\n\n\nFurther control parameters to be part of the return value, e.g., used within optimizer function RS.\n\n\n\n\n\n\nThe control parameters in gamlss2_control can also be extended, e.g., if another optimization function is used, newly specified control parameters are automatically passed on to this function.\n\n\n\nA list with the arguments specified.\n\n\n\nRS, gamlss2\n\n\n\n\nlibrary(\"gamlss2\")\n\n\ndata(\"abdom\", package = \"gamlss.data\")\n\n## specify the model Formula\nf &lt;- y ~ s(x) | s(x)\n\n## estimate model with different step length\n## control in the RS algorithm\nb1 &lt;- gamlss2(f, data = abdom, family = BCT, step = 1)\nb2 &lt;- gamlss2(f, data = abdom, family = BCT, step = 0.9)",
    "crumbs": [
      "Reference",
      "gamlss2_control"
    ]
  },
  {
    "objectID": "man/gamlss2_control.html#control-parameters",
    "href": "man/gamlss2_control.html#control-parameters",
    "title": "gamlss2",
    "section": "",
    "text": "Various parameters that control fitting of GAMLSS using gamlss2.\n\n\n\ngamlss2_control(optimizer = RS, trace = TRUE,\n  flush = TRUE, light = FALSE, expand = TRUE,\n  model = TRUE, x = TRUE, y = TRUE,\n  fixed = FALSE, ...)\n\n\n\n\n\n\n\noptimizer\n\n\nFunction, the optimizer function that should be used for fitting.\n\n\n\n\ntrace\n\n\nLogical, should information be printed while the algorithm is running?\n\n\n\n\nflush\n\n\nLogical, use flush.console for displaying the current output in the console.\n\n\n\n\nlight\n\n\nLogical, if set to light = TRUE, no model frame, response, model matrix and other design matrices will be part of the return value.\n\n\n\n\nexpand\n\n\nLogical, if fewer formulas are supplied than there are parameters of the distribution, should formulas with intercept only formulas be added?\n\n\n\n\nmodel\n\n\nLogical, should the model frame be included as component of the returned object.\n\n\n\n\nx\n\n\nLogical, indicating whether the model matrix should be included as component of the returned object.\n\n\n\n\ny\n\n\nLogical, should the response be included as component of the returned object.\n\n\n\n\nfixed\n\n\nLogical, a named vector of parameters that should be fixed during estimation. See the examples for gamlss2.\n\n\n\n\n…\n\n\nFurther control parameters to be part of the return value, e.g., used within optimizer function RS.\n\n\n\n\n\n\nThe control parameters in gamlss2_control can also be extended, e.g., if another optimization function is used, newly specified control parameters are automatically passed on to this function.\n\n\n\nA list with the arguments specified.\n\n\n\nRS, gamlss2\n\n\n\n\nlibrary(\"gamlss2\")\n\n\ndata(\"abdom\", package = \"gamlss.data\")\n\n## specify the model Formula\nf &lt;- y ~ s(x) | s(x)\n\n## estimate model with different step length\n## control in the RS algorithm\nb1 &lt;- gamlss2(f, data = abdom, family = BCT, step = 1)\nb2 &lt;- gamlss2(f, data = abdom, family = BCT, step = 0.9)",
    "crumbs": [
      "Reference",
      "gamlss2_control"
    ]
  },
  {
    "objectID": "man/lasso.html",
    "href": "man/lasso.html",
    "title": "gamlss2",
    "section": "",
    "text": "Constructor function and plotting for Lasso penalized model terms for GAMLSS.\n\n\n\n## Model term constructor function.\nla(x, type = 1, const = 1e-05, ...)\n\n## Plotting function.\nplot_lasso(x, terms = NULL,\n  which = c(\"criterion\", \"coefficients\"),\n  zoom = c(3, 4), spar = TRUE, ...)\n\n\n\n\n\n\n\nx\n\n\nFor function la(), a numeric vector or matrix, or a formula. See the examples. For function plot_lasso(), an object returned from gamlss2.\n\n\n\n\ntype\n\n\nInteger or character, the type of the Lasso penalty. type = 1 or type = “normal” uses the normal penalty, type = 2 or type = “group” the group penalty, type = 3 or type = “nominal” the nominal fusion penalty and type = 4 or type = “ordinal” the ordinal fusion penalty.\n\n\n\n\nconst\n\n\nNumeric, the constant that is used for approximating the absolute function.\n\n\n\n\nterms\n\n\nCharacter or integer, the model term that should be plotted. The default terms = NULL is plotting all model terms.\n\n\n\n\nwhich\n\n\nCharacter, should the information criterion or the coefficient paths be plotted? See the examples.\n\n\n\n\nzoom\n\n\nNumeric vector of length 2, the zooming factors for plotting information criteria curves and coefficient paths. The first element sets the distance from the optimum shrinkage parameter lambda to the left side, and the second element to the right side, respectively.\n\n\n\n\nspar\n\n\nLogical, should plotting parameters be automatically set in par?\n\n\n\n\n…\n\n\nFor function la() further control arguments can be passed: The criterion = “bic” for shrinkage parameter selection, arguments for creating the model.matrix if the model term is specified using a formula. For function plot_lasso() arguments like lwd, col, main, etc., that control plotting parameters can be supplied. An additional ridge penalty (elastic net) can be added to each la() term be setting add_ridge = TRUE in the gamlss2() call.\n\n\n\n\n\n\nTo implement the Lasso penalty, an approximation of the absolute value function is used, following the approach by Oelker and Tutz (2015). This enables the use of standard Newton-Raphson-type algorithms for estimation. Each Lasso model term has its own shrinkage parameter, allowing a mix of different penalty types within the model. The framework builds on the methodology of Groll et al. (2019), where coefficients are updated through iteratively reweighted least squares (IWLS). This is feasible due to the absolute function approximation, which results in a quadratic penalty matrix similar to that used in penalized splines. By default, the shrinkage parameters are selected using the Bayesian Information Criterion (BIC).\n\n\n\nThe la() function is used internally within gamlss2 and provides the necessary details for estimating Lasso-type model terms. Essentially, it serves as a special model term, as outlined in specials.\nCurrently, the plot_lasso() function does not return any output.\n\n\n\nAndreas Groll, Julien Hambuckers, Thomas Kneib, and Nikolaus Umlauf (2019). Lasso-type penalization in the framework of generalized additive models for location, scale and shape. Computational Statistics & Data Analysis. doi:10.1016/j.csda.2019.06.005\nOelker Margreth-Ruth and Tutz Gerhard (2015). A uniform framework for combination of penalties in generalized structured models. Adv Data Anal Classif. doi:10.1007/s11634-015-0205-y\n\n\n\ngamlss2, specials.\n\n\n\n\nlibrary(\"gamlss2\")\n\n\ndata(\"rent\", package = \"gamlss.data\")\n\n## transform numeric to factor variables\nrent$Flc &lt;- cut(rent$Fl, breaks = seq(20, 160, by = 10),\n  include.lowest = TRUE)\nrent$Ac &lt;- cut(rent$A, breaks = seq(1890, 1990, by = 10),\n  include.lowest = TRUE)\n\n## set up the model formula for a BCT model\nf &lt;- R ~ la(Flc,type=4) + la(Ac,type=4) + la(loc,type=4) |\n  la(Flc,type=4) + la(Ac,type=4) + la(loc,type=4) |\n  la(Flc,type=4) + la(Ac,type=4) + la(loc,type=4)\n\n## estimation\nb &lt;- gamlss2(f, data = rent, family = BCT)\n\n## summary, shows the estimated degrees of freedom\n## for each model term\nsummary(b)\n\n## plot estimated coefficients\nplot(b)\n\n## plot information criteria curves\n## for each model term.\nplot_lasso(b)\n\n## plot parameter paths.\nplot_lasso(b, which = \"coefficients\")\n\n## plot a single model term.\nplot_lasso(b, which = \"coefficients\", term = 5)\n\n## same with\nplot_lasso(b, which = \"coefficients\", term = \"sigma.la(Ac\")\n\n## zoom out\nplot_lasso(b, which = \"coefficients\", term = 5,\n  zoom = c(8, 7))\n\n## set names\nplot_lasso(b, which = \"coefficients\", term = 5,\n  zoom = c(8, 7), names = c(\"A\", \"B\", \"C\"))\n\n## set title\nplot_lasso(b, which = \"coefficients\", term = 5,\n  zoom = c(8, 7), main = \"Fused Lasso\")\n\n## simulated example using the normal lasso\n## and a matrix as argument for la()\nset.seed(123)\n\n## number of observations and covariates\nn &lt;- 500\nk &lt;- 50\n\n## model matrix\nX &lt;- matrix(rnorm(n * k), n, k)\ncolnames(X) &lt;- paste0(\"x\", 1:k)\n\n## true coefficients\nbeta &lt;- list(\n  \"mu\" = rbinom(k, 1, 0.1),\n  \"sigma\" = rbinom(k, 1, 0.1) * 0.3\n)\n\n## parameters\nmu &lt;- X \nsigma &lt;- exp(-1 + X \n\n## response\ny &lt;- rnorm(n, mean = mu, sd = sigma)\n\n## model formula with nominal fused lasso\nf &lt;- y ~ la(X,type=3) | la(X,type=3)\n\n## estimate model incl. extra ridge penalty\n## for all la() model terms\nb &lt;- gamlss2(f, add_ridge = TRUE)\n\n## plot information criteria curves\nplot_lasso(b)\n\n## coefficient paths\nplot_lasso(b, which = \"coefficients\")\n\n## zoom out\nplot_lasso(b, which = \"coefficients\",\n  zoom = c(8, 9))\n\n## extract coefficients\ncb &lt;- coef(b, full = TRUE)\n\n## compare (without intercept)\ncb_mu &lt;- cb[grep(\"mu.\", names(cb))][-1]\ncb_sigma &lt;- cb[grep(\"sigma.\", names(cb))][-1]\n\n## true positive rate\ntp &lt;- mean(c(cb_mu[beta$mu &gt; 0] &gt; 0,\n  cb_sigma[beta$sigma &gt; 0] &gt; 0))\n\n## false positive rate, needs threshold\nthres &lt;- 0.01\nfp &lt;- mean(c(abs(cb_mu[beta$mu == 0]) &gt; thres,\n  abs(cb_sigma[beta$sigma == 0]) &gt; thres))",
    "crumbs": [
      "Reference",
      "lasso"
    ]
  },
  {
    "objectID": "man/lasso.html#lasso-model-terms",
    "href": "man/lasso.html#lasso-model-terms",
    "title": "gamlss2",
    "section": "",
    "text": "Constructor function and plotting for Lasso penalized model terms for GAMLSS.\n\n\n\n## Model term constructor function.\nla(x, type = 1, const = 1e-05, ...)\n\n## Plotting function.\nplot_lasso(x, terms = NULL,\n  which = c(\"criterion\", \"coefficients\"),\n  zoom = c(3, 4), spar = TRUE, ...)\n\n\n\n\n\n\n\nx\n\n\nFor function la(), a numeric vector or matrix, or a formula. See the examples. For function plot_lasso(), an object returned from gamlss2.\n\n\n\n\ntype\n\n\nInteger or character, the type of the Lasso penalty. type = 1 or type = “normal” uses the normal penalty, type = 2 or type = “group” the group penalty, type = 3 or type = “nominal” the nominal fusion penalty and type = 4 or type = “ordinal” the ordinal fusion penalty.\n\n\n\n\nconst\n\n\nNumeric, the constant that is used for approximating the absolute function.\n\n\n\n\nterms\n\n\nCharacter or integer, the model term that should be plotted. The default terms = NULL is plotting all model terms.\n\n\n\n\nwhich\n\n\nCharacter, should the information criterion or the coefficient paths be plotted? See the examples.\n\n\n\n\nzoom\n\n\nNumeric vector of length 2, the zooming factors for plotting information criteria curves and coefficient paths. The first element sets the distance from the optimum shrinkage parameter lambda to the left side, and the second element to the right side, respectively.\n\n\n\n\nspar\n\n\nLogical, should plotting parameters be automatically set in par?\n\n\n\n\n…\n\n\nFor function la() further control arguments can be passed: The criterion = “bic” for shrinkage parameter selection, arguments for creating the model.matrix if the model term is specified using a formula. For function plot_lasso() arguments like lwd, col, main, etc., that control plotting parameters can be supplied. An additional ridge penalty (elastic net) can be added to each la() term be setting add_ridge = TRUE in the gamlss2() call.\n\n\n\n\n\n\nTo implement the Lasso penalty, an approximation of the absolute value function is used, following the approach by Oelker and Tutz (2015). This enables the use of standard Newton-Raphson-type algorithms for estimation. Each Lasso model term has its own shrinkage parameter, allowing a mix of different penalty types within the model. The framework builds on the methodology of Groll et al. (2019), where coefficients are updated through iteratively reweighted least squares (IWLS). This is feasible due to the absolute function approximation, which results in a quadratic penalty matrix similar to that used in penalized splines. By default, the shrinkage parameters are selected using the Bayesian Information Criterion (BIC).\n\n\n\nThe la() function is used internally within gamlss2 and provides the necessary details for estimating Lasso-type model terms. Essentially, it serves as a special model term, as outlined in specials.\nCurrently, the plot_lasso() function does not return any output.\n\n\n\nAndreas Groll, Julien Hambuckers, Thomas Kneib, and Nikolaus Umlauf (2019). Lasso-type penalization in the framework of generalized additive models for location, scale and shape. Computational Statistics & Data Analysis. doi:10.1016/j.csda.2019.06.005\nOelker Margreth-Ruth and Tutz Gerhard (2015). A uniform framework for combination of penalties in generalized structured models. Adv Data Anal Classif. doi:10.1007/s11634-015-0205-y\n\n\n\ngamlss2, specials.\n\n\n\n\nlibrary(\"gamlss2\")\n\n\ndata(\"rent\", package = \"gamlss.data\")\n\n## transform numeric to factor variables\nrent$Flc &lt;- cut(rent$Fl, breaks = seq(20, 160, by = 10),\n  include.lowest = TRUE)\nrent$Ac &lt;- cut(rent$A, breaks = seq(1890, 1990, by = 10),\n  include.lowest = TRUE)\n\n## set up the model formula for a BCT model\nf &lt;- R ~ la(Flc,type=4) + la(Ac,type=4) + la(loc,type=4) |\n  la(Flc,type=4) + la(Ac,type=4) + la(loc,type=4) |\n  la(Flc,type=4) + la(Ac,type=4) + la(loc,type=4)\n\n## estimation\nb &lt;- gamlss2(f, data = rent, family = BCT)\n\n## summary, shows the estimated degrees of freedom\n## for each model term\nsummary(b)\n\n## plot estimated coefficients\nplot(b)\n\n## plot information criteria curves\n## for each model term.\nplot_lasso(b)\n\n## plot parameter paths.\nplot_lasso(b, which = \"coefficients\")\n\n## plot a single model term.\nplot_lasso(b, which = \"coefficients\", term = 5)\n\n## same with\nplot_lasso(b, which = \"coefficients\", term = \"sigma.la(Ac\")\n\n## zoom out\nplot_lasso(b, which = \"coefficients\", term = 5,\n  zoom = c(8, 7))\n\n## set names\nplot_lasso(b, which = \"coefficients\", term = 5,\n  zoom = c(8, 7), names = c(\"A\", \"B\", \"C\"))\n\n## set title\nplot_lasso(b, which = \"coefficients\", term = 5,\n  zoom = c(8, 7), main = \"Fused Lasso\")\n\n## simulated example using the normal lasso\n## and a matrix as argument for la()\nset.seed(123)\n\n## number of observations and covariates\nn &lt;- 500\nk &lt;- 50\n\n## model matrix\nX &lt;- matrix(rnorm(n * k), n, k)\ncolnames(X) &lt;- paste0(\"x\", 1:k)\n\n## true coefficients\nbeta &lt;- list(\n  \"mu\" = rbinom(k, 1, 0.1),\n  \"sigma\" = rbinom(k, 1, 0.1) * 0.3\n)\n\n## parameters\nmu &lt;- X \nsigma &lt;- exp(-1 + X \n\n## response\ny &lt;- rnorm(n, mean = mu, sd = sigma)\n\n## model formula with nominal fused lasso\nf &lt;- y ~ la(X,type=3) | la(X,type=3)\n\n## estimate model incl. extra ridge penalty\n## for all la() model terms\nb &lt;- gamlss2(f, add_ridge = TRUE)\n\n## plot information criteria curves\nplot_lasso(b)\n\n## coefficient paths\nplot_lasso(b, which = \"coefficients\")\n\n## zoom out\nplot_lasso(b, which = \"coefficients\",\n  zoom = c(8, 9))\n\n## extract coefficients\ncb &lt;- coef(b, full = TRUE)\n\n## compare (without intercept)\ncb_mu &lt;- cb[grep(\"mu.\", names(cb))][-1]\ncb_sigma &lt;- cb[grep(\"sigma.\", names(cb))][-1]\n\n## true positive rate\ntp &lt;- mean(c(cb_mu[beta$mu &gt; 0] &gt; 0,\n  cb_sigma[beta$sigma &gt; 0] &gt; 0))\n\n## false positive rate, needs threshold\nthres &lt;- 0.01\nfp &lt;- mean(c(abs(cb_mu[beta$mu == 0]) &gt; thres,\n  abs(cb_sigma[beta$sigma == 0]) &gt; thres))",
    "crumbs": [
      "Reference",
      "lasso"
    ]
  },
  {
    "objectID": "man/Kumaraswamy.html",
    "href": "man/Kumaraswamy.html",
    "title": "gamlss2",
    "section": "",
    "text": "This function implements the two-parameter Kumaraswamy family for responses in (0, 1).\n\n\n\n## The Kumaraswamy family.\nKumaraswamy(a.link = shiftlog, b.link = shiftlog, ...)\n\n## The exp(x) + shift link specification.\nshiftlog(shift = 1)\n\n\n\n\n\n\n\na.link\n\n\nCharacter or function, the link function to be used for parameter a.\n\n\n\n\nb.link\n\n\nCharacter or function, the link function to be used for parameter b.\n\n\n\n\nshift\n\n\nNumeric, the shift parameter to be used for the link.\n\n\n\n\n…\n\n\nNot used.\n\n\n\n\n\n\nThe Kumaraswamy distribution is a continuous distribution defined on the interval (0, 1). The probability density function is\n\n\\(\\displaystyle f(y; a, b) = aby^{a - 1}(1 - y^a)^{b - 1}\\)\n\\(y \\in (0, 1)\\) is the response, \\(a\\) and \\(b\\) are non-negative parameters.\nThe shiftlog link function is given by:\n\n\\(\\displaystyle \\exp(x) + 1\\)\nThis is the default, since the mode of the distribution is only defined for \\(a \\geq 1\\), \\(b \\geq 1\\).\n\n\n\nThe family returns an object of class “gamlss2.family”.\nFunction shiftlog() returns a link specification object of class “link-glm”.\n\n\n\nKumaraswamy P (1980). “A Generalized Probability Density Function for Double-Bounded Random Processes.” Journal of Hydrology, 46(1), 79–88. doi:https://doi.org/10.1016/0022-1694(80)90036-0\n\n\n\ngamlss2.family, gamlss2\n\n\n\n\nlibrary(\"gamlss2\")\n\n## create family object with\n## different link specifications\nfam &lt;- Kumaraswamy(a.link = shiftlog, b.link = \"log\")\n\n## simulate data\nset.seed(123)\nn &lt;- 1000\nd &lt;- data.frame(\"x\" = runif(n, -pi, pi))\n\n## true parameters\npar &lt;- data.frame(\n  \"a\" = exp(1.2 + sin(d$x)) + 1,\n  \"b\" = 1\n)\n\n## sample response\nd$y &lt;- fam$r(1, par)\n\n## estimate model using the Kumaraswamy family\nb &lt;- gamlss2(y ~ s(x), data = d, family = fam)\n\nGAMLSS-RS iteration  1: Global Deviance = -1503.9982 eps = 0.674665     \nGAMLSS-RS iteration  2: Global Deviance = -1504.1075 eps = 0.000072     \nGAMLSS-RS iteration  3: Global Deviance = -1504.1262 eps = 0.000012     \nGAMLSS-RS iteration  4: Global Deviance = -1504.1294 eps = 0.000002     \n\n## plot estimated effect\nplot(b)\n\n\n\n\n\n\n\n## plot residual diagnostics\nplot(b, which = \"resid\")",
    "crumbs": [
      "Reference",
      "Kumaraswamy"
    ]
  },
  {
    "objectID": "man/Kumaraswamy.html#kumaraswamy-distribution",
    "href": "man/Kumaraswamy.html#kumaraswamy-distribution",
    "title": "gamlss2",
    "section": "",
    "text": "This function implements the two-parameter Kumaraswamy family for responses in (0, 1).\n\n\n\n## The Kumaraswamy family.\nKumaraswamy(a.link = shiftlog, b.link = shiftlog, ...)\n\n## The exp(x) + shift link specification.\nshiftlog(shift = 1)\n\n\n\n\n\n\n\na.link\n\n\nCharacter or function, the link function to be used for parameter a.\n\n\n\n\nb.link\n\n\nCharacter or function, the link function to be used for parameter b.\n\n\n\n\nshift\n\n\nNumeric, the shift parameter to be used for the link.\n\n\n\n\n…\n\n\nNot used.\n\n\n\n\n\n\nThe Kumaraswamy distribution is a continuous distribution defined on the interval (0, 1). The probability density function is\n\n\\(\\displaystyle f(y; a, b) = aby^{a - 1}(1 - y^a)^{b - 1}\\)\n\\(y \\in (0, 1)\\) is the response, \\(a\\) and \\(b\\) are non-negative parameters.\nThe shiftlog link function is given by:\n\n\\(\\displaystyle \\exp(x) + 1\\)\nThis is the default, since the mode of the distribution is only defined for \\(a \\geq 1\\), \\(b \\geq 1\\).\n\n\n\nThe family returns an object of class “gamlss2.family”.\nFunction shiftlog() returns a link specification object of class “link-glm”.\n\n\n\nKumaraswamy P (1980). “A Generalized Probability Density Function for Double-Bounded Random Processes.” Journal of Hydrology, 46(1), 79–88. doi:https://doi.org/10.1016/0022-1694(80)90036-0\n\n\n\ngamlss2.family, gamlss2\n\n\n\n\nlibrary(\"gamlss2\")\n\n## create family object with\n## different link specifications\nfam &lt;- Kumaraswamy(a.link = shiftlog, b.link = \"log\")\n\n## simulate data\nset.seed(123)\nn &lt;- 1000\nd &lt;- data.frame(\"x\" = runif(n, -pi, pi))\n\n## true parameters\npar &lt;- data.frame(\n  \"a\" = exp(1.2 + sin(d$x)) + 1,\n  \"b\" = 1\n)\n\n## sample response\nd$y &lt;- fam$r(1, par)\n\n## estimate model using the Kumaraswamy family\nb &lt;- gamlss2(y ~ s(x), data = d, family = fam)\n\nGAMLSS-RS iteration  1: Global Deviance = -1503.9982 eps = 0.674665     \nGAMLSS-RS iteration  2: Global Deviance = -1504.1075 eps = 0.000072     \nGAMLSS-RS iteration  3: Global Deviance = -1504.1262 eps = 0.000012     \nGAMLSS-RS iteration  4: Global Deviance = -1504.1294 eps = 0.000002     \n\n## plot estimated effect\nplot(b)\n\n\n\n\n\n\n\n## plot residual diagnostics\nplot(b, which = \"resid\")",
    "crumbs": [
      "Reference",
      "Kumaraswamy"
    ]
  },
  {
    "objectID": "man/make.link2.html",
    "href": "man/make.link2.html",
    "title": "gamlss2",
    "section": "",
    "text": "This function is used with the family functions in gamlss2(). Given the name of a link, it returns a link function, an inverse link function, the derivative \\(d\\mu/d\\eta\\), and a function for domain checking. Note that make.link2() is slightly more flexible and also allows functions as arguments.\n\n\n\nmake.link2(link)\n\n\n\n\n\n\n\nlink\n\n\nA character string, see function make.link, or function.\n\n\n\n\n\n\nA list containing the following components:\n\n\n\nlinkfun\n\n\nLink function function(mu).\n\n\n\n\nlinkinv\n\n\nInverse link function function(eta).\n\n\n\n\nmu.eta\n\n\nDerivative function(eta): \\(d\\mu/d\\eta\\).\n\n\n\n\nvalideta\n\n\nFunction function(eta) that returns TRUE if eta is in the domain of linkinv.\n\n\n\n\nname\n\n\nA character string representing the name of the link function.\n\n\n\n\n\n\nmake.link, gamlss2, gamlss2.family.\n\n\n\n\nlibrary(\"gamlss2\")\n\n## character specification\nutils::str(make.link2(\"logit\"))\n\nList of 6\n $ linkfun :function (mu)  \n $ linkinv :function (eta)  \n $ mu.eta  :function (eta)  \n $ valideta:function (eta)  \n $ name    : chr \"logit\"\n $ mu.eta2 :function (eta)  \n - attr(*, \"class\")= chr \"link-glm\"\n\n## functions\nutils::str(make.link2(softplus))\n\nList of 6\n $ linkfun :function (mu)  \n $ linkinv :function (eta)  \n $ mu.eta  :function (eta)  \n $ dmu.eta :function (eta)  \n $ valideta:function (eta)  \n $ name    : chr \"softplus(1)\"\n - attr(*, \"class\")= chr \"link-glm\"",
    "crumbs": [
      "Reference",
      "make.link2"
    ]
  },
  {
    "objectID": "man/make.link2.html#create-a-link-for-families",
    "href": "man/make.link2.html#create-a-link-for-families",
    "title": "gamlss2",
    "section": "",
    "text": "This function is used with the family functions in gamlss2(). Given the name of a link, it returns a link function, an inverse link function, the derivative \\(d\\mu/d\\eta\\), and a function for domain checking. Note that make.link2() is slightly more flexible and also allows functions as arguments.\n\n\n\nmake.link2(link)\n\n\n\n\n\n\n\nlink\n\n\nA character string, see function make.link, or function.\n\n\n\n\n\n\nA list containing the following components:\n\n\n\nlinkfun\n\n\nLink function function(mu).\n\n\n\n\nlinkinv\n\n\nInverse link function function(eta).\n\n\n\n\nmu.eta\n\n\nDerivative function(eta): \\(d\\mu/d\\eta\\).\n\n\n\n\nvalideta\n\n\nFunction function(eta) that returns TRUE if eta is in the domain of linkinv.\n\n\n\n\nname\n\n\nA character string representing the name of the link function.\n\n\n\n\n\n\nmake.link, gamlss2, gamlss2.family.\n\n\n\n\nlibrary(\"gamlss2\")\n\n## character specification\nutils::str(make.link2(\"logit\"))\n\nList of 6\n $ linkfun :function (mu)  \n $ linkinv :function (eta)  \n $ mu.eta  :function (eta)  \n $ valideta:function (eta)  \n $ name    : chr \"logit\"\n $ mu.eta2 :function (eta)  \n - attr(*, \"class\")= chr \"link-glm\"\n\n## functions\nutils::str(make.link2(softplus))\n\nList of 6\n $ linkfun :function (mu)  \n $ linkinv :function (eta)  \n $ mu.eta  :function (eta)  \n $ dmu.eta :function (eta)  \n $ valideta:function (eta)  \n $ name    : chr \"softplus(1)\"\n - attr(*, \"class\")= chr \"link-glm\"",
    "crumbs": [
      "Reference",
      "make.link2"
    ]
  },
  {
    "objectID": "man/fake_formula.html",
    "href": "man/fake_formula.html",
    "title": "gamlss2",
    "section": "",
    "text": "Create a \"fake\" formula from a formula, a Formula, or a list of formulas. The function extracts all necessary variables (transformation of variables), to build a model.frame. The function also extracts all special model terms within the formulas, the information can be used to setup any special model term specification list.\n\n\n\nfake_formula(formula, specials = NULL,\n  nospecials = FALSE, onlyspecials = FALSE)\n\n\n\n\n\n\n\nformula\n\n\nA formula, Formula, or a list of formulas.\n\n\n\n\nspecials\n\n\nCharacter, vector of names of special functions in the formula, see terms.formula.\n\n\n\n\nnospecials\n\n\nLogical, should variables of special model terms be part of the \"fake formula\"?\n\n\n\n\nonlyspecials\n\n\nLogical, should only the special model terms be returned?\n\n\n\n\n\n\nDepending on the input formula, the function returns a formula or Formula. If onlyspecials = TRUE a vector or list of special model term names is returned.\n\n\n\ngamlss2\n\n\n\n\nlibrary(\"gamlss2\")\n\n## basic formula\nf &lt;- y ~ x1 + x2 + log(x3)\nff &lt;- fake_formula(f)\nprint(ff)\n\ny ~ x1 + x2 + log(x3)\n\n## including special model terms\nf &lt;- y ~ x1 + s(x2) + x3 + te(log(x3), x4)\nff &lt;- fake_formula(f)\nprint(ff)\n\n~x1 + x3 + x2 + log(x3) + x4\n\n## multiple parts on the right-hand side\nf &lt;- y ~ x1 + s(x2) + x3 + te(log(x3), x4) | x2 + sqrt(x5)\nff &lt;- fake_formula(f)\nprint(ff)\n\ny ~ x1 + x3 + x2 + log(x3) + x4 | x2 + sqrt(x5)\n\n## collapse all formula parts\nprint(formula(ff, collapse = TRUE))\n\ny ~ x1 + x3 + x2 + log(x3) + x4 + (x2 + sqrt(x5))\n\nprint(formula(ff, collapse = TRUE, update = TRUE))\n\ny ~ x1 + x3 + x2 + log(x3) + x4 + sqrt(x5)\n\n## list of formulas\nf &lt;- list(\n  y ~ x1 + s(x2) + x3 + te(log(x3), x4),\n    ~ x2 + sqrt(x5),\n    ~ z2 + x1 + exp(x3)\n)\nff &lt;- fake_formula(f)\nprint(ff)\n\ny ~ x1 + x3 + x2 + log(x3) + x4 | x2 + sqrt(x5) | z2 + x1 + exp(x3)\n\n## extract separate parts on the right-hand side\nformula(ff, rhs = 1)\n\ny ~ x1 + x3 + x2 + log(x3) + x4\n\nformula(ff, rhs = 2)\n\ny ~ x2 + sqrt(x5)\n\nformula(ff, rhs = 3)\n\ny ~ z2 + x1 + exp(x3)\n\n## formula with multiple responses and multiple parts\nf &lt;- y1 | y2 | y3 ~ x1 + s(x2) + x3 + te(log(x3), x4) | x2 + ti(x5)\nff &lt;- fake_formula(f)\nprint(ff)\n\ny1 | y2 | y3 ~ x1 + x3 + x2 + log(x3) + x4 | x2 + x5\n\n## list of formulas with multiple responses\nf &lt;- list(\n  y1 ~ x1 + s(x2) + x3 + te(log(x3), x4),\n  y2 ~ x2 + sqrt(x5),\n  y3 ~ z2 + x1 + exp(x3) + s(x10)\n)\nff &lt;- fake_formula(f)\n\n## extract only without special terms\nff &lt;- fake_formula(f, nospecials = TRUE)\nprint(ff)\n\ny1 | y2 | y3 ~ x1 + x3 | x2 + sqrt(x5) | z2 + x1 + exp(x3)\n\n## extract only special terms\nff &lt;- fake_formula(f, onlyspecials = TRUE)\nprint(ff)\n\n[[1]]\n[1] \"s(x2)\"          \"te(log(x3),x4)\"\n\n[[2]]\ncharacter(0)\n\n[[3]]\n[1] \"s(x10)\"",
    "crumbs": [
      "Reference",
      "fake_formula"
    ]
  },
  {
    "objectID": "man/fake_formula.html#extended-processing-of-fake-formulas",
    "href": "man/fake_formula.html#extended-processing-of-fake-formulas",
    "title": "gamlss2",
    "section": "",
    "text": "Create a \"fake\" formula from a formula, a Formula, or a list of formulas. The function extracts all necessary variables (transformation of variables), to build a model.frame. The function also extracts all special model terms within the formulas, the information can be used to setup any special model term specification list.\n\n\n\nfake_formula(formula, specials = NULL,\n  nospecials = FALSE, onlyspecials = FALSE)\n\n\n\n\n\n\n\nformula\n\n\nA formula, Formula, or a list of formulas.\n\n\n\n\nspecials\n\n\nCharacter, vector of names of special functions in the formula, see terms.formula.\n\n\n\n\nnospecials\n\n\nLogical, should variables of special model terms be part of the \"fake formula\"?\n\n\n\n\nonlyspecials\n\n\nLogical, should only the special model terms be returned?\n\n\n\n\n\n\nDepending on the input formula, the function returns a formula or Formula. If onlyspecials = TRUE a vector or list of special model term names is returned.\n\n\n\ngamlss2\n\n\n\n\nlibrary(\"gamlss2\")\n\n## basic formula\nf &lt;- y ~ x1 + x2 + log(x3)\nff &lt;- fake_formula(f)\nprint(ff)\n\ny ~ x1 + x2 + log(x3)\n\n## including special model terms\nf &lt;- y ~ x1 + s(x2) + x3 + te(log(x3), x4)\nff &lt;- fake_formula(f)\nprint(ff)\n\n~x1 + x3 + x2 + log(x3) + x4\n\n## multiple parts on the right-hand side\nf &lt;- y ~ x1 + s(x2) + x3 + te(log(x3), x4) | x2 + sqrt(x5)\nff &lt;- fake_formula(f)\nprint(ff)\n\ny ~ x1 + x3 + x2 + log(x3) + x4 | x2 + sqrt(x5)\n\n## collapse all formula parts\nprint(formula(ff, collapse = TRUE))\n\ny ~ x1 + x3 + x2 + log(x3) + x4 + (x2 + sqrt(x5))\n\nprint(formula(ff, collapse = TRUE, update = TRUE))\n\ny ~ x1 + x3 + x2 + log(x3) + x4 + sqrt(x5)\n\n## list of formulas\nf &lt;- list(\n  y ~ x1 + s(x2) + x3 + te(log(x3), x4),\n    ~ x2 + sqrt(x5),\n    ~ z2 + x1 + exp(x3)\n)\nff &lt;- fake_formula(f)\nprint(ff)\n\ny ~ x1 + x3 + x2 + log(x3) + x4 | x2 + sqrt(x5) | z2 + x1 + exp(x3)\n\n## extract separate parts on the right-hand side\nformula(ff, rhs = 1)\n\ny ~ x1 + x3 + x2 + log(x3) + x4\n\nformula(ff, rhs = 2)\n\ny ~ x2 + sqrt(x5)\n\nformula(ff, rhs = 3)\n\ny ~ z2 + x1 + exp(x3)\n\n## formula with multiple responses and multiple parts\nf &lt;- y1 | y2 | y3 ~ x1 + s(x2) + x3 + te(log(x3), x4) | x2 + ti(x5)\nff &lt;- fake_formula(f)\nprint(ff)\n\ny1 | y2 | y3 ~ x1 + x3 + x2 + log(x3) + x4 | x2 + x5\n\n## list of formulas with multiple responses\nf &lt;- list(\n  y1 ~ x1 + s(x2) + x3 + te(log(x3), x4),\n  y2 ~ x2 + sqrt(x5),\n  y3 ~ z2 + x1 + exp(x3) + s(x10)\n)\nff &lt;- fake_formula(f)\n\n## extract only without special terms\nff &lt;- fake_formula(f, nospecials = TRUE)\nprint(ff)\n\ny1 | y2 | y3 ~ x1 + x3 | x2 + sqrt(x5) | z2 + x1 + exp(x3)\n\n## extract only special terms\nff &lt;- fake_formula(f, onlyspecials = TRUE)\nprint(ff)\n\n[[1]]\n[1] \"s(x2)\"          \"te(log(x3),x4)\"\n\n[[2]]\ncharacter(0)\n\n[[3]]\n[1] \"s(x10)\"",
    "crumbs": [
      "Reference",
      "fake_formula"
    ]
  },
  {
    "objectID": "man/gamlss2-package.html",
    "href": "man/gamlss2-package.html",
    "title": "gamlss2",
    "section": "",
    "text": "The primary purpose of this package is to facilitate the creation of advanced infrastructures designed to enhance the Generalized Additive Models for Location Scale and Shape (GAMLSS, Rigby and Stasinopoulos 2005) modeling framework. Notably, the gamlss2 package represents a significant overhaul of its predecessor, gamlss, with a key emphasis on improving estimation speed and incorporating more adaptable infrastructures. These enhancements enable the seamless integration of various algorithms into GAMLSS, including gradient boosting, Bayesian estimation, regression trees, and forests, fostering a more versatile and powerful modeling environment.\nMoreover, the package expands its compatibility by supporting all model terms from the base R mgcv package. Additionally, the gamlss2 package introduces the capability to accommodate more than four parameter families. Essentially, this means that users can now specify any type of model using these new infrastructures, making the package highly flexible and accommodating to a wide range of modeling requirements.\n\n\n\nMaintainer: \n\n\n\nRigby RA, Stasinopoulos DM (2005). “Generalized Additive Models for Location, Scale and Shape (with Discussion).” Journal of the Royal Statistical Society, Series C (Applied Statistics), 54, 507–554. doi:10.1111/j.1467-9876.2005.00510.x\nRigby RA, Stasinopoulos DM, Heller GZ, De Bastiani F (2019). Distributions for Modeling Location, Scale, and Shape: Using GAMLSS in R, Chapman and Hall/CRC. doi:10.1201/9780429298547\nStasinopoulos DM, Rigby RA (2007). “Generalized Additive Models for Location Scale and Shape (GAMLSS) in R.” Journal of Statistical Software, 23(7), 1–46. doi:10.18637/jss.v023.i07\nStasinopoulos DM, Rigby RA, Heller GZ, Voudouris V, De Bastiani F (2017). Flexible Regression and Smoothing: Using GAMLSS in R, Chapman and Hall/CRC. doi:10.1201/b21973\n\n\n\ngamlss2, fake_formula",
    "crumbs": [
      "Reference",
      "gamlss2-package"
    ]
  },
  {
    "objectID": "man/gamlss2-package.html#gamlss-modeling-with-advanced-flexible-infrastructures",
    "href": "man/gamlss2-package.html#gamlss-modeling-with-advanced-flexible-infrastructures",
    "title": "gamlss2",
    "section": "",
    "text": "The primary purpose of this package is to facilitate the creation of advanced infrastructures designed to enhance the Generalized Additive Models for Location Scale and Shape (GAMLSS, Rigby and Stasinopoulos 2005) modeling framework. Notably, the gamlss2 package represents a significant overhaul of its predecessor, gamlss, with a key emphasis on improving estimation speed and incorporating more adaptable infrastructures. These enhancements enable the seamless integration of various algorithms into GAMLSS, including gradient boosting, Bayesian estimation, regression trees, and forests, fostering a more versatile and powerful modeling environment.\nMoreover, the package expands its compatibility by supporting all model terms from the base R mgcv package. Additionally, the gamlss2 package introduces the capability to accommodate more than four parameter families. Essentially, this means that users can now specify any type of model using these new infrastructures, making the package highly flexible and accommodating to a wide range of modeling requirements.\n\n\n\nMaintainer: \n\n\n\nRigby RA, Stasinopoulos DM (2005). “Generalized Additive Models for Location, Scale and Shape (with Discussion).” Journal of the Royal Statistical Society, Series C (Applied Statistics), 54, 507–554. doi:10.1111/j.1467-9876.2005.00510.x\nRigby RA, Stasinopoulos DM, Heller GZ, De Bastiani F (2019). Distributions for Modeling Location, Scale, and Shape: Using GAMLSS in R, Chapman and Hall/CRC. doi:10.1201/9780429298547\nStasinopoulos DM, Rigby RA (2007). “Generalized Additive Models for Location Scale and Shape (GAMLSS) in R.” Journal of Statistical Software, 23(7), 1–46. doi:10.18637/jss.v023.i07\nStasinopoulos DM, Rigby RA, Heller GZ, Voudouris V, De Bastiani F (2017). Flexible Regression and Smoothing: Using GAMLSS in R, Chapman and Hall/CRC. doi:10.1201/b21973\n\n\n\ngamlss2, fake_formula",
    "crumbs": [
      "Reference",
      "gamlss2-package"
    ]
  },
  {
    "objectID": "man/quantiles.html",
    "href": "man/quantiles.html",
    "title": "gamlss2",
    "section": "",
    "text": "The function computes estimated quantiles and optionally produces a plot.\n\n\n\n## S3 method for class 'gamlss2'\nquantile(x, probs = c(0.025, 0.25, 0.50, 0.75, 0.975),\n  variable = NULL, newdata = NULL,\n  plot = FALSE, data = TRUE,\n  n = 100L, ...)\n\n\n\n\n\n\n\nx\n\n\nAn object of class “gamlss2”.\n\n\n\n\nprobs\n\n\nNumeric vector of probabilities with values in [0,1].\n\n\n\n\nvariable\n\n\nLogical or integer, should quantiles be plotted using the covariate data? Note that the variable option is only possible for single covariate models.\n\n\n\n\nnewdata\n\n\nData frame that should be used for computing the quantiles.\n\n\n\n\nplot\n\n\nLogical, should a plot be shown?\n\n\n\n\ndata\n\n\nLogical, should the raw data be added to the plot?\n\n\n\n\nn\n\n\nInteger, number of observations that should be used to compute an equidistant grid for the selected variable.\n\n\n\n\n…\n\n\nArguments such as col, legend = TRUE/FALSE. See the examples.\n\n\n\n\n\n\nThe function applies the predict method to determine the parameters of the response distribution. It then computes the quantiles as specified in the argument probs.\n\n\n\nA data frame of the estimated quantiles.\n\n\n\ngamlss2.\n\n\n\n\nlibrary(\"gamlss2\")\n\n\ndata(\"film90\", package = \"gamlss.data\")\n\n## model formula\nf &lt;-  ~ s(lboopen)\nf &lt;- rep(list(f), 4)\nf[[1]] &lt;- update(f[[1]], lborev1 ~ .)\n\n## estimate model\nb &lt;- gamlss2(f, data = film90, family = BCPE)\n\n## compute quantiles using \"newdata\"\nnd &lt;- film90[1:10, ]\nprint(quantile(b, newdata = nd))\n\n## plot sorted quantiles\nquantile(b, plot = TRUE)\n\n## quantile plot using covariate data\nquantile(b, plot = TRUE, variable = TRUE)\n\n## plot without raw data\nquantile(b, plot = TRUE, variable = TRUE, data = FALSE)",
    "crumbs": [
      "Reference",
      "quantiles"
    ]
  },
  {
    "objectID": "man/quantiles.html#quantiles-for-gamlss",
    "href": "man/quantiles.html#quantiles-for-gamlss",
    "title": "gamlss2",
    "section": "",
    "text": "The function computes estimated quantiles and optionally produces a plot.\n\n\n\n## S3 method for class 'gamlss2'\nquantile(x, probs = c(0.025, 0.25, 0.50, 0.75, 0.975),\n  variable = NULL, newdata = NULL,\n  plot = FALSE, data = TRUE,\n  n = 100L, ...)\n\n\n\n\n\n\n\nx\n\n\nAn object of class “gamlss2”.\n\n\n\n\nprobs\n\n\nNumeric vector of probabilities with values in [0,1].\n\n\n\n\nvariable\n\n\nLogical or integer, should quantiles be plotted using the covariate data? Note that the variable option is only possible for single covariate models.\n\n\n\n\nnewdata\n\n\nData frame that should be used for computing the quantiles.\n\n\n\n\nplot\n\n\nLogical, should a plot be shown?\n\n\n\n\ndata\n\n\nLogical, should the raw data be added to the plot?\n\n\n\n\nn\n\n\nInteger, number of observations that should be used to compute an equidistant grid for the selected variable.\n\n\n\n\n…\n\n\nArguments such as col, legend = TRUE/FALSE. See the examples.\n\n\n\n\n\n\nThe function applies the predict method to determine the parameters of the response distribution. It then computes the quantiles as specified in the argument probs.\n\n\n\nA data frame of the estimated quantiles.\n\n\n\ngamlss2.\n\n\n\n\nlibrary(\"gamlss2\")\n\n\ndata(\"film90\", package = \"gamlss.data\")\n\n## model formula\nf &lt;-  ~ s(lboopen)\nf &lt;- rep(list(f), 4)\nf[[1]] &lt;- update(f[[1]], lborev1 ~ .)\n\n## estimate model\nb &lt;- gamlss2(f, data = film90, family = BCPE)\n\n## compute quantiles using \"newdata\"\nnd &lt;- film90[1:10, ]\nprint(quantile(b, newdata = nd))\n\n## plot sorted quantiles\nquantile(b, plot = TRUE)\n\n## quantile plot using covariate data\nquantile(b, plot = TRUE, variable = TRUE)\n\n## plot without raw data\nquantile(b, plot = TRUE, variable = TRUE, data = FALSE)",
    "crumbs": [
      "Reference",
      "quantiles"
    ]
  },
  {
    "objectID": "man/HarzTraffic.html",
    "href": "man/HarzTraffic.html",
    "title": "gamlss2",
    "section": "",
    "text": "This dataset contains daily traffic counts close to Sonnenberg, located in the Harz region in Germany. It covers a period of nearly three years, from 2021-01-01 to 2023-11-30.\n\n\n\ndata(\"HarzTraffic\", package = \"gamlss2\")\n\n\n\nA data frame containing 1057 observations on 16 variables.\n\n\ndate\n\n\nDate, the date of the record.\n\n\nyday\n\n\nInteger, the day of the year.\n\n\nbikes\n\n\nInteger, the number of motorcycles on that day.\n\n\ncars\n\n\nInteger, the number of cars on that day.\n\n\ntrucks\n\n\nInteger, the number of trucks on that day.\n\n\nothers\n\n\nInteger, the number of other vehicles on that day.\n\n\ntempmin\n\n\nNumeric, minimum temperature in \\(^{\\circ}C\\).\n\n\ntempmax\n\n\nNumeric, maximum temperature in \\(^{\\circ}C\\).\n\n\ntemp\n\n\nNumeric, mean temperature in \\(^{\\circ}C\\).\n\n\nhumidity\n\n\nNumeric, mean relative humidity in percent.\n\n\ntempdew\n\n\nNumeric, average dewpoint temperature in \\(^{\\circ}C\\).\n\n\ncloudiness\n\n\nNumeric, average cloud cover in percent.\n\n\nrain\n\n\nNumeric, amount of precipitation in mm (snow and rain).\n\n\nsunshine\n\n\nNumeric, sunshine duration in minutes.\n\n\nwind\n\n\nNumeric, mean wind speed in m/s.\n\n\nwindmax\n\n\nNumeric, maximum wind speed in m/s.\n\n\n\n\n\nWeather Data:\n\n\nData Source:\n\n\nDeutscher Wetterdienst (DWD), Climate Data Center (CDC).\n\n\nLicence:\n\n\nCC BY 4.0\n\n\nURL:\n\n\nhttps://opendata.dwd.de/climate_environment/CDC/\n\n\nStation:\n\n\nWernigerode (5490; Sachsen-Anhalt)\n\n\nPosition:\n\n\n10.7686/51.8454/233 (lon, lat, alt, EPSG 4326)\n\n\nTraffic Data:\n\n\nData Source:\n\n\nBundesanstalt für Strassenwesen (BASt)\n\n\nLicence:\n\n\nCC BY 4.0\n\n\nURL:\n\n\nhttps://www.bast.de, https://www.bast.de/DE/Verkehrstechnik/Fachthemen/v2-verkehrszaehlung/Verkehrszaehlung.html\n\n\n\n\n\n\nlibrary(\"gamlss2\")\n\n## seasonal variation of motorcycle counts at Sonnenberg/Harz\ndata(\"HarzTraffic\", package = \"gamlss2\")\nplot(bikes ~ yday, data = HarzTraffic)\n\n\n\n\n\n\n\n## count distribution\nbarplot(table(HarzTraffic$bikes))\n\n\n\n\n\n\n\n## negative binomial seasonal model using cyclic splines\nm &lt;- gamlss2(bikes ~ s(yday, bs = \"cc\") | s(yday, bs = \"cc\"),\n  data = HarzTraffic, family = NBI)\n\nGAMLSS-RS iteration  1: Global Deviance = 10163.082 eps = 0.148402     \nGAMLSS-RS iteration  2: Global Deviance = 10151.144 eps = 0.001174     \nGAMLSS-RS iteration  3: Global Deviance = 10151.1409 eps = 0.000000     \n\n## visualize effects\nplot(m)\n\n\n\n\n\n\n\n## residual diagnostics\nplot(m, which = \"resid\")\n\n\n\n\n\n\n\n## fitted parameters for each day of the year\nnd &lt;- data.frame(yday = 1:365)\npar &lt;- predict(m, newdata = nd)\n\n## corresponding quantiles\np &lt;- sapply(c(0.05, 0.5, 0.95), function(q) family(m)$q(q, par))\n\n## visualization\nplot(bikes ~ yday, data = HarzTraffic, pch = 19, col = gray(0.1, alpha = 0.3))\nmatplot(nd$yday, p, type = \"l\", lty = c(2, 1, 2), lwd = 2, col = 4, add = TRUE)",
    "crumbs": [
      "Reference",
      "HarzTraffic"
    ]
  },
  {
    "objectID": "man/HarzTraffic.html#traffic-counts-at-sonnenberg-in-the-harz-region",
    "href": "man/HarzTraffic.html#traffic-counts-at-sonnenberg-in-the-harz-region",
    "title": "gamlss2",
    "section": "",
    "text": "This dataset contains daily traffic counts close to Sonnenberg, located in the Harz region in Germany. It covers a period of nearly three years, from 2021-01-01 to 2023-11-30.\n\n\n\ndata(\"HarzTraffic\", package = \"gamlss2\")\n\n\n\nA data frame containing 1057 observations on 16 variables.\n\n\ndate\n\n\nDate, the date of the record.\n\n\nyday\n\n\nInteger, the day of the year.\n\n\nbikes\n\n\nInteger, the number of motorcycles on that day.\n\n\ncars\n\n\nInteger, the number of cars on that day.\n\n\ntrucks\n\n\nInteger, the number of trucks on that day.\n\n\nothers\n\n\nInteger, the number of other vehicles on that day.\n\n\ntempmin\n\n\nNumeric, minimum temperature in \\(^{\\circ}C\\).\n\n\ntempmax\n\n\nNumeric, maximum temperature in \\(^{\\circ}C\\).\n\n\ntemp\n\n\nNumeric, mean temperature in \\(^{\\circ}C\\).\n\n\nhumidity\n\n\nNumeric, mean relative humidity in percent.\n\n\ntempdew\n\n\nNumeric, average dewpoint temperature in \\(^{\\circ}C\\).\n\n\ncloudiness\n\n\nNumeric, average cloud cover in percent.\n\n\nrain\n\n\nNumeric, amount of precipitation in mm (snow and rain).\n\n\nsunshine\n\n\nNumeric, sunshine duration in minutes.\n\n\nwind\n\n\nNumeric, mean wind speed in m/s.\n\n\nwindmax\n\n\nNumeric, maximum wind speed in m/s.\n\n\n\n\n\nWeather Data:\n\n\nData Source:\n\n\nDeutscher Wetterdienst (DWD), Climate Data Center (CDC).\n\n\nLicence:\n\n\nCC BY 4.0\n\n\nURL:\n\n\nhttps://opendata.dwd.de/climate_environment/CDC/\n\n\nStation:\n\n\nWernigerode (5490; Sachsen-Anhalt)\n\n\nPosition:\n\n\n10.7686/51.8454/233 (lon, lat, alt, EPSG 4326)\n\n\nTraffic Data:\n\n\nData Source:\n\n\nBundesanstalt für Strassenwesen (BASt)\n\n\nLicence:\n\n\nCC BY 4.0\n\n\nURL:\n\n\nhttps://www.bast.de, https://www.bast.de/DE/Verkehrstechnik/Fachthemen/v2-verkehrszaehlung/Verkehrszaehlung.html\n\n\n\n\n\n\nlibrary(\"gamlss2\")\n\n## seasonal variation of motorcycle counts at Sonnenberg/Harz\ndata(\"HarzTraffic\", package = \"gamlss2\")\nplot(bikes ~ yday, data = HarzTraffic)\n\n\n\n\n\n\n\n## count distribution\nbarplot(table(HarzTraffic$bikes))\n\n\n\n\n\n\n\n## negative binomial seasonal model using cyclic splines\nm &lt;- gamlss2(bikes ~ s(yday, bs = \"cc\") | s(yday, bs = \"cc\"),\n  data = HarzTraffic, family = NBI)\n\nGAMLSS-RS iteration  1: Global Deviance = 10163.082 eps = 0.148402     \nGAMLSS-RS iteration  2: Global Deviance = 10151.144 eps = 0.001174     \nGAMLSS-RS iteration  3: Global Deviance = 10151.1409 eps = 0.000000     \n\n## visualize effects\nplot(m)\n\n\n\n\n\n\n\n## residual diagnostics\nplot(m, which = \"resid\")\n\n\n\n\n\n\n\n## fitted parameters for each day of the year\nnd &lt;- data.frame(yday = 1:365)\npar &lt;- predict(m, newdata = nd)\n\n## corresponding quantiles\np &lt;- sapply(c(0.05, 0.5, 0.95), function(q) family(m)$q(q, par))\n\n## visualization\nplot(bikes ~ yday, data = HarzTraffic, pch = 19, col = gray(0.1, alpha = 0.3))\nmatplot(nd$yday, p, type = \"l\", lty = c(2, 1, 2), lwd = 2, col = 4, add = TRUE)",
    "crumbs": [
      "Reference",
      "HarzTraffic"
    ]
  },
  {
    "objectID": "man/plots.html",
    "href": "man/plots.html",
    "title": "gamlss2",
    "section": "",
    "text": "Plotting methods for objects of class “gamlss2” and “gamlss2.list”, which can be used for effect plots of model terms or residual plots. Note that effect plots of model terms with more than two covariates are not supported, for this purpose use the predict method.\n\n\n\n## S3 method for class 'gamlss2'\nplot(x, parameter = NULL,\n  which = \"effects\", terms = NULL,\n  scale = TRUE, spar = TRUE, ...)\n\n## S3 method for class 'gamlss2.list'\nplot(x, parameter = NULL, which = \"effects\",\n  terms = NULL, spar = TRUE, legend = TRUE, ...)\n\n\n\n\n\n\n\nx\n\n\nAn object of class “gamlss2” or “gamlss2.list”, which can be created by using the c() method combining “gamlss2” objects. See th examples.\n\n\n\n\nparameter\n\n\nCharacter or integer. For which parameter/model/what should the plots be created? Note that instead of argument parameter plots can also be specified passing argument model and what to ….\n\n\n\n\nwhich\n\n\nCharacter or integer, selects the type of plot: “effects” produces effect plots of (special) model terms, “hist-resid” shows a histogram of residuals, “qq-resid” shows a quantile-quantile plot of residuals, “scatter-resid” shows a scatter plot of residuals with fitted values for the distribution mean (or median, if available in the family object).\n\n\n\n\nterms\n\n\nCharacter or integer. For which model term should the plot(s) be created?\n\n\n\n\nscale\n\n\nIf set to 1, effect plots all have the same scale on the y-axis. If set to 0 each effect plot has its own scale for the y-axis.\n\n\n\n\nspar\n\n\nShould graphical parameters be set?\n\n\n\n\nlegend\n\n\nShould a legend be added using multiple model plots?\n\n\n\n\n…\n\n\nArguments such as lwd, lty, col, legend = TRUE (for multiple model plots), a.o., depending on the type of plot. See the examples.\n\n\n\n\n\n\ngamlss2.\n\n\n\n\nlibrary(\"gamlss2\")\n\n\ndata(\"film90\", package = \"gamlss.data\")\n\n## model formula\nf &lt;-  ~ s(lboopen) + s(lnosc)\nf &lt;- rep(list(f), 4)\nf[[1]] &lt;- update(f[[1]], lborev1 ~ .)\n\n## estimate model\nb1 &lt;- gamlss2(f, data = film90, family = BCCG)\n\n## plot effects (default)\nplot(b1)\n\n## plot specific effect\nplot(b1, parameter = \"sigma\")\nplot(b1, model = \"sigma\")\nplot(b1, model = \"nu\", term = 1)\nplot(b1, model = \"nu\", term = 2)\nplot(b1, model = \"nu\", term = \"lnosc\")\nplot(b1, term = \"lnosc\")\n\n## plot all residual diagnostics\nplot(b1, which = \"resid\")\n\n## single diagnostic plots\nplot(b1, which = \"hist-resid\")\nplot(b1, which = \"qq-resid\")\nplot(b1, which = \"wp-resid\")\nplot(b1, which = \"scatter-resid\")\n\n## estimate another model\nb2 &lt;- gamlss2(f, data = film90, family = BCPE)\n\n## compare estimated effects\nplot(c(b1, b2))\nplot(c(b1, b2), term = \"lboopen\",\n  col = c(1, 4), lwd = 3, lty = 1,\n  pos = c(\"topleft\", \"topright\", \"bottomleft\", \"bottomright\"))\nplot(c(b1, b2), model = \"sigma\")\nplot(c(b1, b2), model = \"sigma\", term = 2)\nplot(c(b1, b2), model = c(\"mu\", \"nu\"))",
    "crumbs": [
      "Reference",
      "plots"
    ]
  },
  {
    "objectID": "man/plots.html#plotting-gamlss",
    "href": "man/plots.html#plotting-gamlss",
    "title": "gamlss2",
    "section": "",
    "text": "Plotting methods for objects of class “gamlss2” and “gamlss2.list”, which can be used for effect plots of model terms or residual plots. Note that effect plots of model terms with more than two covariates are not supported, for this purpose use the predict method.\n\n\n\n## S3 method for class 'gamlss2'\nplot(x, parameter = NULL,\n  which = \"effects\", terms = NULL,\n  scale = TRUE, spar = TRUE, ...)\n\n## S3 method for class 'gamlss2.list'\nplot(x, parameter = NULL, which = \"effects\",\n  terms = NULL, spar = TRUE, legend = TRUE, ...)\n\n\n\n\n\n\n\nx\n\n\nAn object of class “gamlss2” or “gamlss2.list”, which can be created by using the c() method combining “gamlss2” objects. See th examples.\n\n\n\n\nparameter\n\n\nCharacter or integer. For which parameter/model/what should the plots be created? Note that instead of argument parameter plots can also be specified passing argument model and what to ….\n\n\n\n\nwhich\n\n\nCharacter or integer, selects the type of plot: “effects” produces effect plots of (special) model terms, “hist-resid” shows a histogram of residuals, “qq-resid” shows a quantile-quantile plot of residuals, “scatter-resid” shows a scatter plot of residuals with fitted values for the distribution mean (or median, if available in the family object).\n\n\n\n\nterms\n\n\nCharacter or integer. For which model term should the plot(s) be created?\n\n\n\n\nscale\n\n\nIf set to 1, effect plots all have the same scale on the y-axis. If set to 0 each effect plot has its own scale for the y-axis.\n\n\n\n\nspar\n\n\nShould graphical parameters be set?\n\n\n\n\nlegend\n\n\nShould a legend be added using multiple model plots?\n\n\n\n\n…\n\n\nArguments such as lwd, lty, col, legend = TRUE (for multiple model plots), a.o., depending on the type of plot. See the examples.\n\n\n\n\n\n\ngamlss2.\n\n\n\n\nlibrary(\"gamlss2\")\n\n\ndata(\"film90\", package = \"gamlss.data\")\n\n## model formula\nf &lt;-  ~ s(lboopen) + s(lnosc)\nf &lt;- rep(list(f), 4)\nf[[1]] &lt;- update(f[[1]], lborev1 ~ .)\n\n## estimate model\nb1 &lt;- gamlss2(f, data = film90, family = BCCG)\n\n## plot effects (default)\nplot(b1)\n\n## plot specific effect\nplot(b1, parameter = \"sigma\")\nplot(b1, model = \"sigma\")\nplot(b1, model = \"nu\", term = 1)\nplot(b1, model = \"nu\", term = 2)\nplot(b1, model = \"nu\", term = \"lnosc\")\nplot(b1, term = \"lnosc\")\n\n## plot all residual diagnostics\nplot(b1, which = \"resid\")\n\n## single diagnostic plots\nplot(b1, which = \"hist-resid\")\nplot(b1, which = \"qq-resid\")\nplot(b1, which = \"wp-resid\")\nplot(b1, which = \"scatter-resid\")\n\n## estimate another model\nb2 &lt;- gamlss2(f, data = film90, family = BCPE)\n\n## compare estimated effects\nplot(c(b1, b2))\nplot(c(b1, b2), term = \"lboopen\",\n  col = c(1, 4), lwd = 3, lty = 1,\n  pos = c(\"topleft\", \"topright\", \"bottomleft\", \"bottomright\"))\nplot(c(b1, b2), model = \"sigma\")\nplot(c(b1, b2), model = \"sigma\", term = 2)\nplot(c(b1, b2), model = c(\"mu\", \"nu\"))",
    "crumbs": [
      "Reference",
      "plots"
    ]
  },
  {
    "objectID": "man/storms.html",
    "href": "man/storms.html",
    "title": "gamlss2",
    "section": "",
    "text": "According to the Beaufort scale, severe storms occur from a wind speed of 24.5-28.4 m/s. This dataset contains annual severe storm counts from weather stations in Germany from 1981 to 2021.\n\n\n\ndata(\"storms\", package = \"gamlss2\")\n\n\n\nA data frame containing 3494 observations on 8 variables.\n\n\nid\n\n\nFactor, the weather station id.\n\n\ncounty\n\n\nCharacter, the county in Germany where the weather station is located.\n\n\nstate\n\n\nCharacter, the state in Germany where the weather station is located.\n\n\nyear\n\n\nInteger, the year the observation was measured.\n\n\ncounts\n\n\nInteger, the number of severe storms in this year.\n\n\nalt\n\n\nNumeric, the altitude in meters above sea level of the weather station.\n\n\nlon\n\n\nNumeric, the longitude coordinate of the weather station.\n\n\nlat\n\n\nNumeric, the latitude coordinate of the weather station.\n\n\n\n\n\nSevere Storms Data:\n\n\nData Source:\n\n\nDeutscher Wetterdienst (DWD), Climate Data Center (CDC).\n\n\nLicence:\n\n\nCC BY 4.0\n\n\nURL:\n\n\nhttps://opendata.dwd.de/climate_environment/CDC/\n\n\nCoordinate Reference System:\n\n\nLongitude/latitude and the WGS84 datum.\n\n\n\n\n\n\nlibrary(\"gamlss2\")\n\n## load the data\ndata(\"storms\", package = \"gamlss2\")\n\n## yearly observations\nplot(counts ~ year, data = storms)\n\n## count distribution\nbarplot(table(storms$counts))\n\n## NBI model\n## model formula including spatial effect\n  s(year) + s(alt) + s(lon, lat)\n\n## estimate model\nb &lt;- gamlss2(f, data = storms, family = NBI)\n\n## estimated effects\nplot(b)\n\n## residual diagnostics\nplot(b, which = \"resid\")",
    "crumbs": [
      "Reference",
      "storms"
    ]
  },
  {
    "objectID": "man/storms.html#severe-storms-in-germany",
    "href": "man/storms.html#severe-storms-in-germany",
    "title": "gamlss2",
    "section": "",
    "text": "According to the Beaufort scale, severe storms occur from a wind speed of 24.5-28.4 m/s. This dataset contains annual severe storm counts from weather stations in Germany from 1981 to 2021.\n\n\n\ndata(\"storms\", package = \"gamlss2\")\n\n\n\nA data frame containing 3494 observations on 8 variables.\n\n\nid\n\n\nFactor, the weather station id.\n\n\ncounty\n\n\nCharacter, the county in Germany where the weather station is located.\n\n\nstate\n\n\nCharacter, the state in Germany where the weather station is located.\n\n\nyear\n\n\nInteger, the year the observation was measured.\n\n\ncounts\n\n\nInteger, the number of severe storms in this year.\n\n\nalt\n\n\nNumeric, the altitude in meters above sea level of the weather station.\n\n\nlon\n\n\nNumeric, the longitude coordinate of the weather station.\n\n\nlat\n\n\nNumeric, the latitude coordinate of the weather station.\n\n\n\n\n\nSevere Storms Data:\n\n\nData Source:\n\n\nDeutscher Wetterdienst (DWD), Climate Data Center (CDC).\n\n\nLicence:\n\n\nCC BY 4.0\n\n\nURL:\n\n\nhttps://opendata.dwd.de/climate_environment/CDC/\n\n\nCoordinate Reference System:\n\n\nLongitude/latitude and the WGS84 datum.\n\n\n\n\n\n\nlibrary(\"gamlss2\")\n\n## load the data\ndata(\"storms\", package = \"gamlss2\")\n\n## yearly observations\nplot(counts ~ year, data = storms)\n\n## count distribution\nbarplot(table(storms$counts))\n\n## NBI model\n## model formula including spatial effect\n  s(year) + s(alt) + s(lon, lat)\n\n## estimate model\nb &lt;- gamlss2(f, data = storms, family = NBI)\n\n## estimated effects\nplot(b)\n\n## residual diagnostics\nplot(b, which = \"resid\")",
    "crumbs": [
      "Reference",
      "storms"
    ]
  },
  {
    "objectID": "man/gamlss2.html",
    "href": "man/gamlss2.html",
    "title": "gamlss2",
    "section": "",
    "text": "Estimation of generalized additive models for location scale and shape (GAMLSS). The model fitting function gamlss2() provides flexible infrastructures to estimate the parameters of a response distribution. The number of distributional parameters is not fixed, see gamlss2.family. Moreover, gamlss2() supports all smooth term constructors from the mgcv package in addition to the classical model terms as provided by gamlss and gamlss.add.\n\n\n\ngamlss2(x, ...)\n\n## S3 method for class 'formula'\ngamlss2(formula, data, family = NO,\n  subset, na.action, weights, offset, start = NULL,\n  control = gamlss2_control(...), ...)\n\n## S3 method for class 'list'\ngamlss2(x, ...)\n\n\n\n\n\n\n\nformula\n\n\nA GAM-type formula or Formula. All smooth terms of the mgcv package are supported, see also formula.gam.\n\n\n\n\nx\n\n\nFor gamlss.list() x is a list of formulas.\n\n\n\n\ndata\n\n\nA data frame or list or environment containing the variables in the model. If not found in data, the variables are taken from environment(formula), typically the environment from which gamlss2 is called.\n\n\n\n\nfamily\n\n\nA gamlss.family or gamlss2.family object used to define distribution and the link functions of the parameters.\n\n\n\n\nsubset\n\n\nAn optional vector specifying a subset of observations to be used in the fitting process.\n\n\n\n\nna.action\n\n\nNA processing for setting up the model.frame.\n\n\n\n\nweights\n\n\nAn optional vector of prior weights to be used in the fitting process. Should be NULL or a numeric vector.\n\n\n\n\noffset\n\n\nThis can be used to specify an a priori known components to be included in the linear predictors during fitting. Please note that if only a single numeric vector is provided, the offset will be assigned to the first specified parameter of the distribution. In the case of multiple offsets, a data frame or list must be supplied. Each offset is assigned in the same order as the parameters of the distribution specified in the family object.\n\n\n\n\nstart\n\n\nStarting values for estimation algorithms.\n\n\n\n\ncontrol\n\n\nA list of control arguments, see gamlss2_control.\n\n\n\n\n…\n\n\nArguments passed to gamlss2_control.\n\n\n\n\n\n\nThe model fitting function gamlss2() provides flexible infrastructures for the estimation of GAMLSS.\n\n\nDistributional models are specified using family objects, either from the gamlss.dist package or using gamlss2.family objects.\n\n\nEstimation is carried out through a Newton-Raphson/Fisher scoring algorithm, see function RS. The estimation algorithms can also be exchanged using gamlss2_control. Additionally, if an optimizer is specified by the family object, this optimizer function will be employed for estimation.\n\n\nThe return value is determined by the object returned from the optimizer function, typically an object of class “gamlss2”. Default methods and extractor functions are available for this class. Nevertheless, users have the flexibility to supply their own optimizer function, along with user-specific methods tailored for the returned object.\n\n\n\n\n\nThe return value is determined by the object returned from the optimizer function. By default, the optimization is performed using the RS optimizer function (see gamlss2_control), yielding an object of class “gamlss2”. Default methods and extractor functions are available for this class.\n\n\n\nRigby RA, Stasinopoulos DM (2005). “Generalized Additive Models for Location, Scale and Shape (with Discussion).” Journal of the Royal Statistical Society, Series C (Applied Statistics), 54, 507–554. doi:10.1111/j.1467-9876.2005.00510.x\nRigby RA, Stasinopoulos DM, Heller GZ, De Bastiani F (2019). Distributions for Modeling Location, Scale, and Shape: Using GAMLSS in R, Chapman and Hall/CRC. doi:10.1201/9780429298547\nStasinopoulos DM, Rigby RA (2007). “Generalized Additive Models for Location Scale and Shape (GAMLSS) in R.” Journal of Statistical Software, 23(7), 1–46. doi:10.18637/jss.v023.i07\nStasinopoulos DM, Rigby RA, Heller GZ, Voudouris V, De Bastiani F (2017). Flexible Regression and Smoothing: Using GAMLSS in R, Chapman and Hall/CRC. doi:10.1201/b21973\n\n\n\nRS, gamlss2_control, gamlss2.family\n\n\n\n\nlibrary(\"gamlss2\")\n\n\n## load the abdominal circumference data\ndata(\"abdom\", package = \"gamlss.data\")\n\n## specify the model Formula\nf &lt;- y ~ s(x) | s(x) | s(x) | s(x)\n\n## estimate model\nb &lt;- gamlss2(f, data = abdom, family = BCT)\n\nGAMLSS-RS iteration  1: Global Deviance = 4774.4683 eps = 0.534345     \nGAMLSS-RS iteration  2: Global Deviance = 4770.229 eps = 0.000887     \nGAMLSS-RS iteration  3: Global Deviance = 4770.1663 eps = 0.000013     \nGAMLSS-RS iteration  4: Global Deviance = 4770.1554 eps = 0.000002     \n\n## model summary\nsummary(b)\n\nCall:\ngamlss2(formula = f, data = abdom, family = BCT)\n---\nFamily: BCT \nLink function: mu = identity, sigma = log, nu = identity, tau = log\n*--------\nParameter: mu \n---\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  226.334      1.257     180   &lt;2e-16 ***\n---\nSmooth terms:\n     s(x)\nedf 4.551\n*--------\nParameter: sigma \n---\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -2.92264    0.01101  -265.5   &lt;2e-16 ***\n---\nSmooth terms:\n      s(x)\nedf 2.5639\n*--------\nParameter: nu \n---\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.18021    0.04599  -3.918 9.95e-05 ***\n---\nSmooth terms:\n      s(x)\nedf 1.0015\n*--------\nParameter: tau \n---\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.6548     0.0144   184.4   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n---\nSmooth terms:\n      s(x)\nedf 1.0042\n*--------\nn = 610 df =  13.12 res.df =  596.88\nDeviance = 4770.1554 Null Dev. Red. = 33.39%\nAIC = 4796.3966 elapsed =  0.80sec\n\n## plot estimated effects\nplot(b, which = \"effects\")\n\n\n\n\n\n\n\n## plot diagnostics\nplot(b, which = \"resid\")\n\n\n\n\n\n\n\n## predict parameters\npar &lt;- predict(b)\n\n## predict quantiles\npq &lt;- sapply(c(0.05, 0.5, 0.95), function(q) family(b)$q(q, par))\n\n## visualize\nplot(y ~ x, data = abdom, pch = 19,\n  col = rgb(0.1, 0.1, 0.1, alpha = 0.3))\nmatplot(abdom$x, pq, type = \"l\", lwd = 2,\n  lty = 1, col = 4, add = TRUE)\n\n\n\n\n\n\n\n## use of starting values\nm &lt;- gamlss2(f, data = abdom, family = BCT,\n  start = c(mu = 200, sigma = 0.1, nu = 0, tau = 10))\n\nGAMLSS-RS iteration  1: Global Deviance = 4789.7797 eps = 0.556012     \nGAMLSS-RS iteration  2: Global Deviance = 4774.5657 eps = 0.003176     \nGAMLSS-RS iteration  3: Global Deviance = 4771.4193 eps = 0.000658     \nGAMLSS-RS iteration  4: Global Deviance = 4769.9947 eps = 0.000298     \nGAMLSS-RS iteration  5: Global Deviance = 4769.9556 eps = 0.000008     \n\n## fix some parameters\nm &lt;- gamlss2(f, data = abdom, family = BCT,\n  start = c(mu = 200, sigma = 0.1, nu = 0, tau = 10),\n  fixed = c(nu = TRUE, tau = TRUE))\n\nGAMLSS-RS iteration  1: Global Deviance = 4799.422 eps = 0.555118     \nGAMLSS-RS iteration  2: Global Deviance = 4795.2807 eps = 0.000862     \nGAMLSS-RS iteration  3: Global Deviance = 4795.2668 eps = 0.000002     \n\n## estimated coefficients (intercepts)\ncoef(m)\n\n   mu.p.(Intercept) sigma.p.(Intercept)    nu.p.(Intercept)   tau.p.(Intercept) \n         226.347632           -2.922923            0.000000            2.302585 \n\n## starting values using full predictors\nm &lt;- gamlss2(f, data = abdom, family = BCT,\n  start = fitted(m))\n\nGAMLSS-RS iteration  1: Global Deviance = 4902.0767 eps = 0.372276     \nGAMLSS-RS iteration  2: Global Deviance = 4775.8465 eps = 0.025750     \nGAMLSS-RS iteration  3: Global Deviance = 4775.0302 eps = 0.000170     \nGAMLSS-RS iteration  4: Global Deviance = 4774.9582 eps = 0.000015     \nGAMLSS-RS iteration  5: Global Deviance = 4774.9519 eps = 0.000001     \n\n## same with\nm &lt;- gamlss2(f, data = abdom, family = BCT,\n  start = m)\n\nGAMLSS-RS iteration  1: Global Deviance = 4774.4683 eps = 0.534345     \nGAMLSS-RS iteration  2: Global Deviance = 4770.229 eps = 0.000887     \nGAMLSS-RS iteration  3: Global Deviance = 4770.1663 eps = 0.000013     \nGAMLSS-RS iteration  4: Global Deviance = 4770.1554 eps = 0.000002",
    "crumbs": [
      "Reference",
      "gamlss2"
    ]
  },
  {
    "objectID": "man/gamlss2.html#generalized-additive-models-for-location-scale-and-shape",
    "href": "man/gamlss2.html#generalized-additive-models-for-location-scale-and-shape",
    "title": "gamlss2",
    "section": "",
    "text": "Estimation of generalized additive models for location scale and shape (GAMLSS). The model fitting function gamlss2() provides flexible infrastructures to estimate the parameters of a response distribution. The number of distributional parameters is not fixed, see gamlss2.family. Moreover, gamlss2() supports all smooth term constructors from the mgcv package in addition to the classical model terms as provided by gamlss and gamlss.add.\n\n\n\ngamlss2(x, ...)\n\n## S3 method for class 'formula'\ngamlss2(formula, data, family = NO,\n  subset, na.action, weights, offset, start = NULL,\n  control = gamlss2_control(...), ...)\n\n## S3 method for class 'list'\ngamlss2(x, ...)\n\n\n\n\n\n\n\nformula\n\n\nA GAM-type formula or Formula. All smooth terms of the mgcv package are supported, see also formula.gam.\n\n\n\n\nx\n\n\nFor gamlss.list() x is a list of formulas.\n\n\n\n\ndata\n\n\nA data frame or list or environment containing the variables in the model. If not found in data, the variables are taken from environment(formula), typically the environment from which gamlss2 is called.\n\n\n\n\nfamily\n\n\nA gamlss.family or gamlss2.family object used to define distribution and the link functions of the parameters.\n\n\n\n\nsubset\n\n\nAn optional vector specifying a subset of observations to be used in the fitting process.\n\n\n\n\nna.action\n\n\nNA processing for setting up the model.frame.\n\n\n\n\nweights\n\n\nAn optional vector of prior weights to be used in the fitting process. Should be NULL or a numeric vector.\n\n\n\n\noffset\n\n\nThis can be used to specify an a priori known components to be included in the linear predictors during fitting. Please note that if only a single numeric vector is provided, the offset will be assigned to the first specified parameter of the distribution. In the case of multiple offsets, a data frame or list must be supplied. Each offset is assigned in the same order as the parameters of the distribution specified in the family object.\n\n\n\n\nstart\n\n\nStarting values for estimation algorithms.\n\n\n\n\ncontrol\n\n\nA list of control arguments, see gamlss2_control.\n\n\n\n\n…\n\n\nArguments passed to gamlss2_control.\n\n\n\n\n\n\nThe model fitting function gamlss2() provides flexible infrastructures for the estimation of GAMLSS.\n\n\nDistributional models are specified using family objects, either from the gamlss.dist package or using gamlss2.family objects.\n\n\nEstimation is carried out through a Newton-Raphson/Fisher scoring algorithm, see function RS. The estimation algorithms can also be exchanged using gamlss2_control. Additionally, if an optimizer is specified by the family object, this optimizer function will be employed for estimation.\n\n\nThe return value is determined by the object returned from the optimizer function, typically an object of class “gamlss2”. Default methods and extractor functions are available for this class. Nevertheless, users have the flexibility to supply their own optimizer function, along with user-specific methods tailored for the returned object.\n\n\n\n\n\nThe return value is determined by the object returned from the optimizer function. By default, the optimization is performed using the RS optimizer function (see gamlss2_control), yielding an object of class “gamlss2”. Default methods and extractor functions are available for this class.\n\n\n\nRigby RA, Stasinopoulos DM (2005). “Generalized Additive Models for Location, Scale and Shape (with Discussion).” Journal of the Royal Statistical Society, Series C (Applied Statistics), 54, 507–554. doi:10.1111/j.1467-9876.2005.00510.x\nRigby RA, Stasinopoulos DM, Heller GZ, De Bastiani F (2019). Distributions for Modeling Location, Scale, and Shape: Using GAMLSS in R, Chapman and Hall/CRC. doi:10.1201/9780429298547\nStasinopoulos DM, Rigby RA (2007). “Generalized Additive Models for Location Scale and Shape (GAMLSS) in R.” Journal of Statistical Software, 23(7), 1–46. doi:10.18637/jss.v023.i07\nStasinopoulos DM, Rigby RA, Heller GZ, Voudouris V, De Bastiani F (2017). Flexible Regression and Smoothing: Using GAMLSS in R, Chapman and Hall/CRC. doi:10.1201/b21973\n\n\n\nRS, gamlss2_control, gamlss2.family\n\n\n\n\nlibrary(\"gamlss2\")\n\n\n## load the abdominal circumference data\ndata(\"abdom\", package = \"gamlss.data\")\n\n## specify the model Formula\nf &lt;- y ~ s(x) | s(x) | s(x) | s(x)\n\n## estimate model\nb &lt;- gamlss2(f, data = abdom, family = BCT)\n\nGAMLSS-RS iteration  1: Global Deviance = 4774.4683 eps = 0.534345     \nGAMLSS-RS iteration  2: Global Deviance = 4770.229 eps = 0.000887     \nGAMLSS-RS iteration  3: Global Deviance = 4770.1663 eps = 0.000013     \nGAMLSS-RS iteration  4: Global Deviance = 4770.1554 eps = 0.000002     \n\n## model summary\nsummary(b)\n\nCall:\ngamlss2(formula = f, data = abdom, family = BCT)\n---\nFamily: BCT \nLink function: mu = identity, sigma = log, nu = identity, tau = log\n*--------\nParameter: mu \n---\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  226.334      1.257     180   &lt;2e-16 ***\n---\nSmooth terms:\n     s(x)\nedf 4.551\n*--------\nParameter: sigma \n---\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -2.92264    0.01101  -265.5   &lt;2e-16 ***\n---\nSmooth terms:\n      s(x)\nedf 2.5639\n*--------\nParameter: nu \n---\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.18021    0.04599  -3.918 9.95e-05 ***\n---\nSmooth terms:\n      s(x)\nedf 1.0015\n*--------\nParameter: tau \n---\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.6548     0.0144   184.4   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n---\nSmooth terms:\n      s(x)\nedf 1.0042\n*--------\nn = 610 df =  13.12 res.df =  596.88\nDeviance = 4770.1554 Null Dev. Red. = 33.39%\nAIC = 4796.3966 elapsed =  0.80sec\n\n## plot estimated effects\nplot(b, which = \"effects\")\n\n\n\n\n\n\n\n## plot diagnostics\nplot(b, which = \"resid\")\n\n\n\n\n\n\n\n## predict parameters\npar &lt;- predict(b)\n\n## predict quantiles\npq &lt;- sapply(c(0.05, 0.5, 0.95), function(q) family(b)$q(q, par))\n\n## visualize\nplot(y ~ x, data = abdom, pch = 19,\n  col = rgb(0.1, 0.1, 0.1, alpha = 0.3))\nmatplot(abdom$x, pq, type = \"l\", lwd = 2,\n  lty = 1, col = 4, add = TRUE)\n\n\n\n\n\n\n\n## use of starting values\nm &lt;- gamlss2(f, data = abdom, family = BCT,\n  start = c(mu = 200, sigma = 0.1, nu = 0, tau = 10))\n\nGAMLSS-RS iteration  1: Global Deviance = 4789.7797 eps = 0.556012     \nGAMLSS-RS iteration  2: Global Deviance = 4774.5657 eps = 0.003176     \nGAMLSS-RS iteration  3: Global Deviance = 4771.4193 eps = 0.000658     \nGAMLSS-RS iteration  4: Global Deviance = 4769.9947 eps = 0.000298     \nGAMLSS-RS iteration  5: Global Deviance = 4769.9556 eps = 0.000008     \n\n## fix some parameters\nm &lt;- gamlss2(f, data = abdom, family = BCT,\n  start = c(mu = 200, sigma = 0.1, nu = 0, tau = 10),\n  fixed = c(nu = TRUE, tau = TRUE))\n\nGAMLSS-RS iteration  1: Global Deviance = 4799.422 eps = 0.555118     \nGAMLSS-RS iteration  2: Global Deviance = 4795.2807 eps = 0.000862     \nGAMLSS-RS iteration  3: Global Deviance = 4795.2668 eps = 0.000002     \n\n## estimated coefficients (intercepts)\ncoef(m)\n\n   mu.p.(Intercept) sigma.p.(Intercept)    nu.p.(Intercept)   tau.p.(Intercept) \n         226.347632           -2.922923            0.000000            2.302585 \n\n## starting values using full predictors\nm &lt;- gamlss2(f, data = abdom, family = BCT,\n  start = fitted(m))\n\nGAMLSS-RS iteration  1: Global Deviance = 4902.0767 eps = 0.372276     \nGAMLSS-RS iteration  2: Global Deviance = 4775.8465 eps = 0.025750     \nGAMLSS-RS iteration  3: Global Deviance = 4775.0302 eps = 0.000170     \nGAMLSS-RS iteration  4: Global Deviance = 4774.9582 eps = 0.000015     \nGAMLSS-RS iteration  5: Global Deviance = 4774.9519 eps = 0.000001     \n\n## same with\nm &lt;- gamlss2(f, data = abdom, family = BCT,\n  start = m)\n\nGAMLSS-RS iteration  1: Global Deviance = 4774.4683 eps = 0.534345     \nGAMLSS-RS iteration  2: Global Deviance = 4770.229 eps = 0.000887     \nGAMLSS-RS iteration  3: Global Deviance = 4770.1663 eps = 0.000013     \nGAMLSS-RS iteration  4: Global Deviance = 4770.1554 eps = 0.000002",
    "crumbs": [
      "Reference",
      "gamlss2"
    ]
  },
  {
    "objectID": "man/gamlss2.family.html",
    "href": "man/gamlss2.family.html",
    "title": "gamlss2",
    "section": "",
    "text": "Family objects within the package gamlss2 are used to specify the information required to use a model fitting function. This includes details such as parameter names, corresponding link functions, the density function, log-likelihood function and derivatives of the log-likelihood with respect to the predictors. In addition, family objects are used in the calculation of post-modeling statistics, such as residual diagnostics and random number generation. An overview can be found in the accompanying details and examples.\n\n\n\nThe following lists the minimum requirements on a gamlss2 family object to be used with gamlss2:\n\n\nThe family object is expected to return a list of class “gamlss2.family”.\n\n\nThe object must contain the family name as a character string.\n\n\nThe object must contain the names of the parameters as a character string, as well as the corresponding link functions as character string.\n\n\nThe family object must contain a $d() function to evaluate the (log-)density.\n\n\nFurthermore, it is assumed that the density function in a family object has the following arguments:\nd(y, par, log = FALSE, …)\nwhere argument y is the response (possibly a matrix) and par is a named list holding the evaluated parameters of the distribution, e.g., using a normal distribution par has two elements, one for the mean par$mu and one for the standard deviation par$sigma. The dots argument is for passing special internally used objects, depending on the type of model this feature is usually not needed.\nOptionally, the family object holds derivative functions evaluating derivatives of the log-likelihood w.r.t. the predictors (or expectations of derivatives). For each parameter, these functions must have the following arguments:\nfunction(y, par, …)\nfor computing the first derivative of the log-likelihood w.r.t. a predictor and\nfunction(y, par, …)\nfor computing the negative second derivatives. Within the family object these functions are organized in a named list, see the examples below. If these functions are not specified, all derivatives will be approximated numerically. Note that also cross derivatives can be implemented, e.g., when using the CG algorithm for fitting a GAMLSS.\nIn addition, for the cumulative distribution function (p(y, par, …)), for the quantile function (q(y, par, …)) or for creating random numbers (r(n, par, …)) the same structure is assumed.\nUsing function gamlss2 the family objects may also specify the optimizer()er function that should be used with this family.\n\n\n\ngamlss2\n\n\n\n\nlibrary(\"gamlss2\")\n\n\nNormal &lt;- function(...) {\n  fam &lt;- list(\n    \"family\" = \"Normal\",\n    \"names\" = c(\"mu\", \"sigma\"),\n    \"links\" = c(\"mu\" = \"identity\", \"sigma\" = \"log\"),\n    \"score\" = list(\n      \"mu\" = function(y, par, ...) {\n        (y - par$mu) / (par$sigma^2)\n      },\n      \"sigma\" = function(y, par, ...) {\n        -1 + (y - par$mu)^2 / (par$sigma^2)\n      }\n    ),\n    \"hess\" = list(\n      \"mu\" = function(y, par, ...) {\n        1 / (par$sigma^2)\n      },\n      \"sigma\" = function(y, par, ...) {\n        rep(2, length(y))\n      },\n      \"mu.sigma\" = function(y, par, ...) {\n        rep(0, length(y))\n      }\n    ),\n    \"loglik\" = function(y, par, ...) {\n      sum(dnorm(y, par$mu, par$sigma, log = TRUE))\n    },\n    \"mu\" = function(par, ...) {\n      par$mu\n    },\n    \"d\" = function(y, par, log = FALSE) {\n      dnorm(y, mean = par$mu, sd = par$sigma, log = log)\n    },\n    \"p\" = function(y, par, ...) {\n      pnorm(y, mean = par$mu, sd = par$sigma, ...)\n    },\n    \"r\" = function(n, par) {\n      rnorm(n, mean = par$mu, sd = par$sigma)\n    },\n    \"q\" = function(p, par) {\n      qnorm(p, mean = par$mu, sd = par$sigma)\n    },\n    \"initialize\" = list(\n      \"mu\"    = function(y, ...) { (y + mean(y)) / 2 },\n      \"sigma\" = function(y, ...) { rep(sd(y), length(y)) }\n    ),\n    \"mean\"      = function(par) par$mu,\n    \"variance\"  = function(par) par$sigma^2,\n    \"valid.response\" = function(x) {\n      if(is.factor(x) | is.character(x))\n        stop(\"the response should be numeric!\")\n      return(TRUE)\n    }\n  )\n\n  class(fam) &lt;- \"gamlss2.family\"\n\n  return(fam)\n}\n\n## load the abdominal circumference data\ndata(\"abdom\", package = \"gamlss.data\")\n\n## specify the model Formula\nf &lt;- y ~ s(x) | s(x)\n\n## estimate model\nb &lt;- gamlss2(f, data = abdom, family = Normal)\n\n## plot estimated effects\nplot(b, which = \"effects\")\n\n## plot diagnostics\nplot(b, which = \"resid\")\n\n## predict parameters\npar &lt;- predict(b)\n\n## predict quantiles\npq &lt;- sapply(c(0.05, 0.5, 0.95), function(q) family(b)$q(q, par))\n\n## visualize\nplot(y ~ x, data = abdom, pch = 19,\n  col = rgb(0.1, 0.1, 0.1, alpha = 0.3))\nmatplot(abdom$x, pq, type = \"l\", lwd = 2,\n  lty = 1, col = 4, add = TRUE)\n\n## another example using only the density\n## function, all derivatives are approximated\n## in this case; for residual diagnostics,\n## the $p() and $q() function is needed, too.\nGamma &lt;- function(...) {\n  fam &lt;- list(\n    \"names\" = c(\"mu\", \"sigma\"),\n    \"links\" = c(\"mu\" = \"log\", \"sigma\" = \"log\"),\n    \"d\" = function(y, par, log = FALSE, ...) {\n      shape &lt;- par$sigma\n      scale &lt;- par$mu/par$sigma\n      dgamma(y, shape = shape, scale = scale, log = log)\n    },\n    \"p\" = function(y, par, lower.tail = TRUE, log.p = FALSE) {\n      shape &lt;- par$sigma\n      scale &lt;- par$mu/par$sigma\n      pgamma(y, shape = shape, scale = scale,\n        lower.tail = lower.tail, log.p = log.p)\n    },\n    \"q\" = function(p, par, lower.tail = TRUE, log.p = FALSE) {\n      shape &lt;- par$sigma\n      scale &lt;- par$mu/par$sigma\n       qgamma(p, shape = shape, scale = scale,\n         lower.tail = lower.tail, log.p = log.p)\n    }\n  )\n\n  class(fam) &lt;- \"gamlss2.family\"\n\n  return(fam)\n}\n\n## example using the Munich rent data\ndata(\"rent\", package = \"gamlss.data\")\n\n## model formula\nf &lt;- R ~ ti(Fl) + ti(A) + ti(Fl, A, bs = \"ps\") |\n  ti(Fl) + ti(A) + ti(Fl, A, bs = \"ps\")\n\n## estimate model\nb &lt;- gamlss2(f, data = rent, family = Gamma)\n\n## visualize estimated effects\nplot(b, which = \"effects\")\n\n## diagnostics, needs the $p() and $q() function!\nplot(b, which = \"resid\")",
    "crumbs": [
      "Reference",
      "gamlss2.family"
    ]
  },
  {
    "objectID": "man/gamlss2.family.html#family-objects-in-gamlss2",
    "href": "man/gamlss2.family.html#family-objects-in-gamlss2",
    "title": "gamlss2",
    "section": "",
    "text": "Family objects within the package gamlss2 are used to specify the information required to use a model fitting function. This includes details such as parameter names, corresponding link functions, the density function, log-likelihood function and derivatives of the log-likelihood with respect to the predictors. In addition, family objects are used in the calculation of post-modeling statistics, such as residual diagnostics and random number generation. An overview can be found in the accompanying details and examples.\n\n\n\nThe following lists the minimum requirements on a gamlss2 family object to be used with gamlss2:\n\n\nThe family object is expected to return a list of class “gamlss2.family”.\n\n\nThe object must contain the family name as a character string.\n\n\nThe object must contain the names of the parameters as a character string, as well as the corresponding link functions as character string.\n\n\nThe family object must contain a $d() function to evaluate the (log-)density.\n\n\nFurthermore, it is assumed that the density function in a family object has the following arguments:\nd(y, par, log = FALSE, …)\nwhere argument y is the response (possibly a matrix) and par is a named list holding the evaluated parameters of the distribution, e.g., using a normal distribution par has two elements, one for the mean par$mu and one for the standard deviation par$sigma. The dots argument is for passing special internally used objects, depending on the type of model this feature is usually not needed.\nOptionally, the family object holds derivative functions evaluating derivatives of the log-likelihood w.r.t. the predictors (or expectations of derivatives). For each parameter, these functions must have the following arguments:\nfunction(y, par, …)\nfor computing the first derivative of the log-likelihood w.r.t. a predictor and\nfunction(y, par, …)\nfor computing the negative second derivatives. Within the family object these functions are organized in a named list, see the examples below. If these functions are not specified, all derivatives will be approximated numerically. Note that also cross derivatives can be implemented, e.g., when using the CG algorithm for fitting a GAMLSS.\nIn addition, for the cumulative distribution function (p(y, par, …)), for the quantile function (q(y, par, …)) or for creating random numbers (r(n, par, …)) the same structure is assumed.\nUsing function gamlss2 the family objects may also specify the optimizer()er function that should be used with this family.\n\n\n\ngamlss2\n\n\n\n\nlibrary(\"gamlss2\")\n\n\nNormal &lt;- function(...) {\n  fam &lt;- list(\n    \"family\" = \"Normal\",\n    \"names\" = c(\"mu\", \"sigma\"),\n    \"links\" = c(\"mu\" = \"identity\", \"sigma\" = \"log\"),\n    \"score\" = list(\n      \"mu\" = function(y, par, ...) {\n        (y - par$mu) / (par$sigma^2)\n      },\n      \"sigma\" = function(y, par, ...) {\n        -1 + (y - par$mu)^2 / (par$sigma^2)\n      }\n    ),\n    \"hess\" = list(\n      \"mu\" = function(y, par, ...) {\n        1 / (par$sigma^2)\n      },\n      \"sigma\" = function(y, par, ...) {\n        rep(2, length(y))\n      },\n      \"mu.sigma\" = function(y, par, ...) {\n        rep(0, length(y))\n      }\n    ),\n    \"loglik\" = function(y, par, ...) {\n      sum(dnorm(y, par$mu, par$sigma, log = TRUE))\n    },\n    \"mu\" = function(par, ...) {\n      par$mu\n    },\n    \"d\" = function(y, par, log = FALSE) {\n      dnorm(y, mean = par$mu, sd = par$sigma, log = log)\n    },\n    \"p\" = function(y, par, ...) {\n      pnorm(y, mean = par$mu, sd = par$sigma, ...)\n    },\n    \"r\" = function(n, par) {\n      rnorm(n, mean = par$mu, sd = par$sigma)\n    },\n    \"q\" = function(p, par) {\n      qnorm(p, mean = par$mu, sd = par$sigma)\n    },\n    \"initialize\" = list(\n      \"mu\"    = function(y, ...) { (y + mean(y)) / 2 },\n      \"sigma\" = function(y, ...) { rep(sd(y), length(y)) }\n    ),\n    \"mean\"      = function(par) par$mu,\n    \"variance\"  = function(par) par$sigma^2,\n    \"valid.response\" = function(x) {\n      if(is.factor(x) | is.character(x))\n        stop(\"the response should be numeric!\")\n      return(TRUE)\n    }\n  )\n\n  class(fam) &lt;- \"gamlss2.family\"\n\n  return(fam)\n}\n\n## load the abdominal circumference data\ndata(\"abdom\", package = \"gamlss.data\")\n\n## specify the model Formula\nf &lt;- y ~ s(x) | s(x)\n\n## estimate model\nb &lt;- gamlss2(f, data = abdom, family = Normal)\n\n## plot estimated effects\nplot(b, which = \"effects\")\n\n## plot diagnostics\nplot(b, which = \"resid\")\n\n## predict parameters\npar &lt;- predict(b)\n\n## predict quantiles\npq &lt;- sapply(c(0.05, 0.5, 0.95), function(q) family(b)$q(q, par))\n\n## visualize\nplot(y ~ x, data = abdom, pch = 19,\n  col = rgb(0.1, 0.1, 0.1, alpha = 0.3))\nmatplot(abdom$x, pq, type = \"l\", lwd = 2,\n  lty = 1, col = 4, add = TRUE)\n\n## another example using only the density\n## function, all derivatives are approximated\n## in this case; for residual diagnostics,\n## the $p() and $q() function is needed, too.\nGamma &lt;- function(...) {\n  fam &lt;- list(\n    \"names\" = c(\"mu\", \"sigma\"),\n    \"links\" = c(\"mu\" = \"log\", \"sigma\" = \"log\"),\n    \"d\" = function(y, par, log = FALSE, ...) {\n      shape &lt;- par$sigma\n      scale &lt;- par$mu/par$sigma\n      dgamma(y, shape = shape, scale = scale, log = log)\n    },\n    \"p\" = function(y, par, lower.tail = TRUE, log.p = FALSE) {\n      shape &lt;- par$sigma\n      scale &lt;- par$mu/par$sigma\n      pgamma(y, shape = shape, scale = scale,\n        lower.tail = lower.tail, log.p = log.p)\n    },\n    \"q\" = function(p, par, lower.tail = TRUE, log.p = FALSE) {\n      shape &lt;- par$sigma\n      scale &lt;- par$mu/par$sigma\n       qgamma(p, shape = shape, scale = scale,\n         lower.tail = lower.tail, log.p = log.p)\n    }\n  )\n\n  class(fam) &lt;- \"gamlss2.family\"\n\n  return(fam)\n}\n\n## example using the Munich rent data\ndata(\"rent\", package = \"gamlss.data\")\n\n## model formula\nf &lt;- R ~ ti(Fl) + ti(A) + ti(Fl, A, bs = \"ps\") |\n  ti(Fl) + ti(A) + ti(Fl, A, bs = \"ps\")\n\n## estimate model\nb &lt;- gamlss2(f, data = rent, family = Gamma)\n\n## visualize estimated effects\nplot(b, which = \"effects\")\n\n## diagnostics, needs the $p() and $q() function!\nplot(b, which = \"resid\")",
    "crumbs": [
      "Reference",
      "gamlss2.family"
    ]
  },
  {
    "objectID": "man/stepwise.html",
    "href": "man/stepwise.html",
    "title": "gamlss2",
    "section": "",
    "text": "The optimizer function stepwise() performs stepwise model term selection using a Generalized Akaike Information Criterion (GAIC). Estimation is based on the Rigby and Stasinopoulos (RS) & Cole and Green (CG) algorithm as implemented in function RS.\n\n\n\n## Wrapper function for stepwise GAMLSS estimation.\nstep_gamlss2(formula, ..., K = 2,\n  strategy = c(\"both.linear\", \"both\"), keeporder = FALSE,\n  cores = 1L)\n\n## After stepwise search, extract the new formula.\nnew_formula(object)\n\n## Stepwise optimizer function.\nstepwise(x, y, specials, family, offsets,\n  weights, start, xterms, sterms, control)\n\n\n\n\n\n\n\nformula\n\n\nA model formula for gamlss2.\n\n\n\n\n…\n\n\nArguments passed to gamlss2.\n\n\n\n\nK\n\n\nNumeric, the penalty for the GAIC.\n\n\n\n\nstrategy\n\n\nCharacter, the strategy that should be applied for the stepwise algorithm. Possible options are “forward.linear”, “forward”, “backward”, “backward.linear”, “replace”, “replace.linear”, “both”, “both.linear”. See the details.\n\n\n\n\nkeeporder\n\n\nLogical, For the different strategies of the stepwise algorithm, should the updates be performed sequentially according to the order of the parameters of the response distribution as specified in the family (see gamlss2.family), or should the selection search be performed across all parameters?\n\n\n\n\ncores\n\n\nInteger, if cores &gt; 1L, function mclapply function is used to speed up computations using multiple cores within the selection steps.\n\n\n\n\nobject\n\n\nAn object fitted using step_gamlss2().\n\n\n\n\nx\n\n\nThe full model matrix to be used for fitting.\n\n\n\n\ny\n\n\nThe response vector or matrix.\n\n\n\n\nspecials\n\n\nA named list of special model terms, e.g., including design and penalty matrices for fitting smooth terms using smooth.construct.\n\n\n\n\nfamily\n\n\nA family object, see gamlss2.family.\n\n\n\n\noffsets\n\n\nIf supplied, a list or data frame of possible model offset.\n\n\n\n\nweights\n\n\nIf supplied, a numeric vector of weights.\n\n\n\n\nstart\n\n\nStarting values, either for the parameters of the response distribution or, if specified as a named list in which each element of length one is named with “(Intercept)”, the respective intercepts are initialized. If starting values are specified as a named list, data frame or matrix, where each element/column is a vector with the same length as the number of observations in the data, the respective predictors are initialized with these. See the examples for gamlss2.\n\n\n\n\nxterms\n\n\nA named list specifying the linear model terms. Each named list element represents one parameter as specified in the family object.\n\n\n\n\nsterms\n\n\nA named list specifying the special model terms. Each named list element represents one parameter as specified in the family object.\n\n\n\n\ncontrol\n\n\nFurther control arguments as specified within the call of gamlss2.\n\n\n\n\n\n\nThe wrapper function step_gamlss2() calls gamlss2 using the stepwise() optimizer function.\nThe stepwise algorithm can apply the following strategies:\n\n\nEach predictor must include an intercept.\n\n\nIn a forward selection step, model terms with the highest improvement on the GAIC are selected.\n\n\nIn a replacement step, each model term is tested to see if an exchange with a model term not yet selected will improve the GAIC.\n\n\nIn a backward step, model terms are deselected, if the GAIC can be further improved.\n\n\nIn a bidirectional step, model terms can be either added or removed.\n\n\nIn addition, the forward, backward and replace selection step can be combined.\n\n\nThe selected strategies are iterated until no further improvement is achieved.\nThe different strategies can be selected using argument strategy. Please see the examples. Possible values are strategy = c(“both”, “forward”, “backward”, “replace”, “all”). Here, strategy = “all” combines the forward, backward and replace selection step.\nIn addition, each of the steps 2-4 can be applied to linear model terms only, prior to performing the steps for all model terms. This can be done by additionally setting strategy = c(“both.linear”, “forward.linear”, “backward.linear”, “replace.linear”, “all.linear”).\nThe default is strategy = c(“both.linear”, “both”) and keeporder = FALSE.\nNote that each of the steps 2-4 can be performed while maintaining the order of the parameters of the response distribution, i.e., if the keeporder = TRUE argument is set, then the parameters will be updated in the order specified in the gamlss2.family. Using backward elimination, the model terms are deselected in reverse order.\n\n\n\nThe optimizer function stepwise() returns the final model as named list of class “gamlss2”. See the return value of function RS. The wrapper function step_gamlss2() also returns the final model.\n\n\n\ngamlss2, gamlss2_control, RS\n\n\n\n\nlibrary(\"gamlss2\")\n\n\ndata(\"rent\", package = \"gamlss.data\")\n\n## because of possible linear interactions,\n## scale the covariates first\nrent$Fl &lt;- scale(rent$Fl)\nrent$A &lt;- scale(rent$A)\n\n## the Formula defines the searching scope\nf &lt;- R ~ Fl + A + Fl:A + loc + s(Fl) + s(A) + te(Fl, A) |\n  Fl + A + loc + Fl:A + s(Fl) + s(A) + te(Fl, A)\n\n## estimate a Gamma model using the stepwise algorithm\nb &lt;- step_gamlss2(f, data = rent, family = GA, K = 2)\n\n## same with\n## b &lt;- gamlss2(f, data = rent, family = GA, optimizer = stepwise, K = 2)\n\n## show the new formula of selected model terms\nnew_formula(b)\n\n## final model summary\nsummary(b)\n\n## effect plots\nplot(b)\n\n## diagnostic plots\nplot(b, which = \"resid\")\n\n## plot GAIC\nplot(b, which = \"selection\")\n\n## use forward linear, replace and backward strategy\nb &lt;- step_gamlss2(f, data = rent, family = GA, K = 2,\n  strategy = c(\"forward.linear\", \"replace\", \"backward\"))\n\n## more complex model\n## note, the third parameter\n## nu does not include any model terms\nf &lt;- R ~ Fl + A + Fl:A + loc + s(Fl) + s(A) + te(Fl, A) |\n  Fl + A + loc + Fl:A + s(Fl) + s(A) + te(Fl, A) |\n  1 |\n  Fl + A + loc + Fl:A + s(Fl) + s(A) + te(Fl, A)\n\n## model using the BCT family\nb &lt;- step_gamlss2(f, data = rent, family = BCT,\n  K = 2, strategy = c(\"forward.linear\", \"both\"),\n  keeporder = TRUE)\n\n## plot GAIC\nplot(b, which = \"selection\")",
    "crumbs": [
      "Reference",
      "stepwise"
    ]
  },
  {
    "objectID": "man/stepwise.html#stepwise-model-term-selection-using-gaic",
    "href": "man/stepwise.html#stepwise-model-term-selection-using-gaic",
    "title": "gamlss2",
    "section": "",
    "text": "The optimizer function stepwise() performs stepwise model term selection using a Generalized Akaike Information Criterion (GAIC). Estimation is based on the Rigby and Stasinopoulos (RS) & Cole and Green (CG) algorithm as implemented in function RS.\n\n\n\n## Wrapper function for stepwise GAMLSS estimation.\nstep_gamlss2(formula, ..., K = 2,\n  strategy = c(\"both.linear\", \"both\"), keeporder = FALSE,\n  cores = 1L)\n\n## After stepwise search, extract the new formula.\nnew_formula(object)\n\n## Stepwise optimizer function.\nstepwise(x, y, specials, family, offsets,\n  weights, start, xterms, sterms, control)\n\n\n\n\n\n\n\nformula\n\n\nA model formula for gamlss2.\n\n\n\n\n…\n\n\nArguments passed to gamlss2.\n\n\n\n\nK\n\n\nNumeric, the penalty for the GAIC.\n\n\n\n\nstrategy\n\n\nCharacter, the strategy that should be applied for the stepwise algorithm. Possible options are “forward.linear”, “forward”, “backward”, “backward.linear”, “replace”, “replace.linear”, “both”, “both.linear”. See the details.\n\n\n\n\nkeeporder\n\n\nLogical, For the different strategies of the stepwise algorithm, should the updates be performed sequentially according to the order of the parameters of the response distribution as specified in the family (see gamlss2.family), or should the selection search be performed across all parameters?\n\n\n\n\ncores\n\n\nInteger, if cores &gt; 1L, function mclapply function is used to speed up computations using multiple cores within the selection steps.\n\n\n\n\nobject\n\n\nAn object fitted using step_gamlss2().\n\n\n\n\nx\n\n\nThe full model matrix to be used for fitting.\n\n\n\n\ny\n\n\nThe response vector or matrix.\n\n\n\n\nspecials\n\n\nA named list of special model terms, e.g., including design and penalty matrices for fitting smooth terms using smooth.construct.\n\n\n\n\nfamily\n\n\nA family object, see gamlss2.family.\n\n\n\n\noffsets\n\n\nIf supplied, a list or data frame of possible model offset.\n\n\n\n\nweights\n\n\nIf supplied, a numeric vector of weights.\n\n\n\n\nstart\n\n\nStarting values, either for the parameters of the response distribution or, if specified as a named list in which each element of length one is named with “(Intercept)”, the respective intercepts are initialized. If starting values are specified as a named list, data frame or matrix, where each element/column is a vector with the same length as the number of observations in the data, the respective predictors are initialized with these. See the examples for gamlss2.\n\n\n\n\nxterms\n\n\nA named list specifying the linear model terms. Each named list element represents one parameter as specified in the family object.\n\n\n\n\nsterms\n\n\nA named list specifying the special model terms. Each named list element represents one parameter as specified in the family object.\n\n\n\n\ncontrol\n\n\nFurther control arguments as specified within the call of gamlss2.\n\n\n\n\n\n\nThe wrapper function step_gamlss2() calls gamlss2 using the stepwise() optimizer function.\nThe stepwise algorithm can apply the following strategies:\n\n\nEach predictor must include an intercept.\n\n\nIn a forward selection step, model terms with the highest improvement on the GAIC are selected.\n\n\nIn a replacement step, each model term is tested to see if an exchange with a model term not yet selected will improve the GAIC.\n\n\nIn a backward step, model terms are deselected, if the GAIC can be further improved.\n\n\nIn a bidirectional step, model terms can be either added or removed.\n\n\nIn addition, the forward, backward and replace selection step can be combined.\n\n\nThe selected strategies are iterated until no further improvement is achieved.\nThe different strategies can be selected using argument strategy. Please see the examples. Possible values are strategy = c(“both”, “forward”, “backward”, “replace”, “all”). Here, strategy = “all” combines the forward, backward and replace selection step.\nIn addition, each of the steps 2-4 can be applied to linear model terms only, prior to performing the steps for all model terms. This can be done by additionally setting strategy = c(“both.linear”, “forward.linear”, “backward.linear”, “replace.linear”, “all.linear”).\nThe default is strategy = c(“both.linear”, “both”) and keeporder = FALSE.\nNote that each of the steps 2-4 can be performed while maintaining the order of the parameters of the response distribution, i.e., if the keeporder = TRUE argument is set, then the parameters will be updated in the order specified in the gamlss2.family. Using backward elimination, the model terms are deselected in reverse order.\n\n\n\nThe optimizer function stepwise() returns the final model as named list of class “gamlss2”. See the return value of function RS. The wrapper function step_gamlss2() also returns the final model.\n\n\n\ngamlss2, gamlss2_control, RS\n\n\n\n\nlibrary(\"gamlss2\")\n\n\ndata(\"rent\", package = \"gamlss.data\")\n\n## because of possible linear interactions,\n## scale the covariates first\nrent$Fl &lt;- scale(rent$Fl)\nrent$A &lt;- scale(rent$A)\n\n## the Formula defines the searching scope\nf &lt;- R ~ Fl + A + Fl:A + loc + s(Fl) + s(A) + te(Fl, A) |\n  Fl + A + loc + Fl:A + s(Fl) + s(A) + te(Fl, A)\n\n## estimate a Gamma model using the stepwise algorithm\nb &lt;- step_gamlss2(f, data = rent, family = GA, K = 2)\n\n## same with\n## b &lt;- gamlss2(f, data = rent, family = GA, optimizer = stepwise, K = 2)\n\n## show the new formula of selected model terms\nnew_formula(b)\n\n## final model summary\nsummary(b)\n\n## effect plots\nplot(b)\n\n## diagnostic plots\nplot(b, which = \"resid\")\n\n## plot GAIC\nplot(b, which = \"selection\")\n\n## use forward linear, replace and backward strategy\nb &lt;- step_gamlss2(f, data = rent, family = GA, K = 2,\n  strategy = c(\"forward.linear\", \"replace\", \"backward\"))\n\n## more complex model\n## note, the third parameter\n## nu does not include any model terms\nf &lt;- R ~ Fl + A + Fl:A + loc + s(Fl) + s(A) + te(Fl, A) |\n  Fl + A + loc + Fl:A + s(Fl) + s(A) + te(Fl, A) |\n  1 |\n  Fl + A + loc + Fl:A + s(Fl) + s(A) + te(Fl, A)\n\n## model using the BCT family\nb &lt;- step_gamlss2(f, data = rent, family = BCT,\n  K = 2, strategy = c(\"forward.linear\", \"both\"),\n  keeporder = TRUE)\n\n## plot GAIC\nplot(b, which = \"selection\")",
    "crumbs": [
      "Reference",
      "stepwise"
    ]
  },
  {
    "objectID": "man/RS_CG.html",
    "href": "man/RS_CG.html",
    "title": "gamlss2",
    "section": "",
    "text": "The function RS() implements the algorithm of Rigby and Stasinopoulos, the function CG() implements the algorithm of Cole and Green for estimating a GAMLSS with gamlss2.\n\n\n\n## Rigby and Stasinopoulos algorithm.\nRS(x, y, specials, family, offsets,\n  weights, start, xterms, sterms, control)\n\n## Cole and Green algorithm.\nCG(x, y, specials, family, offsets,\n  weights, start, xterms, sterms, control)\n\n\n\n\n\n\n\nx\n\n\nThe full model matrix to be used for fitting.\n\n\n\n\ny\n\n\nThe response vector or matrix.\n\n\n\n\nspecials\n\n\nA named list of special model terms, e.g., including design and penalty matrices for fitting smooth terms using smooth.construct.\n\n\n\n\nfamily\n\n\nA family object, see gamlss2.family.\n\n\n\n\noffsets\n\n\nIf supplied, a list or data frame of possible model offset.\n\n\n\n\nweights\n\n\nIf supplied, a numeric vector of weights.\n\n\n\n\nstart\n\n\nStarting values, either for the parameters of the response distribution or, if specified as a named list in which each element of length one is named with “(Intercept)”, the respective intercepts are initialized. If starting values are specified as a named list, data frame or matrix, where each element/column is a vector with the same length as the number of observations in the data, the respective predictors are initialized with these. See the examples for gamlss2.\n\n\n\n\nxterms\n\n\nA named list specifying the linear model terms. Each named list element represents one parameter as specified in the family object.\n\n\n\n\nsterms\n\n\nA named list specifying the special model terms. Each named list element represents one parameter as specified in the family object.\n\n\n\n\ncontrol\n\n\nFurther control arguments as specified within the call of gamlss2. See the details.\n\n\n\n\n\n\nFunctions RS() and CG() are called within gamlss2. Both functions implement a backfitting algorithm for estimating GAMLSS. For algorithm details see Rigby and Stasinopoulos (2005).\nThe functions use the following control arguments:\n\n\neps: Numeric vector of length 2, the stopping criterion. Default is eps = c(1e-05, 1e-05) for the outer and the inner backfitting loop.\n\n\nmaxit: Integer vector of length 2, the maximum number of iterations of the outer and inner backfitting loop. Default is maxit = c(100, 10).\n\n\nstep: Numeric, the step length control parameter. Default is step = 1. Note that if step is set smaller than 1, it might be appropriate to lower the stopping criterion eps, too.\n\n\nCG: Integer, the number of iterations when to start the CG correction. Default is CG = Inf.\n\n\ntrace: Logical, should information be printed while the algorithm is running?\n\n\nflush: Logical, use flush.console for displaying the current output in the console.\n\n\nridge: Logical, should automatic ridge penalization be applied only to linear effects, without penalizing the intercept? For each parameter of the distribution the optimum ridge penalty is estimated using an information criterion. Possible options are criterion = c(“aic”, “aicc”, “bic”, “gaic”, “gcv”). The default is criterion = “gaic” and argument K = 2, which can be set in gamlss2_control.\n\n\nTo facilitate the development of new algorithms for gamlss2, users can exchange them using the optimizer argument in gamlss2_control. Users developing new model fitting functions are advised to use these functions as templates and pass them to gamlss2_control. Alternatively, users can replace the optimizer function by adding a named list element, “optimizer”, to the family object. For instructions on setting up new families in gamlss2, see gamlss2.family.\n\n\n\nFunctions RS() and CG() return a named list of class “gamlss2” containing the following objects:\n\n\n\nfitted.values\n\n\nA data frame of the fitted values of the modeled parameters of the selected distribution.\n\n\n\n\nfitted.specials\n\n\nA named list, one element for each parameter of the distribution, containing the fitted model object information of special model terms.\n\n\n\n\nfitted.linear\n\n\nA named list, one element for each parameter of the distribution, containing the information on fitted linear effects.\n\n\n\n\ncoefficients\n\n\nA named list, one element for each parameter of the distribution, containing the estimated parameters of the linear effects.\n\n\n\n\nelapsed\n\n\nThe elapsed runtime of the algorithm.\n\n\n\n\niterations\n\n\nHow many iterations the algorithm performed.\n\n\n\n\nlogLik\n\n\nThe final value of the log-likelihood of the model.\n\n\n\n\ncontrol\n\n\nAll control arguments used as supplied from function gamlss2_control.\n\n\n\n\n\n\nRigby RA, Stasinopoulos DM (2005). “Generalized Additive Models for Location, Scale and Shape (with Discussion).” Journal of the Royal Statistical Society, Series C (Applied Statistics), 54, 507–554. doi:10.1111/j.1467-9876.2005.00510.x\n\n\n\ngamlss2, gamlss2_control, gamlss2.family\n\n\n\n\nlibrary(\"gamlss2\")\n\n\ndata(\"abdom\", package = \"gamlss.data\")\n\n## specify the model Formula\nf &lt;- y ~ s(x) | s(x) | s(x) | s(x)\n\n## estimate model using RS (default)\nb &lt;- gamlss2(f, data = abdom, family = BCT, optimizer = RS)\n\n## now with CG\nb &lt;- gamlss2(f, data = abdom, family = BCT, optimizer = CG)\n\n## first 2 RS iterations and afterwards switch to CG\nb &lt;- gamlss2(f, data = abdom, family = BCT, CG = 2)",
    "crumbs": [
      "Reference",
      "RS_CG"
    ]
  },
  {
    "objectID": "man/RS_CG.html#rigby-and-stasinopoulos-rs-cole-and-green-cg-algorithm",
    "href": "man/RS_CG.html#rigby-and-stasinopoulos-rs-cole-and-green-cg-algorithm",
    "title": "gamlss2",
    "section": "",
    "text": "The function RS() implements the algorithm of Rigby and Stasinopoulos, the function CG() implements the algorithm of Cole and Green for estimating a GAMLSS with gamlss2.\n\n\n\n## Rigby and Stasinopoulos algorithm.\nRS(x, y, specials, family, offsets,\n  weights, start, xterms, sterms, control)\n\n## Cole and Green algorithm.\nCG(x, y, specials, family, offsets,\n  weights, start, xterms, sterms, control)\n\n\n\n\n\n\n\nx\n\n\nThe full model matrix to be used for fitting.\n\n\n\n\ny\n\n\nThe response vector or matrix.\n\n\n\n\nspecials\n\n\nA named list of special model terms, e.g., including design and penalty matrices for fitting smooth terms using smooth.construct.\n\n\n\n\nfamily\n\n\nA family object, see gamlss2.family.\n\n\n\n\noffsets\n\n\nIf supplied, a list or data frame of possible model offset.\n\n\n\n\nweights\n\n\nIf supplied, a numeric vector of weights.\n\n\n\n\nstart\n\n\nStarting values, either for the parameters of the response distribution or, if specified as a named list in which each element of length one is named with “(Intercept)”, the respective intercepts are initialized. If starting values are specified as a named list, data frame or matrix, where each element/column is a vector with the same length as the number of observations in the data, the respective predictors are initialized with these. See the examples for gamlss2.\n\n\n\n\nxterms\n\n\nA named list specifying the linear model terms. Each named list element represents one parameter as specified in the family object.\n\n\n\n\nsterms\n\n\nA named list specifying the special model terms. Each named list element represents one parameter as specified in the family object.\n\n\n\n\ncontrol\n\n\nFurther control arguments as specified within the call of gamlss2. See the details.\n\n\n\n\n\n\nFunctions RS() and CG() are called within gamlss2. Both functions implement a backfitting algorithm for estimating GAMLSS. For algorithm details see Rigby and Stasinopoulos (2005).\nThe functions use the following control arguments:\n\n\neps: Numeric vector of length 2, the stopping criterion. Default is eps = c(1e-05, 1e-05) for the outer and the inner backfitting loop.\n\n\nmaxit: Integer vector of length 2, the maximum number of iterations of the outer and inner backfitting loop. Default is maxit = c(100, 10).\n\n\nstep: Numeric, the step length control parameter. Default is step = 1. Note that if step is set smaller than 1, it might be appropriate to lower the stopping criterion eps, too.\n\n\nCG: Integer, the number of iterations when to start the CG correction. Default is CG = Inf.\n\n\ntrace: Logical, should information be printed while the algorithm is running?\n\n\nflush: Logical, use flush.console for displaying the current output in the console.\n\n\nridge: Logical, should automatic ridge penalization be applied only to linear effects, without penalizing the intercept? For each parameter of the distribution the optimum ridge penalty is estimated using an information criterion. Possible options are criterion = c(“aic”, “aicc”, “bic”, “gaic”, “gcv”). The default is criterion = “gaic” and argument K = 2, which can be set in gamlss2_control.\n\n\nTo facilitate the development of new algorithms for gamlss2, users can exchange them using the optimizer argument in gamlss2_control. Users developing new model fitting functions are advised to use these functions as templates and pass them to gamlss2_control. Alternatively, users can replace the optimizer function by adding a named list element, “optimizer”, to the family object. For instructions on setting up new families in gamlss2, see gamlss2.family.\n\n\n\nFunctions RS() and CG() return a named list of class “gamlss2” containing the following objects:\n\n\n\nfitted.values\n\n\nA data frame of the fitted values of the modeled parameters of the selected distribution.\n\n\n\n\nfitted.specials\n\n\nA named list, one element for each parameter of the distribution, containing the fitted model object information of special model terms.\n\n\n\n\nfitted.linear\n\n\nA named list, one element for each parameter of the distribution, containing the information on fitted linear effects.\n\n\n\n\ncoefficients\n\n\nA named list, one element for each parameter of the distribution, containing the estimated parameters of the linear effects.\n\n\n\n\nelapsed\n\n\nThe elapsed runtime of the algorithm.\n\n\n\n\niterations\n\n\nHow many iterations the algorithm performed.\n\n\n\n\nlogLik\n\n\nThe final value of the log-likelihood of the model.\n\n\n\n\ncontrol\n\n\nAll control arguments used as supplied from function gamlss2_control.\n\n\n\n\n\n\nRigby RA, Stasinopoulos DM (2005). “Generalized Additive Models for Location, Scale and Shape (with Discussion).” Journal of the Royal Statistical Society, Series C (Applied Statistics), 54, 507–554. doi:10.1111/j.1467-9876.2005.00510.x\n\n\n\ngamlss2, gamlss2_control, gamlss2.family\n\n\n\n\nlibrary(\"gamlss2\")\n\n\ndata(\"abdom\", package = \"gamlss.data\")\n\n## specify the model Formula\nf &lt;- y ~ s(x) | s(x) | s(x) | s(x)\n\n## estimate model using RS (default)\nb &lt;- gamlss2(f, data = abdom, family = BCT, optimizer = RS)\n\n## now with CG\nb &lt;- gamlss2(f, data = abdom, family = BCT, optimizer = CG)\n\n## first 2 RS iterations and afterwards switch to CG\nb &lt;- gamlss2(f, data = abdom, family = BCT, CG = 2)",
    "crumbs": [
      "Reference",
      "RS_CG"
    ]
  },
  {
    "objectID": "man/misc.html",
    "href": "man/misc.html",
    "title": "gamlss2",
    "section": "",
    "text": "Various auxiliary functions to facilitate the work with formulas and fitted model objects.\n\n\n\nresponse_name(formula)\n\n\n\n\n\n\n\nformula\n\n\nA formula, Formula, or a fitted model object.\n\n\n\n\n\n\nFunction response_name extracts the response name as a character vector.\n\n\n\ngamlss2\n\n\n\n\nlibrary(\"gamlss2\")\n\n## basic formula\nf &lt;- y ~ x1 + x2 + log(x3)\nresponse_name(f)\n\n[1] \"y\"\n\n## formula with multiple responses\nf &lt;- y1 | y2 | y3 ~ x1 + s(x2) + x3 + te(log(x3), x4) | x2 + ti(x5)\nresponse_name(f)\n\n[1] \"y1\" \"y2\" \"y3\"\n\n## list of formulas\nf &lt;- list(\n  y1 ~ x1 + s(x2) + x3 + te(log(x3), x4),\n  y2  ~ x2 + sqrt(x5),\n  y3  ~ z2 + x1 + exp(x3) + s(x10)\n)\nresponse_name(f)\n\n[1] \"y1\" \"y2\" \"y3\"",
    "crumbs": [
      "Reference",
      "misc"
    ]
  },
  {
    "objectID": "man/misc.html#auxiliary-functions-for-formulas-and-model-objects",
    "href": "man/misc.html#auxiliary-functions-for-formulas-and-model-objects",
    "title": "gamlss2",
    "section": "",
    "text": "Various auxiliary functions to facilitate the work with formulas and fitted model objects.\n\n\n\nresponse_name(formula)\n\n\n\n\n\n\n\nformula\n\n\nA formula, Formula, or a fitted model object.\n\n\n\n\n\n\nFunction response_name extracts the response name as a character vector.\n\n\n\ngamlss2\n\n\n\n\nlibrary(\"gamlss2\")\n\n## basic formula\nf &lt;- y ~ x1 + x2 + log(x3)\nresponse_name(f)\n\n[1] \"y\"\n\n## formula with multiple responses\nf &lt;- y1 | y2 | y3 ~ x1 + s(x2) + x3 + te(log(x3), x4) | x2 + ti(x5)\nresponse_name(f)\n\n[1] \"y1\" \"y2\" \"y3\"\n\n## list of formulas\nf &lt;- list(\n  y1 ~ x1 + s(x2) + x3 + te(log(x3), x4),\n  y2  ~ x2 + sqrt(x5),\n  y3  ~ z2 + x1 + exp(x3) + s(x10)\n)\nresponse_name(f)\n\n[1] \"y1\" \"y2\" \"y3\"",
    "crumbs": [
      "Reference",
      "misc"
    ]
  },
  {
    "objectID": "CITATION.html",
    "href": "CITATION.html",
    "title": "Citation",
    "section": "",
    "text": "Citation\nTo cite GAMLSS in publications use:\n\nR.A. Rigby, D.M. Stasinopoulos (2005). “Generalized Additive Models for Location, Scale and Shape (with Discussion).” Journal of the Royal Statistical Society, Series C (Applied Statistics), 54, 507–554. doi:10.1111/j.1467-9876.2005.00510.x.",
    "crumbs": [
      "Citation"
    ]
  },
  {
    "objectID": "vignettes/quantiles.html",
    "href": "vignettes/quantiles.html",
    "title": "Centile (Quantile) Estimation",
    "section": "",
    "text": "Centile estimation or quantile estimation is a powerful approach in statistics that provides insights into the distributional characteristics of a response variable at various values of one of the explanatory variables. A centile is a quantile value multiplied by 100.\nThe LMS methods of Cole and Green (1992) is a subset of the GAMLSS model of Rigby and Stasinopoulos (2005). The BCPE distribution of Rigby and Stasinopoulos (2004), was used by WHO to create of child growth standards which are now used in over 150 countries. Centiles (quantiles) provide information about the entire distribution of the response variable rather than estimating just the mean (as in traditional regression).\nIn this vignette, we demonstrate how to estimate quantiles (e.g., the 10th, 50th, and 90th percentiles) using gamlss2.\nSpecifically, we will cover:",
    "crumbs": [
      "Articles",
      "Centile (Quantile) Estimation"
    ]
  },
  {
    "objectID": "vignettes/quantiles.html#the-bmi-data",
    "href": "vignettes/quantiles.html#the-bmi-data",
    "title": "Centile (Quantile) Estimation",
    "section": "1 The BMI data",
    "text": "1 The BMI data\nIn this example we use the Dutch boys BMI data, dbbmi, from the package gamlss.data. More infomation about the data can be found in Section 13.1.3 of Stasinopoulos et al. (2017). The dataset consists of \\(7294\\) rows and \\(2\\) columns, containing the variables bmi and age.\n\n## load package and data\nlibrary(\"gamlss2\")\ndata(\"dbbmi\", package = \"gamlss.data\")\n\n## plot the data\nplot(bmi ~ age, data = dbbmi, col = gray(.5))\n\n\n\n\n\n\n\n\nDue to the sharp upward trend in BMI at the lower end of age, we will apply a square root transformation (sqrt()) to the age variable to facilitate the fitting of the centile curves. The transformed data are plotted below:\n\nplot(bmi ~ sqrt(age), data = dbbmi, col = gray(.5))",
    "crumbs": [
      "Articles",
      "Centile (Quantile) Estimation"
    ]
  },
  {
    "objectID": "vignettes/quantiles.html#fitting-the-model",
    "href": "vignettes/quantiles.html#fitting-the-model",
    "title": "Centile (Quantile) Estimation",
    "section": "2 Fitting the model",
    "text": "2 Fitting the model\nNext, we will fit three different models to the data. The first model uses the Box-Cox Cole and Green distribution (BCCGo), which has three parameters: \\(\\mu\\), \\(\\sigma\\), and \\(\\nu\\). These parameters represent the location, scale, and skewness of the distribution, respectively. The BCCGo distribution is almost equivalent to fitting the Cole and Green (LMS) method.\n\n## model formula as list\n## note that we set up 4 formulas for\n## the more complex families later.\nf &lt;- ~ pb(sqrt(age))\nf &lt;- rep(list(f), 4)\nf[[1]] &lt;- update(f[[1]], bmi ~ .)\n\n## estimate model\nm1 &lt;- gamlss2(f, data = dbbmi, family = BCCGo)\n\nGAMLSS-RS iteration  1: Global Deviance = 29306.5604 eps = 0.264607     \nGAMLSS-RS iteration  2: Global Deviance = 29192.9585 eps = 0.003876     \nGAMLSS-RS iteration  3: Global Deviance = 29185.1133 eps = 0.000268     \nGAMLSS-RS iteration  4: Global Deviance = 29184.1597 eps = 0.000032     \nGAMLSS-RS iteration  5: Global Deviance = 29184.1352 eps = 0.000000     \n\n\nThe second model uses the Box-Cox power exponential distribution (BCPEo), which has four parameters: \\(\\mu\\), \\(\\sigma\\), \\(\\nu\\), and \\(\\tau\\). These parameters represent the location, scale, skewness, and kurtosis of the distribution, respectively.\n\nm2 &lt;- gamlss2(f, data = dbbmi, family = BCPEo)\n\nGAMLSS-RS iteration  1: Global Deviance = 29373.553 eps = 0.284491     \nGAMLSS-RS iteration  2: Global Deviance = 29166.7255 eps = 0.007041     \nGAMLSS-RS iteration  3: Global Deviance = 29152.7734 eps = 0.000478     \nGAMLSS-RS iteration  4: Global Deviance = 29152.1736 eps = 0.000020     \nGAMLSS-RS iteration  5: Global Deviance = 29152.1599 eps = 0.000000     \n\n\nThe final model uses the Box-Cox t distribution (BCTo), also with four parameters: \\(\\mu\\), \\(\\sigma\\), \\(\\nu\\), and \\(\\tau\\), representing location, scale, skewness, and kurtosis, respectively. The key difference between BCPEo and BCTo is that BCPEo can handle both platykurtic and leptokurtic distributions, while BCTo is limited to leptokurtic distributions. Detailed definitions of these three \"gamlss.family\" distributions can be found in Chapter 19 of Rigby et al. (2019).\n\nm3 &lt;- gamlss2(f, data = dbbmi, family = BCTo)\n\nGAMLSS-RS iteration  1: Global Deviance = 29167.1765 eps = 0.218025     \nGAMLSS-RS iteration  2: Global Deviance = 29143.0977 eps = 0.000825     \nGAMLSS-RS iteration  3: Global Deviance = 29142.3472 eps = 0.000025     \nGAMLSS-RS iteration  4: Global Deviance = 29142.1955 eps = 0.000005     \n\n\nWe can now select the best-fitting model using the generalized Akaike Information Criterion (GAIC), implemented in the GAIC() function.\n\nGAIC(m1, m2, m3)\n\n        AIC       df\nm3 29203.92 30.86223\nm2 29211.18 29.50911\nm1 29236.12 25.99076\n\n\nNote that all models were fitted using the square root transformation (sqrt()) for age to facilitate the smoothing function, pb(). Also, by default, the GAIC() function uses the classical Akaike Information Criterion (AIC). Based on the AIC, the m3 model appears to provide the best fit.",
    "crumbs": [
      "Articles",
      "Centile (Quantile) Estimation"
    ]
  },
  {
    "objectID": "vignettes/quantiles.html#diagnostics",
    "href": "vignettes/quantiles.html#diagnostics",
    "title": "Centile (Quantile) Estimation",
    "section": "3 Diagnostics",
    "text": "3 Diagnostics\nSeveral diagnostic tools are available to assess the adequacy of a fitted model. One useful tool is the worm plot, a detrended Q-Q plot that provides valuable insight into the fit of the distribution. The plot can be generated with\n\nplot(m3, which = \"wp\")\n\n\n\n\n\n\n\n\nOur preferred approach is to use the resid_wp() function from the gamlss.ggplots package, as it provides additional useful information.\n\nlibrary(\"gamlss.ggplots\")\nresid_wp(m3)\n\nThe function model_wp() can be use for multiple model worm plots.\n\nmodel_wp(m1, m2, m3)\n\nOne of the advantages of the gamlss.ggplots package is its ability to split the worm plot into different age ranges, which is useful for detecting model inadequacies across various age groups. Here’ s how you can use the model_wp_wrap() function:\n\nmodel_wp_wrap(m1,m2,m3,xvar=dbbmi$age)",
    "crumbs": [
      "Articles",
      "Centile (Quantile) Estimation"
    ]
  },
  {
    "objectID": "vignettes/quantiles.html#centile-computation",
    "href": "vignettes/quantiles.html#centile-computation",
    "title": "Centile (Quantile) Estimation",
    "section": "4 Centile Computation",
    "text": "4 Centile Computation\nTo obtain plots or tables of fitted centile curves, we can use the gamlss2 generic quantile() method to generate a table of predicted values. We then use these values to plot the relevant curves. First, we create a grid for age with a length of 300 and use it to predict the relevant quantiles.\n\n## set tup new data for prediction\nnd &lt;- with(dbbmi, data.frame(\"age\" = seq(min(age), max(age), length = 300)))\n\n## compute quantiles/centiles\nqu &lt;- c(0.02, 0.10, 0.25, 0.50, 0.75, 0.90, 0.98)\nfit &lt;- quantile(m3, newdata = nd, probs = qu)\n\n## estimated values\nhead(fit)\n\n        2%      10%      25%      50%      75%      90%      98%\n1 11.20725 12.09278 12.75882 13.50573 14.30283 15.10974 16.35648\n2 12.33387 13.26385 13.96394 14.74787 15.58075 16.41769 17.69525\n3 13.05537 14.01173 14.73189 15.53745 16.39101 17.24505 18.53968\n4 13.58129 14.55547 15.28902 16.10882 16.97577 17.84063 19.14547\n5 13.97783 14.96424 15.70684 16.53615 17.41186 18.28358 19.59438\n6 14.27853 15.27310 16.02164 16.85707 17.73829 18.61413 19.92805\n\n\nNow we plot the data and then fitted curves.\n\n## plot estimated curves\npar(mar = c(4, 4, 1, 1)) \nplot(bmi ~ age, data = dbbmi,   pch = 16, col = rgb(0.1, 0.1, 0.1, alpha = 0.1)) \nmatplot(nd$age, fit, type = \"l\",   lwd = 2, lty = 1, col = 4, add = TRUE)\n\n\n\n\n\n\n\n\nA more elegant plot can be generated using the fitted_centiles() or fitted_centiles_legend() functions from the gamlss.ggplots package. For example:\n\nfitted_centiles_legend(m3, cent= c(2, 10, 25, 50, 75, 90, 98))",
    "crumbs": [
      "Articles",
      "Centile (Quantile) Estimation"
    ]
  },
  {
    "objectID": "vignettes/quantiles.html#summary",
    "href": "vignettes/quantiles.html#summary",
    "title": "Centile (Quantile) Estimation",
    "section": "5 Summary",
    "text": "5 Summary\nThe gamlss2 package offers the appropriate models and tools for generating centile curves. For more detailed information and diagnostics related to centile curve estimation, refer to Chapter 13 of Stasinopoulos et al. (2017). Additionally, the gamlss.ggplots package provides useful extra functions for plotting and diagnostics.",
    "crumbs": [
      "Articles",
      "Centile (Quantile) Estimation"
    ]
  },
  {
    "objectID": "vignettes/mixture.html",
    "href": "vignettes/mixture.html",
    "title": "Mixture Models",
    "section": "",
    "text": "Mixture models are used for modeling data generated from multiple distinct processes, where each process can be described by a separate probability distribution. The challenge is that for each observation, we do not know which process generated it, and therefore we must infer the underlying latent components.\nThis vignette demonstrates how to fit flexible mixture models using gamlss2.",
    "crumbs": [
      "Articles",
      "Mixture Models"
    ]
  },
  {
    "objectID": "vignettes/mixture.html#model-overview",
    "href": "vignettes/mixture.html#model-overview",
    "title": "Mixture Models",
    "section": "1 Model Overview",
    "text": "1 Model Overview\nIn a finite mixture model, each observation \\(y_i\\) for \\(i = 1, \\ldots, n\\), is assumed to be generated from one of \\(K\\) distinct underlying distributions. The probability that an observation comes from the \\(k\\)-th component is determined by the mixing probability \\(\\pi_k(\\mathbf{x}_i)\\), which may depend on covariates \\(\\mathbf{x}_i\\). The probability density function (pdf) of \\(y_i\\) is expressed as\n\\[\nd(y_i \\mid \\mathbf{x}_i) = \\sum_{k=1}^{K} \\pi_k(\\mathbf{x}_i) d_k(y_i \\mid \\boldsymbol{\\theta}_k(\\mathbf{x}_i)).\n\\]\nWhere\n\n\\(\\pi_k(\\mathbf{x}_i)\\) is the probability that the \\(i\\)-th observation belongs to the \\(k\\)-th component,\n\\(d_k(y_i \\mid \\boldsymbol{\\theta}_k(\\mathbf{x}_i))\\) is the pdf of the \\(k\\)-th component, parameterized by \\(\\boldsymbol{\\theta}_k(\\mathbf{x}_i) = (\\theta_{1k}(\\mathbf{x}_i), \\ldots, \\theta_{J_kk}(\\mathbf{x}_i))^\\top\\), \\(j = 1, \\ldots, J_k\\),\nand the sum of \\(\\pi_k(\\mathbf{x}_i)\\) over all components equals 1.\n\nWhile \\(\\pi_k(\\mathbf{x}_i)\\) represents the prior probability of the observation belonging to the \\(k\\)-th component, posterior mixing probabilities refine this by considering both the prior and the likelihood of the observed data under each component.\nGiven the observation \\(y_i\\) and the estimated model parameters, the posterior probability that \\(y_i\\) belongs to the \\(k\\)-th component is computed as\n\\[\n\\text{Pr}(z_i = k \\mid y_i, \\mathbf{x}_i) = \\frac{\\pi_k(\\mathbf{x}_i) d_k(y_i \\mid \\boldsymbol{\\theta}_k(\\mathbf{x}_i))}{\\sum_{k=1}^K \\pi_k(\\mathbf{x}_i) d_k(y_i \\mid \\boldsymbol{\\theta}_k(\\mathbf{x}_i))}.\n\\]\nThis posterior probability gives a more accurate assessment of which component likely generated the observation, incorporating both the component probability (prior) and the likelihood of observing the data under each component. In mixture models, these posterior probabilities are often used for:\n\nClassifying observations: Assigning each observation to the most likely component.\nAnalyzing component memberships: Understanding the uncertainty in assigning observations to components.\n\nIn practice, posterior mixing probabilities will not always be close to 0 or 1. If an observation could reasonably belong to multiple components, the probabilities may be more evenly distributed across components.",
    "crumbs": [
      "Articles",
      "Mixture Models"
    ]
  },
  {
    "objectID": "vignettes/mixture.html#two-component-normal-mixture-model",
    "href": "vignettes/mixture.html#two-component-normal-mixture-model",
    "title": "Mixture Models",
    "section": "2 Two-Component Normal Mixture Model",
    "text": "2 Two-Component Normal Mixture Model\nFor a two-component normal mixture model, the response \\(y_i\\) is generated by one of two normal distributions. The pdf is given by\n\\[\nd(y_i \\mid \\mathbf{x}_i) = \\sum_{k=1}^2 \\pi_k(\\mathbf{x}_i) \\mathcal{N}(y_i \\mid \\boldsymbol{\\theta}_k = (\\mu_k(\\mathbf{x}_i), \\sigma_k(\\mathbf{x}_i))).\n\\]\nWhere\n\n\\(\\mathcal{N}(y \\mid \\boldsymbol{\\theta} = (\\mu, \\sigma))\\) denotes a normal distribution with mean \\(\\mu\\) and standard deviation \\(\\sigma\\),\nthe parameters \\(\\boldsymbol{\\theta}_k = (\\mu_k(\\mathbf{x}_i), \\sigma_k(\\mathbf{x}_i))^\\top\\) are functions of covariates \\(\\mathbf{x}_i\\),\nand to ensure the component probabilities sum to one, we set \\(\\pi_2(\\mathbf{x}_i) = 1 - \\pi_1(\\mathbf{x}_i)\\).",
    "crumbs": [
      "Articles",
      "Mixture Models"
    ]
  },
  {
    "objectID": "vignettes/mixture.html#gamlss-framework-for-the-mixture-model",
    "href": "vignettes/mixture.html#gamlss-framework-for-the-mixture-model",
    "title": "Mixture Models",
    "section": "3 GAMLSS Framework for the Mixture Model",
    "text": "3 GAMLSS Framework for the Mixture Model\nIn the GAMLSS framework, each parameter \\(\\boldsymbol{\\theta}_{k}(\\mathbf{x}_i) = (\\boldsymbol{\\theta}_{1k}(\\mathbf{x}_i), \\ldots, \\boldsymbol{\\theta}_{J_kk}(\\mathbf{x}_i))^{\\top}\\), as well as the mixing probabilities \\(\\pi_k(\\mathbf{x}_i)\\), are modeled using GAM-type predictors given by\n\\[\n\\eta_{jk}(\\mathbf{x}_i) = f_{1k}(\\mathbf{x}_i) + \\dots + f_{L_{jk}k}(\\mathbf{x}_i),\n\\]\nwhich are linked to the parameters through \\(h_{jk}(\\theta_{jk}(\\mathbf{x}_i)) = \\eta_{jk}(\\mathbf{x}_i)\\) using suitable link functions \\(h_{jk}(\\cdot)\\). The functions \\(f_{lk}(\\cdot)\\), \\(l = 1, \\ldots, L_{jk}\\), can be nonlinear smooth functions (typically estimated using regression splines), linear effects, or random effects, among others.\nFor the two-component normal mixture, we use\n\nIdentity link for the means: \\(\\mu_k(\\mathbf{x}_i) = \\eta_{1k}(\\mathbf{x}_i)\\),\nLog-link for the standard deviations: \\(\\log(\\sigma_k(\\mathbf{x}_i)) = \\eta_{2k}(\\mathbf{x}_i)\\),\nLogit-link for the mixing probability: \\(\\log\\left(\\frac{\\pi_k(\\mathbf{x}_i)}{1 - \\pi_k(\\mathbf{x}_i)}\\right) = \\eta_{\\pi k}(\\mathbf{x}_i)\\).",
    "crumbs": [
      "Articles",
      "Mixture Models"
    ]
  },
  {
    "objectID": "vignettes/mixture.html#example-using-simulated-data",
    "href": "vignettes/mixture.html#example-using-simulated-data",
    "title": "Mixture Models",
    "section": "4 Example using Simulated Data",
    "text": "4 Example using Simulated Data\nWe begin by simulating data where the response y is generated by one of two normal distributions, depending on a covariate x. The latent component membership is determined by a logistic model. Morover, we let the standard deviation of the first component also depend on x.\n\nset.seed(123)\n\n## simulate covariate\nn &lt;- 2000\nx &lt;- sort(runif(n, -pi, pi))\n\n## logistic model for mixing probability (dependent on x)\n## this creates a probability that varies with x using a logistic function\nmix_prob &lt;- 1 / (1 + exp(-1 - 0.5 * x))\n\n## simulate latent component assignment based on covariate-dependent probability\nz &lt;- rbinom(n, 1, mix_prob)\n\n## generate response based on the latent component\ny &lt;- ifelse(z == 1,\n            sin(x) + rnorm(n, sd = exp(-2 + cos(x))),\n            cos(x) + rnorm(n, sd = 0.2))\n\n## combine into a data frame\nd &lt;- data.frame(\"x\" = x, \"y\" = y)\n\n## plot the data, color by latent component z\npar(mar = c(4, 4, 4, 1))\nplot(d, col = z + 1, main = \"Simulated Data by Latent Component\", \n     xlab = \"x\", ylab = \"y\")",
    "crumbs": [
      "Articles",
      "Mixture Models"
    ]
  },
  {
    "objectID": "vignettes/mixture.html#defining-a-custom-gamlss2-mixture-family",
    "href": "vignettes/mixture.html#defining-a-custom-gamlss2-mixture-family",
    "title": "Mixture Models",
    "section": "5 Defining a Custom gamlss2 Mixture Family",
    "text": "5 Defining a Custom gamlss2 Mixture Family\nTo fit the mixture model in gamlss2, we define a custom family of distributions. In this case, we create a mixture of two normal distributions (using dnorm()) where the mixing probabilities depend on a covariate.\n\n## mixture family definition for a normal mixture\nNOmx &lt;- function(...) {\n  fam &lt;- list(\n    \"family\" = \"Normal Mixture\",\n    \"names\" = c(\"mu1\", \"mu2\", \"sigma1\", \"sigma2\", \"pi\"),\n    \"links\" = c(\"mu1\" = \"identity\", \"mu2\" = \"identity\",\n                \"sigma1\" = \"log\", \"sigma2\" = \"log\", \"pi\" = \"logit\"),\n    \"d\" = function(y, par, log = FALSE, ...) {\n      d &lt;- par$pi * dnorm(y, par$mu1, par$sigma1) +\n        (1 - par$pi) * dnorm(y, par$mu2, par$sigma2)\n      if(log) d &lt;- log(d)\n      return(d)\n    }\n  )\n  class(fam) &lt;- \"gamlss2.family\"\n  return(fam)\n}\n\nNote that in this case, analytical derivatives for the likelihood function are not explicitly defined in the family. As a result, the parameter estimation relies on numerical derivatives. While this approach is feasible, defining analytical derivatives would significantly speed up the estimation process and improve computational efficiency.",
    "crumbs": [
      "Articles",
      "Mixture Models"
    ]
  },
  {
    "objectID": "vignettes/mixture.html#estimation",
    "href": "vignettes/mixture.html#estimation",
    "title": "Mixture Models",
    "section": "6 Estimation",
    "text": "6 Estimation\nWe now proceed to fit the mixture model. The model includes smooth functions (s(x)), which are used to model the means, standard deviations, and the mixing probability for the two components. This flexible approach allows the influence of the covariate x to vary smoothly across the different parameters of the mixture distribution.\nThe model can be estimated with\n\n## model formula, spline for each parameter\nf &lt;- y ~ s(x) | s(x) | s(x) | s(x) | s(x)\n\n## estimate normal GAMLSS mixture model\nb &lt;- gamlss2(f, data = d, family = NOmx)\n\nPlot estimated effects.\n\npar(mar = c(4, 4, 1, 1))\nplot(b)\n\n\n\n\n\n\n\n\nThe estimated effects indicate that the GAMLSS mixture model fits the data very well. Both mean components closely align with the true data-generating process. Additionally, the estimated standard deviation for the first component is also accurately captured, and the linear effect for the mixing probability is well-estimated.",
    "crumbs": [
      "Articles",
      "Mixture Models"
    ]
  },
  {
    "objectID": "vignettes/mixture.html#predicting-and-visualizing-results",
    "href": "vignettes/mixture.html#predicting-and-visualizing-results",
    "title": "Mixture Models",
    "section": "7 Predicting and Visualizing Results",
    "text": "7 Predicting and Visualizing Results\nWe predict the component-specific means (mu1, mu2) and the mixing probability (pi) from the fitted model. Then, we compare the predicted and true component probabilities and plot the fitted means along with the data.\nFirst, compute predicted parameters.\n\np &lt;- predict(b, type = \"parameter\")\n\nPlot estimated vs. true component probabilities.\n\npar(mar = c(4, 4, 4, 1))\nplot(mix_prob, p[,\"pi\"], main = \"Mixing Probabilities (True vs. Estimated)\",\n     xlab = \"True\", ylab = \"Estimated\", col = 1)\nabline(0, 1, lty = 2, col = 4, lwd = 2)\n\n\n\n\n\n\n\n\nOverlay predicted means onto the observed data.\n\n## compute posterior component probabilities\nd1 &lt;- dnorm(d$y, p$mu1, p$sigma1)\nd2 &lt;- dnorm(d$y, p$mu2, p$sigma2)\ntotprob &lt;- rowSums(cbind(p$pi * d1, (1 - p$pi) * d2))\np1 &lt;- p$pi * d1  / totprob\np2 &lt;- (1 - p$pi) * d2  / totprob\n\n## get components\ncomp &lt;- apply(cbind(p2, p1), 1, which.max)\n\n## extract component means and quantiles\nf1 &lt;- cbind(\n  \"1%\" = qnorm(0.01, mean = p[, \"mu1\"], sd = p[, \"sigma1\"]),\n  \"Mean\" = p[, \"mu1\"],\n  \"99%\" = qnorm(0.99, mean = p[, \"mu1\"], sd = p[, \"sigma1\"])\n)\n\nf2 &lt;- cbind(\n  \"1%\" = qnorm(0.01, mean = p[, \"mu2\"], sd = p[, \"sigma2\"]),\n  \"Mean\" = p[, \"mu2\"],\n  \"99%\" = qnorm(0.99, mean = p[, \"mu2\"], sd = p[, \"sigma2\"])\n)\n\n## colors for plotting components\ncol &lt;- rep(\"#DF536B4D\", length(p1))\ncol[comp == 1] &lt;- \"#1A1A1A4D\"\n\n## plot data and fitted values\npar(mar = c(4, 4, 4, 1))\nplot(d, col = col, main = \"Fitted Component Means\",\n     xlab = \"x\", ylab = \"y\")\nmatplot(d$x, f1, type = \"l\", lty = c(2, 1, 2),\n  lwd = c(1, 3, 1), col = 2, add = TRUE)\nmatplot(d$x, f2, type = \"l\", lty = c(2, 1, 2),\n  lwd = c(1, 3, 1), col = 1, add = TRUE)\n\n\n\n\n\n\n\n\nThe plot shows that the estimated component means are highly accurate, and the observations are assigned to the two components with high precision. Moreover, by using a full GAMLSS model for both components, we are able to compute corresponding quantile estimates, which align well with the data.\nThe posterior probabilities can be visualized with\n\npar(mar = c(4, 4, 4, 1))\nplot(p1 ~ d$x, col = comp,\n  xlab = \"x\", ylab = \"Probability\",\n  main = \"Posterior Probabilities\")\n\n\n\n\n\n\n\n\nThe plot clearly illustrates that component classification is less certain in areas where the data points overlap.",
    "crumbs": [
      "Articles",
      "Mixture Models"
    ]
  },
  {
    "objectID": "vignettes/mixture.html#summary",
    "href": "vignettes/mixture.html#summary",
    "title": "Mixture Models",
    "section": "8 Summary",
    "text": "8 Summary\nThis vignette demonstrated how to estimate flexible mixture models using gamlss2. The framework allows us to model the means, variances, and mixing probabilities of the components in a very flexible manner using smooth effects of covariates.",
    "crumbs": [
      "Articles",
      "Mixture Models"
    ]
  },
  {
    "objectID": "vignettes/gamlss2.html",
    "href": "vignettes/gamlss2.html",
    "title": "First Steps",
    "section": "",
    "text": "The package is designed to follow the workflow of well-established model fitting functions like lm() or glm(), i.e., the step of estimating full distributional regression models is actually not very difficult.\nTo illustrate the workflow using gamlss2, we analyze the HarzTraffic data, where we model the number of motorcycles (response bikes) at Sonnenberg in the Harz region of Germany. The data can be loaded with\ndata(\"HarzTraffic\")\nhead(HarzTraffic)\n\n        date yday bikes cars trucks others tempmin tempmax  temp humidity\n1 2021-01-01    0     2 3135     25      1     0.2     2.6  1.32       85\n2 2021-01-02    1     7 6593     32     10     1.6     4.0  2.63       72\n3 2021-01-03    2     0 3367     30      2    -0.4     1.2  0.19       94\n4 2021-01-04    3     0 2186     75      0    -0.6    -0.1 -0.37       97\n5 2021-01-05    4     3 2071     68      0    -0.6     0.5 -0.21       98\n6 2021-01-06    5     1 2022     97      0    -0.2     0.5  0.17       93\n  tempdew cloudiness rain sunshine wind windmax\n1   -0.93         99  1.2       50 1.38     3.7\n2   -1.99        100  0.0       13 1.35     2.4\n3   -0.65         98 13.5        0 1.74     2.8\n4   -0.78         99  3.8        0 1.39     2.1\n5   -0.46         98  5.3        0 1.42     2.1\n6   -0.84         97  4.5        0 3.02     4.6\nThe data consists of seasonal time information (variable yday) along with a number of environmental variables (e.g. mean daily temperature). As a first model, we estimate a linear regression model with normal errors (which is the default)\nb1 &lt;- gamlss2(bikes ~ temp + rain + sunshine + wind, data = HarzTraffic)\n\nGAMLSS-RS iteration  1: Global Deviance = 14325.7146 eps = 0.046095     \nGAMLSS-RS iteration  2: Global Deviance = 14325.7146 eps = 0.000000     \n\nsummary(b1)\n\nCall:\ngamlss2(formula = bikes ~ temp + rain + sunshine + wind, data = HarzTraffic)\n---\nFamily: NO \nLink function: mu = identity, sigma = log\n*--------\nParameter: mu \n---\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -15.33601   19.67683  -0.779   0.4359    \ntemp         17.68501    1.01429  17.436  &lt; 2e-16 ***\nrain         -3.76399    1.74873  -2.152   0.0316 *  \nsunshine      0.36452    0.02995  12.172  &lt; 2e-16 ***\nwind        -25.26905    4.38768  -5.759 1.11e-08 ***\n*--------\nParameter: sigma \n---\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  5.35765    0.02175   246.3   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n*--------\nn = 1057 df =  6 res.df =  1051\nDeviance = 14325.7146 Null Dev. Red. = 4.61%\nAIC = 14337.7146 elapsed =  0.02sec\nNote that the summary output is very similar to lm() and glm() with the main difference being that summary outputs are provided for all parameters of the distribution. In this case, the model is estimated using the NO family of the gamlss.dist package, a two-parameter distribution with parameters mu and sigma.",
    "crumbs": [
      "Articles",
      "First Steps"
    ]
  },
  {
    "objectID": "vignettes/gamlss2.html#residual-diagnostics",
    "href": "vignettes/gamlss2.html#residual-diagnostics",
    "title": "First Steps",
    "section": "1 Residual Diagnostics",
    "text": "1 Residual Diagnostics\nSince we estimated a simple linear model with Gaussian errors up to now, we are assuming that the distribution of the response variable, the number of motorcycles (bikes), follows a normal distribution with constant variance. However, this assumption may not always hold true, especially when the response variable is count data, which often exhibits overdispersion or non-constant variance. The data also exhibits a strong seasonal effect that is likely not fully explained by the environmental variables alone. This effect may include nonlinear patterns that require further modeling for proper capture.\nTo assess whether the linear normal distribution with constant variance is appropriate, we can start by examining diagnostic plots.\n\nplot(b1)\n\n\n\n\n\n\n\n\nThese plots help us visually inspect the residuals for any deviations from the assumptions of normality and constant variance.",
    "crumbs": [
      "Articles",
      "First Steps"
    ]
  },
  {
    "objectID": "vignettes/gamlss2.html#estimating-nonlinear-effects",
    "href": "vignettes/gamlss2.html#estimating-nonlinear-effects",
    "title": "First Steps",
    "section": "2 Estimating Nonlinear Effects",
    "text": "2 Estimating Nonlinear Effects\nThe gamlss2 package uses the mgcv infrastructures for estimating nonlinear smooth effects. Now, let’s inspect the seaonal aspect of the data, there\n\npar(mar = c(4, 4, 1, 1))\nplot(bikes ~ yday, data = HarzTraffic)\n\n\n\n\n\n\n\n\nClearly, the number of bikes increases during the summer season. Therefore, we add the seasonal component to the model using the s() smooth constructor of the mgcv package. Moreover, since the variation of the number of bikes increases during the summer season, we now estimate a full GAMLSS and model also the variance parameter of the normal distribution by covariates\n\n## set up the model formula for\n## the mu and sigma parameter\n## the vertical | separates the two formulae\nf &lt;- bikes ~ temp + rain + sunshine + wind + s(yday, bs = \"cc\") |\n  temp + rain + sunshine + wind + s(yday, bs = \"cc\")\n\n## estimate model\nb2 &lt;- gamlss2(f, data = HarzTraffic)\n\nGAMLSS-RS iteration  1: Global Deviance = 13297.5718 eps = 0.114556     \nGAMLSS-RS iteration  2: Global Deviance = 12597.9982 eps = 0.052609     \nGAMLSS-RS iteration  3: Global Deviance = 12015.6207 eps = 0.046227     \nGAMLSS-RS iteration  4: Global Deviance = 11573.0053 eps = 0.036836     \nGAMLSS-RS iteration  5: Global Deviance = 11473.3928 eps = 0.008607     \nGAMLSS-RS iteration  6: Global Deviance = 11469.6654 eps = 0.000324     \nGAMLSS-RS iteration  7: Global Deviance = 11469.5761 eps = 0.000007     \n\n\nPlot estimated seasonal effect.\n\nplot(b2)\n\n\n\n\n\n\n\n\nThe effect for both, mu and sigma show a clear seasonal peak during summer times.\nInspect again model residuals\n\nplot(b2, which = \"resid\")\n\n\n\n\n\n\n\n\nThe quantile residuals show a much better model fit, but still show that the model might not be the most appropriate for predicting the number of bikes.",
    "crumbs": [
      "Articles",
      "First Steps"
    ]
  },
  {
    "objectID": "vignettes/gamlss2.html#count-models",
    "href": "vignettes/gamlss2.html#count-models",
    "title": "First Steps",
    "section": "3 Count Models",
    "text": "3 Count Models\nNow, instead of a normal distribution, we use the negative binomial distribution for count data\n\nb3 &lt;- gamlss2(f, data = HarzTraffic, family = NBI)\n\nGAMLSS-RS iteration  1: Global Deviance = 9919.2995 eps = 0.168829     \nGAMLSS-RS iteration  2: Global Deviance = 9831.291 eps = 0.008872     \nGAMLSS-RS iteration  3: Global Deviance = 9822.4009 eps = 0.000904     \nGAMLSS-RS iteration  4: Global Deviance = 9820.9371 eps = 0.000149     \nGAMLSS-RS iteration  5: Global Deviance = 9819.6573 eps = 0.000130     \nGAMLSS-RS iteration  6: Global Deviance = 9819.4805 eps = 0.000018     \nGAMLSS-RS iteration  7: Global Deviance = 9819.3814 eps = 0.000010     \nGAMLSS-RS iteration  8: Global Deviance = 9819.35 eps = 0.000003     \n\n\nPlot again the estimated smooth seasonal effects.\n\nplot(b3)\n\n\n\n\n\n\n\n\nInspecting the model residuals again shows a major improvement.\n\nplot(b3, which = \"resid\")",
    "crumbs": [
      "Articles",
      "First Steps"
    ]
  },
  {
    "objectID": "vignettes/selection.html",
    "href": "vignettes/selection.html",
    "title": "Model Selection",
    "section": "",
    "text": "A distribution regression model is defined as\n\\[\\begin{split}\ny_i     &  \\stackrel{\\small{ind}}{\\sim }&  {D}( \\theta_{1i}, \\ldots, \\theta_{ki}) \\nonumber \\\\\ng(\\theta_{1i})  &=& b_{10} + s_1({x}_{1i})  +  \\ldots,  s_p({x}_{pi}) \\nonumber\\\\\n\\ldots &=& \\ldots \\nonumber\\\\\ng({\\theta}_{ki})  &=& b_0 + s_1({x}_{1i})  +   \\ldots,  s_p({x}_{pi})\n\\end{split}\n\\tag{1}\\] where \\({D}( )\\) is the assumed distribution which depends on parameters \\(\\theta_{1i}, \\ldots, \\theta_{ki}\\) and where all the parameters can be functions of the explanatory variables \\(({x}_{1i}, \\ldots, {x}_{pi})\\). In reality we do not know the distribution \\({D}( )\\) and also we do not know which and how the variables \\(({x}_{1i}, \\ldots, {x}_{pi})\\) effect the parameters \\(\\theta_{1i}, \\ldots, \\theta_{ki}\\). So the model selection in a distributional regression model should;\nOne way to achieve that is the following general algorithm for searching for best model;\nThe selection criterion could be a GAIC defined on the training data a measure defined in the out of bag data. While the above algorithm could work reasonable with data having a relative small number or explanatory variables could be very slow for data with a lot of explanatory variables.\nCutting corners could improve the speed of the algorithm. For example, if the practitioner gives up the smooth additive structure, that gamlss2 provides, and he/she prepare to use only linear terms, a LASSO method can be used at step 2 which will speed up things. Also if the practitioner has confidence on a particular distribution choice, then only the selection step 2 should be performed. The support for a specific distribution can enforced my the preliminary analysis for choosing a distribution described in Section 1.2 and suggested in Stasinopoulos et al. (2024).",
    "crumbs": [
      "Articles",
      "Model Selection"
    ]
  },
  {
    "objectID": "vignettes/selection.html#sec-Selectadistribution",
    "href": "vignettes/selection.html#sec-Selectadistribution",
    "title": "Model Selection",
    "section": "1 Select a distribution",
    "text": "1 Select a distribution\n\n1.1 The range of the response\nThe first thing to take into the account in the selection of the distribution is that the distribution should be defined in the range of the response variable. Figure 1 shows the different possibilities depending on whether the response is continuous, discrete of factor If the response is continuous and has negative values a distribution in the real line is appropriate. For positive responses a positive real line distribution is appropriate. For bounded continuous response we have the options to transform the response to values between 0 and 1 or to create an appropriate truncated distribution. For count response the consideration is whether the counts are finite or not. For infinity counts a distribution similar to the Poisson distribution can be used. For finite counts binomial type distributions can be used. The case in which the response is a categorical variable (factor) is called classification regression. If the factor is an ordered factor appropriate models exist but we will not deal with them here. For unordered factor responses a binomial distribution can be use if the classification is binary otherwise a multinomial distribution. Note that for classification problems, there is a vast literature in machine learning to deal with the problem.\n\n\n\n\n\n\nflowchart LR\n  A[responce] --&gt; B(continuous) \n  A --&gt; C[discrete]\n  A --&gt; D[factor]\n  B --&gt; F[real line]\n  B --&gt; G[pos. real line]\n  B --&gt; H[0 to 1]\n  C --&gt; J[infinite count]\n  C --&gt; I[finite count]\n  D --&gt; K[unordered]\n  D --&gt; L[ordered]\n  I --&gt; N[binary]\n  K --&gt; N[binary]\n\n\n\n\nFigure 1: The response determines which type of distribution to use.\n\n\n\n\n\n\n\n1.2 Preliminary analysis\nA preliminary analysis in selecting the distribution can be performed using the chooseDist() function of the package gamlss. Here we used the rent data of the package gamlss.data. We first bring the package and the data set in;\n\nlibrary(gamlss2)\nlibrary(gamlss)\nda &lt;- rent99[, -c(2,9)]\nhead(da)\n\n      rent area yearc location bath kitchen cheating\n1 109.9487   26  1918        2    0       0        0\n2 243.2820   28  1918        2    0       0        1\n3 261.6410   30  1918        1    0       0        1\n4 106.4103   30  1918        2    0       0        0\n5 133.3846   30  1918        2    0       0        1\n6 339.0256   30  1918        2    0       0        1\n\n\nThe response variable is is rent and there are two continuous, the area of the flat area and the year of construction yearc and 4 categorical variables, location, bath, kitchen and central heating, cheating.\nHere, first we fit a linear model with all explanatory variables to the location parameters \\(\\mu\\) and scale parameter \\(\\sigma\\). Later we use the function chooseDist() to find out which distribution from the ones in positive real line fit, type=\"realplus\", best fit the data, given that \\(\\mu\\) and \\(\\sigma\\) models are fitted linearly with all available variables. Note that, in order to speed up the procedure, we used here a parallel version of chooseDist() using snow with 10 NCPUS (the maximum that our machine can take). Please modify accordantly to your machine capabilities.\n\n m1 &lt;- gamlss2(rent~.|., data=da, family=GA,trace=FALSE)\n M1 &lt;- gamlss:::chooseDist(m1, type=\"realplus\", parallel=\"snow\", ncpus=10)\n\nminimum GAIC(k= 2 ) family: BCTo \nminimum GAIC(k= 3.84 ) family: BCCGo \nminimum GAIC(k= 8.03 ) family: BCCGo \n\n\nThe function chooseDist() chooses the “best” distribution according to a GAIC criterion. In our case the BCTo distribution was chosen using AIC while the BCCGo using \\(\\chi^2\\) or BIC criteria, respectively.",
    "crumbs": [
      "Articles",
      "Model Selection"
    ]
  },
  {
    "objectID": "vignettes/selection.html#sec-Selectappropriatevariables",
    "href": "vignettes/selection.html#sec-Selectappropriatevariables",
    "title": "Model Selection",
    "section": "2 Select appropriate variables",
    "text": "2 Select appropriate variables\nThe methodology of “which explanatory variable is needed and for which parameters” depends on the scope of modelling, while special attention has to be taken for non-linear relationships and for interaction. If the scope of the model is to provide good interpretation then the additive smooth structure of gamlss2is adequate because can cope well with non-linearities and relatively well with interactions. Note that interactions in an additive structure have to specified explicitly while in some machine learning algorithms like neural network they come as part of the model. Machine learning algorithms like random forest and neural networks are more difficult to interpreter therefore more suited for prediction purposes. Here we will discuss the the step-wise methodology while boosting is discussed in a different vignette?.\n\ndata(\"rent\", package = \"gamlss.data\")\n\nBecause the possiblility of linear interactions, we shall scale the two continuous covariates first;\n\nrent$Fl &lt;- scale(rent$Fl)\nrent$A &lt;- scale(rent$A)\n\nThe formula defines the searching scope of the search;\n\nf &lt;- R ~ Fl + A + Fl:A + loc + s(Fl) + s(A) + te(Fl, A) |\n  Fl + A + loc + Fl:A + s(Fl) + s(A) + te(Fl, A)\n\nHere we use the the stepwise algorithm to find the “best” explanatory variables using a Gamma family model;\n\nb &lt;- step_gamlss2(f, data = rent, family = GA, K = 2)\n\nBidirectional Linear Selection\n  GAIC = 28104.4252 &lt;+&gt; parameter mu, term Fl\n  GAIC = 27996.2040 &lt;+&gt; parameter mu, term A\n  GAIC = 27937.8423 &lt;+&gt; parameter sigma, term A\n  GAIC = 27905.5919 &lt;+&gt; parameter mu, term loc3\n  GAIC = 27863.1707 &lt;+&gt; parameter mu, term loc2\n  GAIC = 27860.8491 &lt;+&gt; parameter sigma, term loc3\n  GAIC = 27856.2102 &lt;+&gt; parameter sigma, term loc2\nBidirectional Selection\n  GAIC = 27766.9437 &lt;+&gt; parameter mu, term te(Fl,A)\n  GAIC = 27736.7146 &lt;+&gt; parameter sigma, term te(Fl,A)\n  GAIC = 27734.7120 &lt;-&gt; parameter mu, term A\n  GAIC = 27732.7116 &lt;-&gt; parameter sigma, term A\n  GAIC = 27730.7149 &lt;-&gt; parameter mu, term Fl\nContinue\nFinal Model\n$mu\n.. ~1 + loc3 + loc2 + te(Fl, A)\n$sigma\n.. ~1 + loc3 + loc2 + te(Fl, A)\n\n\nNote that step_gamlss2() is equivalent to using\n\nb &lt;- gamlss2(f, data = rent, family = GA, optimizer = stepwise, K = 2)\n\nThe new_formula() function will show the new selected model terms;\n\nnew_formula(b)\n\n$mu\nR ~ loc3 + loc2 + te(Fl, A)\n\n$sigma\n~1 + loc3 + loc2 + te(Fl, A)\n\n\nHere is the summary of the final model;\n\nsummary(b)\n\nCall:\ngamlss2(formula = formula, data = ..1, family = ..2, ... = pairlist(optimizer = stepwise, K = K, strategy = strategy, keeporder = keeporder, cores = cores))\n---\nFamily: GA \nLink function: mu = log, sigma = log\n*--------\nParameter: mu \n---\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  6.46626    0.03108 208.053  &lt; 2e-16 ***\nloc3         0.28437    0.03428   8.294  &lt; 2e-16 ***\nloc2         0.18899    0.03273   5.775 8.96e-09 ***\n---\nSmooth terms:\n    te(Fl,A)\nedf   17.834\n*--------\nParameter: sigma \n---\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.89132    0.04390 -20.301  &lt; 2e-16 ***\nloc3        -0.17639    0.04950  -3.564 0.000375 ***\nloc2        -0.11723    0.04672  -2.509 0.012183 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n---\nSmooth terms:\n    te(Fl,A)\nedf   22.773\n*--------\nn = 1969 df =  46.61 res.df =  1922.39\nDeviance = 27637.5013 Null Dev. Red. = 3.4%\nAIC = 27730.7149 elapsed = 28.80sec\n\n\nand here are the smooth fitted plots;\n\nplot(b)\n\n\n\n\n\n\n\n\nTo get the diagnostic plots of the model use;\n\nplot(b, which = \"resid\")\n\n\n\n\n\n\n\n\nThe selection path can be plotted using;\n\nplot(b, which = \"selection\")\n\n\n\n\n\n\n\n\nNow we use a more complex diatributional model using the BCTo family. First we define the formula.\n\nf &lt;- R ~ Fl + A + Fl:A + loc + s(Fl) + s(A) + te(Fl, A) |\n  Fl + A + loc + Fl:A + s(Fl) + s(A) + te(Fl, A) |\n  Fl + A + loc + Fl:A + s(Fl) + s(A) + te(Fl, A) |\n  Fl + A + loc + Fl:A + s(Fl) + s(A) + te(Fl, A)\n\n\n\n\n\n\n\nNote\n\n\n\nNote that if modelling of certain parameters is not required the formula 1| could be used.\n\n\nNext we use the function step_gamlss2() but using different options this time, more specificaly we use;\n\nK=log(3082) so the criterion used will be BIC rather than AIC and therefore less terms will be allowed in the model.\nstrategy = c(\"forward.linear\", \"both\") so specified explicitly which strategies should be used, see the hlp file for more startegies.\n\n\nb &lt;- step_gamlss2(f, data = rent, family = BCTo,\n  K = log(3082), strategy = c(\"forward.linear\", \"both\"),\n  keeporder = TRUE)\n\nForward Linear Selection\n  GAIC = 28121.0230 &lt;+&gt; parameter mu, term Fl\n  GAIC = 28028.2802 &lt;+&gt; parameter mu, term A\n  GAIC = 28001.2470 &lt;+&gt; parameter mu, term loc3\n  GAIC = 27947.0011 &lt;+&gt; parameter sigma, term A\n  GAIC = 27936.1483 &lt;+&gt; parameter nu, term A\nBidirectional Selection\n  GAIC = 27895.7041 &lt;+&gt; parameter mu, term s(A)\n  GAIC = 27860.3933 &lt;+&gt; parameter mu, term loc2\n  GAIC = 27852.4835 &lt;-&gt; parameter mu, term A\nContinue\nFinal Model\n$mu\n.. ~1 + Fl + loc3 + loc2 + s(A)\n$sigma\n.. ~1 + A\n$nu\n.. ~1 + A\n$tau\n.. ~1\n\n\nThe final model model seems lot simpler than the one obtain using AIC and the GA distribution. Let us looks at its residual diagnostic plots.\n\nplot(b, which = \"resid\")\n\n\n\n\n\n\n\n\nThe residual plots lok goog. Next we plot the path of selection.\n\nplot(b, which = \"selection\")",
    "crumbs": [
      "Articles",
      "Model Selection"
    ]
  },
  {
    "objectID": "vignettes/selection.html#conclusions",
    "href": "vignettes/selection.html#conclusions",
    "title": "Model Selection",
    "section": "3 Conclusions",
    "text": "3 Conclusions\nSelection in any distributional regression model like gamlss2 requires both the selection of the distribution and also the selection of the expanatory of variables affecting the parameters of the distribution. A general procedure is proposed here but not implemented. Mikis we should do that. We have shown how distibutions and variables can be sellected seperately.",
    "crumbs": [
      "Articles",
      "Model Selection"
    ]
  },
  {
    "objectID": "vignettes/cens.html",
    "href": "vignettes/cens.html",
    "title": "Censored Estimation",
    "section": "",
    "text": "Describe estimation of censored models.\n\nlibrary(\"gamlss2\")\n\n\n\n\n\nReferences\n\nRigby, R. A., and D. M. Stasinopoulos. 2005. “Generalized Additive Models for Location, Scale and Shape.” Journal of the Royal Statistical Society C 54 (3): 507–54. https://doi.org/10.1111/j.1467-9876.2005.00510.x.",
    "crumbs": [
      "Articles",
      "Censored Estimation"
    ]
  },
  {
    "objectID": "vignettes/Supplement_Families.html",
    "href": "vignettes/Supplement_Families.html",
    "title": "Supplement to Distribution Families in gamlss2",
    "section": "",
    "text": "The distributions in the gamlss2 package differ from those in the original gamlss family, as described by Rigby et al. (2019). The structure of the \"gamlss.family\" object (see Stasinopoulos and Rigby (2007)) differs from that of the \"gamlss2.family\". While both families contain the same core information about the distribution, it is represented in different formats. The key reason for this change is that the new \"gamlss2.family\" structure is more flexible and can be more easily generalized to accommodate models with more than four parameters—something that was a limitation of the earlier GAMLSS implementation in the gamlss package.\nIn this vignette, we aim to:\nFirst we import the packages we are going to need later.\nlibrary(\"gamlss\")\nlibrary(\"gamlss2\")\nlibrary(\"gamlss.ggplots\")",
    "crumbs": [
      "Articles",
      "Supplement to Distribution Families in `gamlss2`"
    ]
  },
  {
    "objectID": "vignettes/Supplement_Families.html#sec-Thestructureofgamlss2family",
    "href": "vignettes/Supplement_Families.html#sec-Thestructureofgamlss2family",
    "title": "Supplement to Distribution Families in gamlss2",
    "section": "1 The structure of \"gamlss2.family\" object",
    "text": "1 The structure of \"gamlss2.family\" object\nA \"gamlss2.family\" object is a list with the following components:\n\nfamily: The name of the family.\nnames: The names of the distribution parameters.\nlinks: The link functions for the parameters.\nd: The probability density function (PDF). If the log-likelihood function (loglik()) is not provided, it will be evaluated using d().\nscores: A named list of the first derivatives of the log-likelihood with respect to the predictors. There is one list entry for each parameter. If these derivatives are not provided, they will be automatically approximated numerically.\nhess: A named list of second derivatives with respect to the predictors. If these derivatives are missing or not supplied, they will be approximated numerically using information from the scores component.\np: The cumulative distribution function (CDF).\nr: The random number generation function.\nq: The quantile function (inverse CDF).\ninitialize: A named list of functions used to set starting values for the distribution parameters.\nmean: The mean function of the distribution (if it exists).\nvariance: The variance function of the distribution (if it exists).\nvalid.response: A function that checks the validity of the response range.\n\nThe first four components (family, names, links, and d) are mandatory for setting up a \"gamlss2.family\" object. The remaining components are optional. However, for model diagnostics using (randomized) quantile residuals, it is recommended to also provide the p() function. Additionally, to compute quantiles, the q() function is necessary. In practice, it is advised to always include the q() function in the family object.\n\n1.1 The normal distribution as gamlss2 family\nAs an example, we demonstrate how to define the normal distribution as a \"gamlss2.family\" object.\n\nNormal &lt;- function(...) {\n  fam &lt;- list(\n    \"family\" = \"Normal\",\n    \"names\" = c(\"mu\", \"sigma\"),\n    \"links\" = c(\"mu\" = \"identity\", \"sigma\" = \"log\"),\n    \n    ## PDF and log-likelihood function\n    \"d\" = function(y, par, log = FALSE) {\n      dnorm(y, mean = par$mu, sd = par$sigma, log = log)\n    },\n    \"loglik\" = function(y, par, ...) {\n      sum(dnorm(y, par$mu, par$sigma, log = TRUE))\n    },\n    \n    ## derivatives (first and second)\n    \"scores\" = list(\n      \"mu\" = function(y, par, ...) {\n        (y - par$mu) / (par$sigma^2)\n      },\n      \"sigma\" = function(y, par, ...) {\n        -1 + (y - par$mu)^2 / (par$sigma^2)\n      }\n    ),\n    \n    \"hess\" = list(\n      \"mu\" = function(y, par, ...) {\n        1 / (par$sigma^2)\n      },\n      \"sigma\" = function(y, par, ...) {\n        rep(2, length(y))\n      },\n      \"mu.sigma\" = function(y, par, ...) {\n        rep(0, length(y))\n      }\n    ),\n    \n    ## CDF, quantile, and random functions\n    \"p\" = function(y, par, ...) { \n      pnorm(y, mean = par$mu, sd = par$sigma, ...)\n    },\n    \"r\" = function(n, par) {\n      rnorm(n, mean = par$mu, sd = par$sigma)\n    },\n    \"q\" = function(p, par) {\n      qnorm(p, mean = par$mu, sd = par$sigma)\n    },\n    \n    ## initialization functions\n    \"initialize\" = list(\n      \"mu\" = function(y, ...) {\n        (y + mean(y)) / 2\n      },\n      \"sigma\" = function(y, ...) {\n        rep(sd(y), length(y))\n      }\n    ),\n    \n    ## mean and variance functions\n    \"mean\" = function(par) {\n      par$mu\n    },\n    \"variance\" = function(par) {\n      par$sigma^2\n    },\n    \n    ## valid response check\n    \"valid.response\" = function(x) {\n      if(is.factor(x) | is.character(x))\n        stop(\"The response should be numeric!\")\n      return(TRUE)\n    }\n  )\n  \n  class(fam) &lt;- \"gamlss2.family\"\n\n  return(fam)\n}\n\nThe family and names components define the name of the distribution and the names of the distribution’s parameters, respectively.\nThe links component specifies the default link functions for the parameters. Link functions govern the range and behavior of the parameters. For example, using a log link for the scale parameter \\(\\sigma\\) ensures that it remains positive. Note that link functions alter the interpretation of the model. For instance, an identity link implies an additive relationship on the parameter scale, such as \\(b_1 x_1 + \\dots + b_p x_p\\), whereas a log link is additive on the predictor scale but introduces a multiplicative structure on the original parameter scale.\nThe scores(), hess(), and loglik() functions define the first and second derivatives and the log-likelihood of the distribution, respectively. These derivatives are crucial for model fitting. The initialize() and valid.response() functions also play important roles in model fitting: initialize() specifies how the initial values for the parameters are determined, and valid.response() defines the valid range for the response variable \\(y\\).\nThe d(), p(), q(), and r() functions define the probability density function (PDF), cumulative distribution function (CDF), quantile function (inverse CDF), and random number generation function for the distribution family.\nThe mean() and variance() functions define the mean and variance of the distribution (if they exist). Note that for some distributions—especially those with heavy tails—these moments may not exist.\n Mikis commends\nit needs to say here which of the options are compulsory and\nwhich are not. By undestanding is that\n family, names, links, d and p are compulsory the rest not. Am I right?\nI am not clear when and why rqres is needed.",
    "crumbs": [
      "Articles",
      "Supplement to Distribution Families in `gamlss2`"
    ]
  },
  {
    "objectID": "vignettes/Supplement_Families.html#sec-fittingmarginal",
    "href": "vignettes/Supplement_Families.html#sec-fittingmarginal",
    "title": "Supplement to Distribution Families in gamlss2",
    "section": "2 Fitting a marginal distribution",
    "text": "2 Fitting a marginal distribution\nBy marginal distribution, we refer to the situation where we are interested in fitting a theoretical distribution, \\(f(y|\\theta)\\), to a single vector \\(y\\) without considering any explanatory variables. In contrast, we use the term conditional distribution to describe the scenario where the response variable \\(y\\) is modeled based on explanatory variables \\(X\\), such that the parameters \\(\\theta\\) are a function of \\(X\\), i.e., \\(f(y|\\theta(X))\\).\n\n2.1 The function find_family()\nIn this section, we aim to find the “best” family for the variable \\(y\\) from a set of relevant available families:\n\np &lt;- find_family(rent$R, families = available_families(\"continuous\"))\n\nThe option families = \"continuous\" limits the available distributions to those in the continuous category. The function find_family() tries to fit all continuous distributions and stores the Generalized Akaike Information Criterion (GAIC) values in a vector. The values of this vector are sorted in decreasing order of GAIC.\n\nprint(p)\n\nNote that similar results can be obtained in gamlss using the fitDist() function:\n\na &lt;- gamlss::fitDist(rent$R)\n\nNote here, the results are sorted in increasing order of GAIC:\n\na$fits\n\n\n\n2.2 The function fit_family()\nThe function fit_family() is similar to the older gamlss function fitDist(). It fits a marginal distribution to the variable \\(y\\) and then generates a histogram of \\(y\\) alongside the fitted distribution.\n\nfit_family(rent$R, family=BCTo)\n\nHere is the output from the older fitDist() function:\n\ngamlss:::histDist(rent$R, family=BCTo, nbins=30)",
    "crumbs": [
      "Articles",
      "Supplement to Distribution Families in `gamlss2`"
    ]
  },
  {
    "objectID": "vignettes/Supplement_Families.html#sec-fittingConditional",
    "href": "vignettes/Supplement_Families.html#sec-fittingConditional",
    "title": "Supplement to Distribution Families in gamlss2",
    "section": "3 Fitting conditional distributions",
    "text": "3 Fitting conditional distributions\n\n3.1 Single conditional distributions\nIn this section, we use the Normal family defined in Section 1.1 to fit a Normal distribution to a model specified by the following formula\n\n## model formula \nf &lt;- R ~ ti(Fl) + ti(A) + ti(Fl, A, bs = \"ps\") | \n  ti(Fl) + ti(A) + ti(Fl, A, bs = \"ps\") \n\n## estimate model\nmNormal &lt;- gamlss2(f, data = rent, family = Normal)\n\nWe can visualize the fitted smoothing terms using\n\nplot(mNormal)\n\nTo inspect the residuals of the model, use\n\nresid_plots(mNormal)\n\nTo improve the residual plots, we can fit a more sophisticated distribution with four parameters.\n\nmBCTo &lt;- gamlss2(f, data = rent, family = BCTo) \nresid_plots(mBCTo)\n\n\n\n3.2 Fitting multiple conditional distributions\nThe function chooseDist() from the gamlss package can be used to compare multiple conditional distributions.\n\nT1 &lt;- gamlss:::chooseDist(mNormal, type = \"realplus\")\n\nThis function generates a table of GAIC values, which can be printed as follows:\n\nlibrary(knitr)\nT1  |&gt; kable(digits = c(2, 2, 3, 3 ))\n\nNote that the function uses the same formula f to fit all the distributional regression models. Also, note that f does not include a model for the parameters \\(\\nu\\) and \\(\\tau\\); therefore, constants (intercepts) are fitted for these two parameters when the distributions have more than two parameters.",
    "crumbs": [
      "Articles",
      "Supplement to Distribution Families in `gamlss2`"
    ]
  },
  {
    "objectID": "vignettes/Supplement_Families.html#sec-Fittinga5parameterdistribution",
    "href": "vignettes/Supplement_Families.html#sec-Fittinga5parameterdistribution",
    "title": "Supplement to Distribution Families in gamlss2",
    "section": "4 Fitting a 5-Parameter distribution",
    "text": "4 Fitting a 5-Parameter distribution\nIn this section, we demonstrate the advantage of using gamlss2 over gamlss for fitting distribution families, specifically highlighting the ease with which a five-parameter distribution can be fitted. As an example, we use the Skew Generalized T (SGT) distribution.\nThe SGT distribution was introduced to R by the sgt package (Carter & Davis, 2015). Its key feature is that it includes a wide range of sub-distributions as special cases, making it highly versatile. The figure below, taken from the sgt package vignette, illustrates the Skew Generalized T distribution and its various sub-distributions.\n\n\n\n\n\n\nThe Skew Generalized T distributions and its sub-distributions (Image from the vignette of the R package sgt)\n\n\n\n\nFigure 1\n\n\n\n\n4.1 Importing the sgt Package\nFirst, load the sgt package:\n\nlibrary(\"sgt\")\n\n\n\n4.2 Defining the SGT distribution as a \"gamlss2.family\"\nWe now define the Skew Generalized T distribution as a \"gamlss2.family\" object using the d(), p(), and q() functions from the sgt package. The function below shares similarities with the Normal distribution created in Section 1.1, though it omits some elements, including:\n\nscore\nhess\nloglik()\nmean()\nvariance()\n\nHere is how the SGT() function is defined:\n\n## Skewed generalized T distribution\nSGT &lt;- function(...) {\n  stopifnot(requireNamespace(\"sgt\"))\n\n  fam &lt;- list(\n    \"names\" = c(\"mu\", \"sigma\", \"lambda\", \"p\", \"q\"),\n    \"links\" = c(\"mu\" = \"identity\", \"sigma\" = \"log\",\n       \"lambda\" = \"rhogit\", \"p\" = \"log\", \"q\" = \"log\"),\n    \"d\" = function(y, par, log = FALSE, ...) {\n      sgt::dsgt(y, mu = par$mu, sigma = par$sigma, lambda = par$lambda,\n        p = par$p, q = par$q, log = log)\n    },\n    \"p\" = function(y, par, lower.tail = TRUE, log.p = FALSE) {\n      sgt::psgt(y, mu = par$mu, sigma = par$sigma,\n        lambda = par$lambda, p = par$p, q = par$q,\n        lower.tail = lower.tail, log.p = log.p)\n    },\n    \"q\" = function(p, par, lower.tail = TRUE, log.p = FALSE) {\n      sgt::qsgt(p, mu = par$mu, sigma = par$sigma,\n        lambda = par$lambda, p = par$p, q = par$q,\n        lower.tail = lower.tail, log.p = log.p)\n    }\n  )\n\n  class(fam) &lt;- \"gamlss2.family\"\n\n  return(fam)\n}\n\n\ndata(\"abdom\", package = \"gamlss.data\")\n## specify the model formula\nf &lt;- y ~ s(x) | s(x) | s(x) | s(x) | s(x)\n\n## estimate SGT model\nb &lt;- gamlss2(f, data = abdom, family = SGT,\n  maxit = c(100, 100), eps = 1e-04)\n\n## plot estimated effects\nplot(b, which = \"effects\")",
    "crumbs": [
      "Articles",
      "Supplement to Distribution Families in `gamlss2`"
    ]
  },
  {
    "objectID": "vignettes/families.html",
    "href": "vignettes/families.html",
    "title": "Family Objects",
    "section": "",
    "text": "All family objects of the gamlss.dist package, see Rigby et al. (2019), can be used for modelling in gamlss2. However, for users wanting to specify their own (new) distribution model, this document provides a guide on how to define custom family objects within the gamlss2 framework.\nFamily objects in the gamlss2 package play an essential role in defining the models used for fitting data to distributions. These objects encapsulate the necessary details about the distribution and the parameters, such as:\nThis document provides an overview of how to construct and use family objects within gamlss2. By the end, you should have a good understanding of how to implement a custom family for use in statistical models.",
    "crumbs": [
      "Articles",
      "Family Objects"
    ]
  },
  {
    "objectID": "vignettes/families.html#defining-family-objects",
    "href": "vignettes/families.html#defining-family-objects",
    "title": "Family Objects",
    "section": "1 Defining Family Objects",
    "text": "1 Defining Family Objects\nA family object in gamlss2 is a list that must meet the following minimum criteria:\n\nFamily Name: The object must contain the family name as a character string.\nParameters: The object must list the parameters of the distribution (e.g., \"mu\" and \"sigma\" for a normal distribution).\nLink Functions: It must specify the link functions associated with each parameter.\nDensity Function: A d() function must be provided to evaluate the (log-)density of the distribution.\n\nOptionally, a family object can include functions to calculate the log-likelihood, random number generation, cumulative distribution function (CDF), and quantile function.\nHere’s an example of a minimal family object for the normal distribution.\n\nNormal &lt;- function(...) {\n  fam &lt;- list(\n    \"family\" = \"Normal\",\n    \"names\" = c(\"mu\", \"sigma\"),\n    \"links\" = c(\"mu\" = \"identity\", \"sigma\" = \"log\"),\n    \"d\" = function(y, par, log = FALSE, ...) {\n      dnorm(y, par$mu, par$sigma, log = log)\n    }\n  )\n  class(fam) &lt;- \"gamlss2.family\"\n  return(fam)\n}\n\nIn this example, we define a normal distribution with two parameters: \"mu\" (mean) and \"sigma\" (standard deviation). The link function for \"mu\" is the identity, and for \"sigma\", it is the log function. The density function uses the standard dnorm() function from to calculate the normal density.",
    "crumbs": [
      "Articles",
      "Family Objects"
    ]
  },
  {
    "objectID": "vignettes/families.html#density-function",
    "href": "vignettes/families.html#density-function",
    "title": "Family Objects",
    "section": "2 Density Function",
    "text": "2 Density Function\nThe density function must accept the following arguments:\n\nd(y, par, log = FALSE, ...)\n\n\ny: The response variable.\npar: A named list of parameters (e.g., \"mu\", \"sigma\" for the normal distribution).\nlog: A logical value indicating whether to return the log-density.",
    "crumbs": [
      "Articles",
      "Family Objects"
    ]
  },
  {
    "objectID": "vignettes/families.html#optional-derivatives",
    "href": "vignettes/families.html#optional-derivatives",
    "title": "Family Objects",
    "section": "3 Optional Derivatives",
    "text": "3 Optional Derivatives\nFamily objects can optionally include functions to compute the first and second derivatives of the log-likelihood with respect to the predictors (or its expectations). These derivatives are used for optimization during model fitting.\nThe derivative functions follow the form:\n\nfunction(y, par, ...)\n\nThe derivate functions of first order must be provided as a named list, one list element for each parameter of the distribution, and is named \"score\". The second order derivative list is named \"hess\". Note that these functions must return the derivative w.r.t. predictor and the \"hess\" functions must return the negative (expected) second derivatives\nAn example of setting up first and second order derivatives for the normal is provided in the following code:\n\nNormal &lt;- function(...) {\n  fam &lt;- list(\n    \"family\" = \"Normal\",\n    \"names\" = c(\"mu\", \"sigma\"),\n    \"links\" = c(\"mu\" = \"identity\", \"sigma\" = \"log\"),\n    \"d\" = function(y, par, log = FALSE, ...) {\n      dnorm(y, par$mu, par$sigma, log = log)\n    },\n    \"score\" = list(\n      \"mu\" = function(y, par, ...) {\n        (y - par$mu) / (par$sigma^2)\n      },\n      \"sigma\" = function(y, par, ...) {\n        -1 + (y - par$mu)^2 / (par$sigma^2)\n      }\n    ),\n    \"hess\" = list(\n      \"mu\" = function(y, par, ...) {\n        1 / (par$sigma^2)\n      },\n      \"sigma\" = function(y, par, ...) {\n        rep(2, length(y))\n      }\n    )\n  )\n  class(fam) &lt;- \"gamlss2.family\"\n  return(fam)\n}\n\nIf no derivatives are provided, numerical approximations will be used by the package.",
    "crumbs": [
      "Articles",
      "Family Objects"
    ]
  },
  {
    "objectID": "vignettes/families.html#additional-functions",
    "href": "vignettes/families.html#additional-functions",
    "title": "Family Objects",
    "section": "4 Additional Functions",
    "text": "4 Additional Functions\nFamily objects can also include other functions such as:\n\nCumulative distribution function (p()).\nQuantile function (q()).\nRandom number generation (r()).\n\nThese functions should adhere to the same structure as the density function, taking the response (y), parameters (par), and other relevant arguments.\n\n\n\n\n\n\nNote\n\n\n\nNote that the CDF p() function is needed it for computing the quantile residuals.",
    "crumbs": [
      "Articles",
      "Family Objects"
    ]
  },
  {
    "objectID": "vignettes/families.html#flexible-links",
    "href": "vignettes/families.html#flexible-links",
    "title": "Family Objects",
    "section": "5 Flexible Links",
    "text": "5 Flexible Links\nNote that the example above used static link functions to define the family object. However, users can easily create families with flexible link functions as well. A helpful example of how to implement such flexibility can be found in the Kumaraswamy distribution implementation, which provides a clear template for setting up families with customizable link functions.\nThe Kumaraswamy distribution is a continuous distribution defined on the interval \\((0, 1)\\). It is similar to the Beta distribution but has simpler forms for its cumulative distribution and inverse cumulative distribution functions, making it more computationally efficient for certain applications. Unfortunately the Kumaraswamy distribution parameters do not conform with the distribution regression principal that parameters should have a clear interpretation in terms of location and scale. For example, the mean and variance of the distribution are a rather complicated functions of the parameters a and b, nevertheless the distribution is a good example of two parameter distribution in which the parameters are not named as mu and sigma as in all distributions defined in Rigby et al. (2019).\nThe probability density function (PDF) of the Kumaraswamy distribution is:\n\\[\nf(y; a, b) = aby^{a-1}(1 - y^a)^{b-1}\n\\]\nwhere \\(y \\in (0, 1)\\) is the response, and \\(a\\) and \\(b\\) are non-negative parameters that determine the shape of the distribution. The complete implementation, including flexible link functions is provided in the Kumaraswamy() family.\nIn the following example, we will create the family object for the Kumaraswamy distribution using the Kumaraswamy() function and estimate a model using this distribution. In detail, we will:\n\nDefine the Kumaraswamy family object.\nSimulate data based on this distribution.\nEstimate the model and plot the results.\n\n\n## Define the Kumaraswamy family object with specific link functions.\nfam &lt;- Kumaraswamy(a.link = shiftlog, b.link = \"log\")\n\n## Set seed for reproducibility.\nset.seed(123)\n\n## Simulate data for 1000 observations.\nn &lt;- 1000\nd &lt;- data.frame(\"x\" = runif(n, -pi, pi))\n\n## Specify the true parameters.\npar &lt;- data.frame(\n  \"a\" = exp(1.2 + sin(d$x)) + 1,  # Parameter 'a' depends on 'x'\n  \"b\" = 1  # Parameter 'b' is constant\n)\n\n## Sample response values using the family object.\nd$y &lt;- fam$r(1, par)\n\n## Estimate a model using the Kumaraswamy family.\nb &lt;- gamlss2(y ~ s(x), data = d, family = fam)\n\nGAMLSS-RS iteration  1: Global Deviance = -1503.9982 eps = 0.674665     \nGAMLSS-RS iteration  2: Global Deviance = -1504.1075 eps = 0.000072     \nGAMLSS-RS iteration  3: Global Deviance = -1504.1262 eps = 0.000012     \nGAMLSS-RS iteration  4: Global Deviance = -1504.1294 eps = 0.000002     \n\n## Plot the estimated effect.\nplot(b)\n\n\n\n\n\n\n\n## Plot residual diagnostics.\nplot(b, which = \"resid\")\n\n\n\n\n\n\n\n\nIn this example, we simulated a dataset where the parameter a of the Kumaraswamy distribution varies with x following a sinusoidal pattern. We then used the gamlss2() function to fit a smooth model that estimates this relationship. The effect of x on y is plotted, followed by a diagnostic plot to assess residuals.\nThe Kumaraswamy() family in gamlss2 is flexible, allowing the user to specify different link functions for its parameters, such as the default shiftlog link function for parameter a, which ensures non-negative values.",
    "crumbs": [
      "Articles",
      "Family Objects"
    ]
  },
  {
    "objectID": "vignettes/families.html#summary",
    "href": "vignettes/families.html#summary",
    "title": "Family Objects",
    "section": "6 Summary",
    "text": "6 Summary\nFamily objects in the gamlss2 package are a fundamental component for defining flexible, distribution-based regression models, and beyond. By encapsulating the necessary elements, such as parameters, link functions, and density functions, they provide a powerful framework for customizing models to fit specific data. The flexibility to define custom families, as demonstrated with the Kumaraswamy() distribution, enables users to extend the package beyond its default families, making it adaptable to a wide range of modeling scenarios. Furthermore, the ability to define both static and dynamic link functions enhances the versatility of gamlss2 for distributional regression, empowering users to tailor models to their unique data and research needs.",
    "crumbs": [
      "Articles",
      "Family Objects"
    ]
  }
]