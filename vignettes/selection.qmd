---
title: "Model Selection"
format: 
  html:
    html-math-method: mathjax
    toc: true
    number-sections: true
bibliography: gamlss2.bib
nocite: |
  @Rigby+Stasinopoulos:2005
vignette: >
  %\VignetteIndexEntry{Selection}
  %\VignetteEngine{quarto::html}
  %\VignetteDepends{gamlss2}
  %\VignetteKeywords{distributional regression, model selection, variable selection}
  %\VignettePackage{gamlss2}
---

```{r preliminaries, echo=FALSE, message=FALSE, results="hide"}
library("gamlss2")
```



A distribution regression model is defined as 

$$\begin{split}
y_i     &  \stackrel{\small{ind}}{\sim }&  {D}( \theta_{1i}, \ldots, \theta_{ki}) \nonumber \\
g(\theta_{1i})  &=& b_{10} + s_1({x}_{1i})  +  \ldots,  s_p({x}_{pi}) \nonumber\\
 \ldots &=& \ldots \nonumber\\
g({\theta}_{ki})  &=& b_0 + s_1({x}_{1i})  +   \ldots,  s_p({x}_{pi})
\end{split} 
$$ {#eq-GAMLSS}
where ${D}( )$ is the assumed distribution which depends on parameters $\theta_{1i}, \ldots, \theta_{ki}$ and where all the parameters can be functions of the explanatory variables $({x}_{1i}, \ldots, {x}_{pi})$.
In reality we do not know the distribution ${D}( )$  and also we do not know **which**  and **how** the variables   $({x}_{1i}, \ldots, {x}_{pi})$ effect the parameters $\theta_{1i}, \ldots, \theta_{ki}$. So the model selection in a distributional regression model could takes the form ;


* select the _best_ fitting distribution;

* select the _relevant_ variables for the parameters and how they effect the parameters. 


A  **general algorithm** for searching for a _best_ model could be;

-  **step 0**: Defining a set of appropriate distributions for the response ${D_J()}$ for $j=1,\ldots, J.$

- **step 1**: **FOR** $J$ in   $j=1,\ldots, J$

- **step 2**: use distribution ${D_J()}$  to **SELECT** appropriate   variables $({x}_{1i}, \ldots, {x}_{pi})$.

- **step 3**: **SELECT** the distribution  $\hat{D}_J()$ and variables which give a  minimum values for a selection  criterion measure.

The selection criterion could be a GAIC defined on the training data a measure defined in the **out of bag** data. While the above algorithm could work reasonable with data having a relative small number or explanatory variables could be very slow for data with a lot of explanatory variables.   


Cutting corners could improve the speed of the algorithm. For example, if  the practitioner gives up the smooth additive structure, that `gamlss2` provides, and she prepare to use only linear terms, a LASSO method can be used at step 2 which will speed up things. Also if the practitioner has confidence on a particular distribution choice, then only the selection step 2 should be performed. The support for a specific distribution can enforced my the preliminary analysis for choosing a distribution described in @sec-Preliminaryanalysis.


## Select a distribution {#sec-Selectadistribution}

### The range of the response {#sec-theranseoftherespons}

The first thing to take into the account in the selection of the distribution is that the distribution should be defined in the range of the response variable. @fig-responseType shows the different possibilities depending on whether the response is `continuous`, `discrete` of `factor`  If the response is continuous and has negative values a distribution in the real line is appropriate. For positive responses a positive real line distribution is appropriate. For bounded continuous response we have the options to transform the response to values between 0 and 1 or to create an appropriate truncated distribution. For count response the consideration is whether the counts are finite or not. For infinity counts a distribution similar to the Poisson distribution can be used. For finite counts binomial type distributions can be used. The case in which the  response is a categorical variable (factor) is called  `classification` regression.  If the factor is an `ordered` factor appropriate models exist but we will not deal with them here.  For unordered factor responses a binomial distribution can be use if the classification is binary otherwise a multinomial distribution. Note that   for classification problems, there is a vast literature in machine learning to deal with the problem.


```{mermaid}
%%| label: fig-responseType
%%| fig-cap: "The response determines which type of distribution to use."
%%| fig-width: 10
%%| fig-height: 6
%%| fig-size: 10
flowchart LR
  A[responce] --> B(continuous) 
  A --> C[discrete]
  A --> D[factor]
  B --> F[real line]
  B --> G[pos. real line]
  B --> H[0 to 1]
  C --> J[infinite count]
  C --> I[finite count]
  D --> K[unordered]
  D --> L[ordered]
  I --> N[binary]
  K --> N[binary]
``` 


### Preliminary analysis {#sec-Preliminaryanalysis}


A preliminary analysis in selecting the distribution can be performed using the `chooseDist()` function of the package `gamlss`. Here we used the `rent` data of the package `gamlss.data`. We first  bring the package and the data set in;

```{r}
#| cache: true
#| warning: false
library(gamlss2)
library(gamlss)
da <- rent99[, -c(2,9)]
head(da)
```
The response variable is is `rent` and there are two continuous, the area of the flat `area` and the year of construction `yearc`  and 4 categorical variables, `location`,  `bath`, `kitchen` and central heating, `cheating`.

Here, first we fit a linear model with all explanatory variables to the location parameters $\mu$ and scale parameter $\sigma$. Later we use the function `chooseDist()` to find out which distribution from the ones in positive real line fit, `type="realplus"`, best fit the data, given that $\mu$ and  $\sigma$ models are fitted linearly with all available variables. Note that, in order to speed up the procedure,  we used here a parallel version of `chooseDist()` using `snow` with 10 NCPUS (the maximum that our machine can take). Please modify accordantly to your machine capabilities.


```{r}
 m1 <- gamlss2(rent~.|., data=da, family=GA,trace=FALSE)
 M1 <- gamlss:::chooseDist(m1, type="realplus", parallel="snow", ncpus=10)
```
The function `chooseDist()` chooses the "best" distribution according to a GAIC criterion. In our case the `BCTo` distribution was chosen using AIC while the `BCCGo` using $\chi^2$ or BIC criteria, respectively.

## Select appropriate variables  {#sec-Selectappropriatevariables}

The methodology of "which explanatory variable is needed and for which parameters" depends on the scope of modelling,
while special attention has to be taken for **non-linear** relationships and for **interaction**.   If the scope of the model is to provide  good interpretation then the additive smooth structure of `gamlss2`is adequate because can cope well with non-linearities and relatively  well with interactions. Note that interactions in an additive structure have to specified explicitly while in some machine learning algorithms like neural network they come part of the model. Machine learning algorithm like random forest and neural networks are more difficult to interpreter.        

