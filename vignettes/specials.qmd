---
title: "Creating a special function in `gamlss2`"
subtitle: "`loess` in gamlss2"
format: 
  html:
    html-math-method: mathjax
    toc: true
    number-sections: true
bibliography: gamlss2.bib
nocite: |
  @Rigby+Stasinopoulos:2005
vignette: >
  %\VignetteIndexEntry{specials}
  %\VignetteEngine{quarto::html}
  %\VignetteDepends{gamlss2}
  %\VignetteKeywords{distributional regression, loess}
  %\VignettePackage{gamlss2}
---

## Introduction

In order to add any new machine learning type algorithm in `gamlss2` you need to define three `special` functions. 

-   a **definition** function

-   a **fitting** function and

-   a **prediction** function


Here we demonstrate how this can be done using the local polynomial smoothing function `loess()` in **R** , @Clevelandetal93.

Note that any regression type machine learning function is **R** can be easily incorporated in `gamlss2` especially if there is a **prior weights** argument in the function. `loess()` has the argument `weights` for prior weights so it can be incorporated easily.

Let us bring in the relevant packages;

```{r}
#| warning: false
rm(list=ls())
library(gamlss2)
library(gamlss)
library(Formula)
library(gamlss.ggplots)
```



In order to incorporate  `loess()`  we need the three  functions dicribed in the next three sections;


### The definition function

The definition function needs a `special` name. 
Names for all new special terms are stored in the `gamlss2` function `fake.formula()`. 
The name is  **needed** to be added into the `fake.formula()` otherwise the function will not work.


`Mikis:` I suggest to add in the in the 'fake.formula' of the package dummy names, like,  "own", "test" etc  so anyone can use it to start off a new function in `gamlss2`. But in order to be include it properly he/she need to contact us (so we can keep some control over the new functions). 


The definition function can take all relevant `loess` and `loess.control` arguments so it can pass them into the fitting function.

```{r}
lo <- function(formula, ...) 
{  stopifnot(requireNamespace("nnet")) 
  ## List for setting up the special model term. 
  st <- list() 
  ## List of control arguments. 
  ctr <- list(...) 
  if(is.null(ctr$span)) 
    ctr$span <- 0.75 
  if(is.null(ctr$enp.target)) 
    ctr$enp.target <- NULL
  if(is.null(ctr$degree)) 
    ctr$degree <- 2 
  if(is.null(ctr$parametric)) 
    ctr$parametric<- "parametric" 
  if(is.null(ctr$drop.square)) 
    ctr$drop.square <- FALSE 
  if(is.null(ctr$normalize)) 
    ctr$normalize <- TRUE 
  if(is.null(ctr$family)) 
    ctr$family <- c("gaussian")
  if(is.null(ctr$method)) 
    ctr$method <- c("loess")      
  if(is.null(ctr$surface)) 
    ctr$surface <- c("interpolate")
  if(is.null(ctr$statistics))        
    ctr$statistics <- c("approximate")
  if(is.null(ctr$trace.hat))        
    ctr$trace.hat <-c("exact")
  if(is.null(ctr$cell))        
    ctr$cell <- 0.2
  if(is.null(ctr$iterations))        
    ctr$iterationsl <- 4
  if(is.null(ctr$iterTrace))        
    ctr$iterTrace <- FALSE 
  ## Put all information together
  st$control <- ctr 
  st$formula <- formula 
  st$term <- all.vars(formula) 
  st$label <- paste0("n(", paste0(gsub(" ", "", as.character(formula)), collapse = ""), ")") 
  st$data <- model.frame(formula) 
  ## Assign the "special" class and the new class "n".
  class(st) <- c("special", "lo") 
  return(st) 
} 
```



## The fitting function

The fitting function takes the current working response, the iterative weights and the corresponding relevant term  and creates a call to the  `loess` function to fit the relevant model. It then saves the fitted values and the fitted objects for later use.  


```{r}
special_fit.lo <- function(x, z, w, control, ...)
{
  ## Model formula needs to be updated.
  f <- update(x$formula, response_z ~ .)
  ## Assign current working response.
  x$data$response_z <- z
  x$data$weights_w <- w 
  ## Estimate model.
  nnc <- parse(text =
          paste0('loess(formula = f, data = x$data, weights = weights_w,',
                 'span = x$control$span, degree=x$control$degree, parametric=x$control$parametric,',
                 'drop.square = x$control$drop.square, normalize=x$control$normalize,',
                 'family=x$control$family, surface=x$control$surface,statistics=x$control$statistics,',
                 'trace=x$control$trace, cell=x$control$cell,iteration=x$control$iteration,',
                  ')'))
  rval <- list("model" = eval(nnc)) 
  ## Get the fitted.values.
  rval$fitted.values <- fitted(rval$model) 
  ## Center fitted values. 
  rval$shift <- mean(rval$fitted.values)
  rval$fitted.values <- rval$fitted.values - rval$shift 
  ## Degrees of freedom.
  rval$edf <-  rval$model$trace.hat
  ## Assign class for predict method. 
  class(rval) <- "lo.fitted" 
  return(rval) 
} 
```

<!-- ## Transferring the weights for the next backfitting iteration. -->
<!--   ## Note, "transfer" can be used to transfer anything from one -->
<!--   ## iteration to the next. -->
<!--   ## save the fitted object  -->
<!--   ## Possible scaling.  -->
<!--   rval$scalex <- x$scalex  -->

## The predict function

The prediction function show how the predicted values of the model can be extracted.

```{r}
special_predict.lo.fitted <- function(x, data, se.fit = FALSE, ...) 
{ 
  p <- predict(x$model, newdata = data) 
  p <- p - x$shift 
  if(se.fit)
    p <- data.frame("fit" = p)
  return(p) 
}  
```

## Example: rent99 data

We use the `rent99` data to demonstrate the use of the functions

```{r}
library(gamlss.prepdata)
## Example with data.
#data("rent", package = "gamlss.data") 
data("rent99", package = "gamlss.data") 
da <- rent99[,-c(2,9)]
da <- gamlss.prepdata:::data_scale(da, response=rent) 
data_names(da) 
head(da)
###########################################################
```
Note that the continuous variables in the data `area` and `yearc` have been standardised. 
We defined four formulae for modelling the rent data. The first two use `loess` and the third and fourth uses the additive smoothing function `s()` for comparison.  Formula `f` uses main effect smoothing terms for `area` and `yearc` for parameters $\mu$ and $\sigma$, respectively,  while the second, `f1`, uses  two dimensional smoothing functions for modelling one way interaction. The third formula uses one dimensional smoother for main effects and the fourth  two dimensional cubic splines smoothers for interactions.  Note that in this example we only use explanatory terms for the first two parameters  $\mu$ and $\sigma$  and constants for the rest, $\nu$ and $\tau$.

```{r}

f <- rent ~ lo(~area)+lo(~yearc)+location+bath+kitchen| 
            lo(~area)+lo(~yearc)+location+bath+kitchen|
            1|1 

f1 <- rent ~ lo(~area*yearc)+location+bath+kitchen| 
             lo(~area*yearc)+location+bath+kitchen|
             1|1

sf <- rent ~ s(~area)+s(~yearc)+location+bath+kitchen| 
             s(~area)+s(~yearc)+location+bath+kitchen|
            1|1 

sf1 <- rent ~ s(area,yearc)+location+bath+kitchen| 
             s(~area,yearc)+location+bath+kitchen|
             1|1

```

## The fits

Below we use the package `tictoc` to measure the time is taken to fit each model.
The main effect fit for `loess`  is; 
```{r}
#| cache: true
## Estimate model. 
## Set the seed for reproducibility. 
library(tictoc)
tic()
b <- gamlss2(f, data = da, family = BCTo) 
toc()
```

The first order interaction fit for `loess` is;
```{r}
#| cache: true
#| warning: false
library(tictoc)
tic()
b1 <- gamlss2(f1, data = da, family = BCTo) 
toc()
```
```{r}
library(tictoc)
tic()
a<- gamlss2(sf, data = da, family = BCT) 
toc()
```

```{r}
library(tictoc)
tic()
a1<- gamlss2(sf1, data = da, family = BCT) 
toc()
```

The cubic spline function `s()` is lot faster that the `lo()`, the `loess()`  implementation  of `gamlss2`.  We now compare the models using AIC;

```{r}
AIC(b,b1,a,a1, k=0) # deviance
AIC(b,b1,a,a1,  k=log(dim(rent99)[1]))# BIC
```


It seems that the two `lo()` models do better that the `s()` as far as the BIC criterion is concern. 


## Visualise the fits

The function `vis.lo()` of ther package `gamlss` can be use to visualised the fitted terms.
Here we show the `area` fitted values for model `b` and for parameter  including the partial residuals from the model.

```{r}
 gamlss:::vis.lo(specials(b, model="mu")[[1]]$model, partial=TRUE)
```

Next we show the year of construction `yearc` fit from model `b` and parameter $\mu$ without partial residuals.

```{r}
gamlss:::vis.lo(specials(b, model="mu")[[2]]$model, partial=FALSE)
```

Here we plot the fitted surface fit from model `b2` and parameters $\mu$;

```{r}
gamlss:::vis.lo(specials(b1, model="mu")$model, partial=FALSE)
```
Here we plot the same fitted surface as above adding  a 95% confidence intervals;
```{r}
gamlss:::vis.lo(specials(b1, model="mu")$model, se=1.97)
```
Finally we plot the fitted surface fit as above  adding the partial residuals. 
```{r}
gamlss:::vis.lo(specials(b1, model="mu")$model, partial=TRUE)
```
Note that similar plots are given in section 9.6.3 of @Stasinopoulosetal2017 where the `lo()` function within package `gamlss` is described.
