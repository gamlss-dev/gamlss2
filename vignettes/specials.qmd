---
title: "Special Model Terms"
format: 
  html:
    html-math-method: mathjax
    toc: true
    number-sections: true
bibliography: gamlss2.bib
nocite: |
  @Rigby+Stasinopoulos:2005
vignette: >
  %\VignetteIndexEntry{specials}
  %\VignetteEngine{quarto::html}
  %\VignetteDepends{gamlss2}
  %\VignetteKeywords{distributional regression, loess}
  %\VignettePackage{gamlss2}
---

```{r preliminaries, echo=FALSE, message=FALSE, results="hide"}
library("gamlss")
library("gamlss2")
```

## Introduction

In order to add any new machine learning type algorithm in `gamlss2` you need to
define three _special_ functions:

-   A **special term constructor** function,
-   a **fitting** function and,
-   a **predict** function.

Here we demonstrate how this can be done using the local polynomial smoothing function
`loess()` in **R**, @Clevelandetal93.

Note that any regression type machine learning function is **R** can be easily incorporated in
`gamlss2` especially if there is a **prior weights** argument in the function.
`loess()` has the argument `weights` for prior weights so it can be incorporated easily.

## The special model term constructor

Any special model term cosntructor **must** be registered in the `fake_formula()` function.
If not yet registered, the user can provide a new special name in the `specials` argument
of `fake_formula()`. Another option is to use the special model term constructor name '"user"',
which is already part of the special names list in `fake_formula()`.

The definition function can take all relevant `loess` and `loess.control` arguments so it
can pass them later into the fitting function.

```{r}
lo <- function(formula, ...) 
{
  ## ensure it's a formula
  if(!inherits(formula, "formula")) {
    formula <- as.character(substitute(formula))
    formula <- as.formula(paste("~", formula))
    environment(formula) <- sys.frame(-1)
  }

  ## list for setting up the special model term 
  st <- list()

  ## control arguments
  st$control <- list(...)

  ## variables, label and data
  st$term <- all.vars(formula) 
  st$label <- paste0("lo(", paste0(gsub(" ", "",
    as.character(formula)), collapse = ""), ")") 
  st$data <- model.frame(formula)

  ## New model formula used for fitting.
  st$formula <- update(formula, response_z ~ .)

  ## Assign the "special" class and the new class "n".
  class(st) <- c("special", "lo")

  return(st) 
} 
```

## The fitting function

The fitting function takes the current working response, the iterative weights and the 
corresponding relevant term and fits and creates a call to the `loess` function to fit the
relevant mdel. It saves the fitted values and the fitted objects for later use.  

```{r}
special_fit.lo <- function(x, z, w, control, ...)
{
  ## assign current working response and weights
  x$data$response_z <- z
  x$data$weights_w <- w

  ## set up loess call
  call <- "loess(formula = x$formula, data = x$data, weights = weights_w"

  ## add optional control parameters
  if(!is.null(x$control)) {
    for(j in names(x$control))
      call <- paste0(call, ", ", j, "= x$control$", j)
  }

  call <- paste0(call, ")")

  ## estimate model
  rval <- list("model" = eval(parse(text = call)))

  ## get the fitted.values
  rval$fitted.values <- fitted(rval$model) 

  ## center fitted values
  rval$shift <- mean(rval$fitted.values)
  rval$fitted.values <- rval$fitted.values - rval$shift 

  ## degrees of freedom
  rval$edf <-  rval$model$trace.hat

  ## assign class for predict method 
  class(rval) <- "lo.fitted" 

  return(rval) 
} 
```

## The predict function

The prediction function shows how the predicted values of the model can be extracted.

```{r}
special_predict.lo.fitted <- function(x, data, se.fit = FALSE, ...) 
{
  p <- as.numeric(predict(x$model, newdata = data))
  if(se.fit)
    p <- data.frame("fit" = p)
  return(p)
}
```

## Example: rent99 data

We use the `rent99` data to demonstrate the use of the functions

```{r}
## load the Munich rent data
data("rent99", package = "gamlss.data") 

## scale covariates
rent99$area <- scale(rent99$area)
rent99$yearc <- scale(rent99$yearc)
```

Note that the continuous variables have been standardised. 
We defined three formulae for modelling the rent data. The first two use `loess` and the third uses the additive smoothing function `s()` for comparison.  Formula `f` uses main effect smoothing terms for `area` and `yearc` for parameters $\mu$ and $\sigma$ while the second, `f1`, uses  two dimensional smoothing functions for interaction. The third formula uses two dimensional cubic splines smoothing for interactions.  Note that in this exapm ple we only use explanatory terms for the first two parameters  $\mu$ and $\sigma$  and constant for the rest, $\nu$ and $\tau$.

```{r}
f1 <- rent ~ lo(area) + lo(yearc) + location + bath + kitchen | 
  lo(area) + lo(yearc) + location + bath + kitchen

f2 <- rent ~ lo(~area*yearc) + location + bath + kitchen | 
  lo(~area*yearc) + location + bath + kitchen

f3 <- rent ~ te(area,yearc) + location + bath + kitchen | 
  te(area,yearc) + location + bath + kitchen
```

## Estimation

We will use the package `tictoc` to measure the amound of time is taken to fit each model.

```{r}
library("tictoc")

tic()
b1 <- gamlss2(f1, data = rent99, family = BCTo) 
toc()
```

The first order interaction fit is.

```{r}
tic()
b2 <- gamlss2(f2, data = rent99, family = BCTo) 
toc()
```

```{r}
tic()
b3 <- gamlss2(f3, data = rent99, family = BCT) 
toc()
```

The cubic spline function is lot faster than the `loess()` implementation `lo()`
in `gamlss2`, but let us now compare the models using AIC.

```{r}
## deviance
AIC(b1, b2, b3, k = 0)

## BIC
AIC(b1, b2, b3, k = log(nrow(rent99)))
```

It seems that the two `lo()` models do better that the `s()` as far as the
AIC criteria are concern. 

## Visualise the fits

```{r}
plot(b1)
```

```{r}
plot(b2)
```

```{r}
plot(b3)
```

The function `vis.lo()` of ther package `gamlss` can be use to visualised the fitted terms.
Here we show the `area` fitted values for model `b` and for parameter $\mu$ including the partial residuals from the model.

```{r}
gamlss:::vis.lo(specials(b1, model="mu")[[1]]$model, partial = TRUE)
```

Next we shos again from model `b` the fitted values for year of construction `yearc`, without partial residuals.

```{r}
gamlss:::vis.lo(specials(b1, model = "mu")[[2]]$model, partial = FALSE)
```

Here we plot the fitted surface fit from the $\mu$ model of `b1`.

```{r}
gamlss:::vis.lo(specials(b2, model = "mu")$model, partial = FALSE)
```

Here we plot the same fitted surface as above adding  95% confidence intervals;

```{r}
gamlss:::vis.lo(specials(b2, model = "mu")$model, se = 1.97)
```

Finally we plot the fitted surface fit from the $\mu$ model of `b2` adding the patial residuals. 

```{r}
gamlss:::vis.lo(specials(b2, model = "mu")$model, partial = TRUE)
```

Note that similar plots are given in section 9.6.3 of @Stasinopoulosetal2017.

